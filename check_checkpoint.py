import torch
import numpy as np

def check_checkpoint(checkpoint_path):
    """μ²΄ν¬ν¬μΈνΈ κ°€μ¤‘μΉλ¥Ό κ²€μ¦ν•λ” ν•¨μ"""
    print(f"μ²΄ν¬ν¬μΈνΈ κ²€μ¦: {checkpoint_path}")
    print("=" * 50)
    
    # μ²΄ν¬ν¬μΈνΈ λ΅λ“
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print("β… μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ„±κ³µ")
    except Exception as e:
        print(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ‹¤ν¨: {e}")
        return
    
    # κΈ°λ³Έ μ •λ³΄ ν™•μΈ
    print(f"μ²΄ν¬ν¬μΈνΈ ν‚¤: {list(checkpoint.keys())}")
    print(f"μ—ν­: {checkpoint.get('epoch', 'Not found')}")
    
    # State dict ν™•μΈ
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
        print(f"\nπ“ λ¨λΈ νλΌλ―Έν„° μ •λ³΄:")
        print(f"μ΄ νλΌλ―Έν„° μ: {len(state_dict)}")
        
        # νλΌλ―Έν„° ν†µκ³„
        total_params = 0
        param_stats = []
        
        for key, param in state_dict.items():
            if param.dtype in [torch.float32, torch.float16]:
                total_params += param.numel()
                param_stats.append({
                    'key': key,
                    'shape': param.shape,
                    'mean': param.mean().item(),
                    'std': param.std().item(),
                    'min': param.min().item(),
                    'max': param.max().item(),
                    'has_nan': torch.isnan(param).any().item(),
                    'has_inf': torch.isinf(param).any().item()
                })
        
        print(f"μ΄ νλΌλ―Έν„° κ°μ: {total_params:,}")
        
        # λ¬Έμ κ°€ μλ” νλΌλ―Έν„° ν™•μΈ
        nan_params = [p for p in param_stats if p['has_nan']]
        inf_params = [p for p in param_stats if p['has_inf']]
        zero_params = [p for p in param_stats if p['std'] == 0]
        
        print(f"\nβ οΈ  λ¬Έμ κ°€ μλ” νλΌλ―Έν„°:")
        print(f"NaN ν¬ν•¨: {len(nan_params)}κ°")
        print(f"Inf ν¬ν•¨: {len(inf_params)}κ°")
        print(f"ν‘μ¤€νΈμ°¨ 0: {len(zero_params)}κ°")
        
        if nan_params:
            print("NaNμ΄ ν¬ν•¨λ νλΌλ―Έν„° (μ²μ 5κ°):")
            for p in nan_params[:5]:
                print(f"  {p['key']}: shape={p['shape']}")
        
        if inf_params:
            print("Infκ°€ ν¬ν•¨λ νλΌλ―Έν„° (μ²μ 5κ°):")
            for p in inf_params[:5]:
                print(f"  {p['key']}: shape={p['shape']}")
        
        # μ²« λ²μ§Έ νλΌλ―Έν„°λ“¤μ μƒμ„Έ μ •λ³΄
        print(f"\nπ“‹ μ²« λ²μ§Έ νλΌλ―Έν„°λ“¤μ μƒμ„Έ μ •λ³΄:")
        for i, p in enumerate(param_stats[:10]):
            print(f"{i+1}. {p['key']}")
            print(f"   Shape: {p['shape']}")
            print(f"   Mean: {p['mean']:.6f}, Std: {p['std']:.6f}")
            print(f"   Range: [{p['min']:.6f}, {p['max']:.6f}]")
            print(f"   Has NaN: {p['has_nan']}, Has Inf: {p['has_inf']}")
            print()
    
    # Optimizer μƒνƒ ν™•μΈ
    if 'optimizer' in checkpoint:
        optimizer = checkpoint['optimizer']
        print(f"\nπ”§ Optimizer μ •λ³΄:")
        print(f"Optimizer ν‚¤: {list(optimizer.keys())}")
        if 'state' in optimizer:
            print(f"Optimizer state ν•­λ© μ: {len(optimizer['state'])}")
    
    # EMA μƒνƒ ν™•μΈ
    if 'state_dict_ema' in checkpoint:
        ema_state_dict = checkpoint['state_dict_ema']
        print(f"\nπ“ EMA μ •λ³΄:")
        print(f"EMA νλΌλ―Έν„° μ: {len(ema_state_dict)}")
        
        # EMA νλΌλ―Έν„° ν†µκ³„
        ema_has_nan = any(torch.isnan(param).any() for param in ema_state_dict.values())
        ema_has_inf = any(torch.isinf(param).any() for param in ema_state_dict.values())
        print(f"EMA Has NaN: {ema_has_nan}")
        print(f"EMA Has Inf: {ema_has_inf}")
    
    print("\n" + "=" * 50)
    print("μ²΄ν¬ν¬μΈνΈ κ²€μ¦ μ™„λ£")

if __name__ == "__main__":
    # μµμ‹  μ²΄ν¬ν¬μΈνΈ κ²€μ¦
    checkpoint_path = "work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/checkpoint/epoch_59.pth"
    check_checkpoint(checkpoint_path)
    
    # μ΄μ „ μ²΄ν¬ν¬μΈνΈμ™€ λΉ„κµ (μ„ νƒμ‚¬ν•­)
    print("\n" + "=" * 50)
    print("μ΄μ „ μ²΄ν¬ν¬μΈνΈμ™€ λΉ„κµ")
    print("=" * 50)
    
    try:
        prev_checkpoint = torch.load("work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/checkpoint/epoch_57.pth", map_location='cpu')
        current_checkpoint = torch.load("work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/checkpoint/epoch_59.pth", map_location='cpu')
        
        print(f"μ΄μ „ μ—ν­: {prev_checkpoint.get('epoch', 'Not found')}")
        print(f"ν„μ¬ μ—ν­: {current_checkpoint.get('epoch', 'Not found')}")
        
        # νλΌλ―Έν„° λ³€ν™” ν™•μΈ
        prev_state = prev_checkpoint['state_dict']
        curr_state = current_checkpoint['state_dict']
        
        print(f"\nνλΌλ―Έν„° λ³€ν™” λ¶„μ„:")
        total_diff = 0
        for key in curr_state.keys():
            if key in prev_state:
                diff = torch.abs(curr_state[key] - prev_state[key]).mean().item()
                total_diff += diff
        
        print(f"ν‰κ·  νλΌλ―Έν„° λ³€ν™”: {total_diff / len(curr_state):.8f}")
        
        if total_diff < 1e-8:
            print("β οΈ  κ²½κ³ : νλΌλ―Έν„° λ³€ν™”κ°€ λ§¤μ° μ‘μµλ‹λ‹¤. ν•™μµμ΄ μ λ€λ΅ λμ§€ μ•μ•μ„ μ μμµλ‹λ‹¤.")
        elif total_diff > 1.0:
            print("β οΈ  κ²½κ³ : νλΌλ―Έν„° λ³€ν™”κ°€ λ§¤μ° ν½λ‹λ‹¤. ν•™μµμ΄ λ¶μ•μ •ν•  μ μμµλ‹λ‹¤.")
        else:
            print("β… νλΌλ―Έν„° λ³€ν™”κ°€ μ •μƒ λ²”μ„μ…λ‹λ‹¤.")
            
    except Exception as e:
        print(f"μ΄μ „ μ²΄ν¬ν¬μΈνΈ λΉ„κµ μ‹¤ν¨: {e}") 