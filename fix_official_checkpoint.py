#!/usr/bin/env python3

import torch

def fix_official_checkpoint():
    """Official modelì˜ 'module.' prefixë¥¼ ì œê±°í•˜ì—¬ single GPUì—ì„œ ë¡œë“œ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤"""
    
    print("ğŸ”§ Official checkpoint ìˆ˜ì • ì¤‘...")
    
    # Official model ë¡œë“œ
    checkpoint_path = "pretrained/official/adatad_videomae_s_official.pth"
    checkpoint = torch.load(checkpoint_path, map_location="cpu")
    
    print(f"ğŸ“ ì›ë³¸ checkpoint keys ê°œìˆ˜: {len(checkpoint['state_dict_ema'])}")
    
    # ìƒˆë¡œìš´ state_dict ìƒì„± (module. prefix ì œê±°)
    new_state_dict = {}
    for key, value in checkpoint["state_dict_ema"].items():
        if key.startswith("module."):
            new_key = key[7:]  # "module." ì œê±° (7ê¸€ì)
            new_state_dict[new_key] = value
        else:
            new_state_dict[key] = value
    
    # ìˆ˜ì •ëœ checkpoint ì €ì¥
    checkpoint["state_dict_ema"] = new_state_dict
    
    # ìƒˆë¡œìš´ ê²½ë¡œì— ì €ì¥
    fixed_path = "pretrained/official/adatad_videomae_s_official_fixed.pth"
    torch.save(checkpoint, fixed_path)
    
    print(f"âœ… ìˆ˜ì •ëœ checkpoint ì €ì¥ ì™„ë£Œ: {fixed_path}")
    print(f"ğŸ“ ìˆ˜ì •ëœ checkpoint keys ê°œìˆ˜: {len(new_state_dict)}")
    
    # ëª‡ ê°œ key ì˜ˆì‹œ ì¶œë ¥
    print("\nğŸ” ìˆ˜ì •ëœ key ì˜ˆì‹œ:")
    for i, key in enumerate(list(new_state_dict.keys())[:5]):
        print(f"  {i+1}. {key}")
    
    return fixed_path

if __name__ == "__main__":
    fix_official_checkpoint() 