{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc60c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lib import completed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from mmengine.config import Config\n",
    "from opentad.datasets import build_dataset, build_dataloader\n",
    "from opentad.datasets.base import SlidingWindowDataset, PaddingDataset, filter_same_annotation\n",
    "from opentad.datasets.pku import PkuSlidingDataset, PkuPaddingDataset\n",
    "\n",
    "sys.path.append(str(Path.cwd()))\n",
    "print(\"lib import completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2d364c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file load\n",
      "path : {config_path}\n",
      "keys : {list(cfg.keys())}\n",
      "dataset_cfg keys: ['train', 'val', 'test']\n",
      "train_cfg settings\n",
      "type : PkuPaddingDataset\n",
      "ann_file : data/PKU-MMD/pku_train.json\n",
      "data path : Unknown\n",
      "pipelines : 13\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/adatad/pku_mmd/e2e_pku_mmd_videomae_s_768x1_160_adapter.py\"\n",
    "cfg = Config.fromfile(config_path)\n",
    "print(\"config file load\")\n",
    "print(\"path : {config_path}\")\n",
    "print(\"keys : {list(cfg.keys())}\")\n",
    "\n",
    "if hasattr(cfg, \"dataset\"):\n",
    "    dataset_cfg = cfg.dataset\n",
    "    print(f\"dataset_cfg keys: {list(dataset_cfg.keys())}\")\n",
    "\n",
    "    if hasattr(dataset_cfg, 'train'):\n",
    "        train_cfg = dataset_cfg.train\n",
    "        print(f\"train_cfg settings\")\n",
    "        print(f\"type : {train_cfg.get('type', 'Unknown')}\")\n",
    "        print(f\"ann_file : {train_cfg.get('ann_file', 'Unknown')}\")\n",
    "        print(f\"data path : {train_cfg.get('data_prefix', 'Unknown')}\")\n",
    "        print(f\"pipelines : {len(train_cfg.get('pipeline', []))}\")\n",
    "else:\n",
    "    print(\"dataset_cfg x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e71d93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training subset: 831 videos\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_dataset(cfg.dataset.train)\n",
    "\n",
    "train_loader = build_dataloader(\n",
    "    train_dataset,\n",
    "    rank=0,\n",
    "    world_size=1,\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212c6f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/12 12:39:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "08/12 12:39:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "train dataset sample keys : ['inputs', 'masks', 'gt_segments', 'gt_labels', 'metas']\n",
      "inputs\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([1, 3, 512, 160, 160])\n",
      "data type: torch.uint8\n",
      "masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([512])\n",
      "data type: torch.bool\n",
      "gt_segments\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([3, 2])\n",
      "data type: torch.float32\n",
      "gt_labels\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([3])\n",
      "data type: torch.int32\n",
      "metas\n",
      "type: <class 'dict'>\n",
      "no dataset\n"
     ]
    }
   ],
   "source": [
    "if 'train_dataset' in locals():\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"train dataset sample keys : {list(sample.keys())}\")\n",
    "\n",
    "    for key, value in sample.items():\n",
    "        print(f\"{key}\")\n",
    "        print(f\"type: {type(value)}\")\n",
    "\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"shape: {value.shape}\")\n",
    "            print(f\"data type: {value.dtype}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"no dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f36fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sample metadata:\n",
      "metas: {'video_name': '0002-L', 'data_path': 'F:/dataset/pku-mmd/rgb', 'fps': 30.0, 'duration': 4462, 'snippet_stride': 1, 'window_start_frame': 0, 'window_size': 512, 'offset_frames': 0}\n"
     ]
    }
   ],
   "source": [
    "first_sample = train_dataset[0]\n",
    "print(f\"first sample metadata:\")\n",
    "for key, value in first_sample.items():\n",
    "    if key not in ['inputs', 'masks', 'gt_segments', 'gt_labels']:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "if 'video_name' in first_sample:\n",
    "    print(f\"video name: {first_sample['video_name']}\")\n",
    "\n",
    "if 'windows_start_frame' in first_sample:\n",
    "    print(f\"windows start frame: {first_sample['windows_start_frame']}\")\n",
    "\n",
    "\n",
    "\n",
    "if 'duration' in first_sample:\n",
    "    print(f\"duration: {first_sample['duration']}\")\n",
    "\n",
    "if 'fps' in first_sample:\n",
    "    print(f\"fps: {first_sample['fps']}\")\n",
    "\n",
    "if 'snippet_stride' in first_sample:\n",
    "    print(f\"snippet stride: {first_sample['snippet_stride']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a016456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no batch data\n"
     ]
    }
   ],
   "source": [
    "def visualize_pku_batch_sample(data_dict, sample_idx: int = 0, title: str = \"sample\"):\n",
    "\n",
    "    if \"inputs\" not in data_dict:\n",
    "        print(\"no inputs\");  return\n",
    "\n",
    "    inputs = data_dict[\"inputs\"].cpu()      \n",
    "    sample_inputs = inputs[sample_idx]      \n",
    "\n",
    "\n",
    "    if sample_inputs.dim() == 5:          \n",
    "        sample_inputs = sample_inputs[:, 0]    \n",
    "    elif sample_inputs.dim() != 4:       \n",
    "        raise ValueError(f\"Unexpected shape: {sample_inputs.shape}\")\n",
    "\n",
    "    C, T, H, W = sample_inputs.shape\n",
    "    frame_idx = np.linspace(0, T - 1, 8, dtype=int)\n",
    "\n",
    " \n",
    "    fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle(f\"{title} (sample {sample_idx})\", fontsize=16)\n",
    "\n",
    "    for k, fi in enumerate(frame_idx):\n",
    "        r, c = divmod(k, 4)\n",
    "        frame = sample_inputs[:, fi].permute(1, 2, 0).numpy()     \n",
    "        frame = (frame - frame.min()) / (frame.max() - frame.min() + 1e-6)\n",
    "        ax[r, c].imshow((frame * 255).astype(\"uint8\"))\n",
    "        ax[r, c].set_title(f\"Frame {fi}\")\n",
    "        ax[r, c].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout();  plt.show()\n",
    "\n",
    "    if {\"gt_segments\", \"gt_labels\"} <= data_dict.keys():\n",
    "        segs, lbls = data_dict[\"gt_segments\"], data_dict[\"gt_labels\"]\n",
    "        print(f\"\\n[pku annotation info] sample {sample_idx}\")\n",
    "        if sample_idx < len(segs):\n",
    "            for i, (seg, lab) in enumerate(zip(segs[sample_idx], lbls[sample_idx])):\n",
    "                print(f\"  #{i+1:02d}  label={lab.item():2d}  segment={seg.tolist()}\")\n",
    "        else:\n",
    "            print(\"  no annotation\")\n",
    "\n",
    "    if \"metas\" in data_dict and sample_idx < len(data_dict[\"metas\"]):\n",
    "        meta = data_dict[\"metas\"][sample_idx]\n",
    "        print(f\"\\n[pku metadata] sample {sample_idx}\")\n",
    "        for k, v in meta.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "if 'data_dict' in locals():\n",
    "    visualize_pku_batch_sample(data_dict, sample_idx=0, title=\"sample 0\")\n",
    "\n",
    "    if data_dict['inputs'].shape[0] > 1:\n",
    "        visualize_pku_batch_sample(data_dict, sample_idx=1, title=\"sample 1\")\n",
    "\n",
    "else:\n",
    "    print(\"no batch data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7193064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load batch data first\n",
    "data_dict = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a6aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
