2025-08-07 14:58:56 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-07 14:58:57 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.1,
        0.3,
        0.5,
        0.7,
        0.9,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.3)
load_from = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/checkpoint/epoch_34.pth'
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=500,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=True)
resume = False
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=2)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=5,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=1,
    start_epoch=35,
    val_eval_interval=5,
    val_loss_interval=5,
    val_start_epoch=5)

2025-08-07 14:58:57 Train INFO: training subset: 831 videos
2025-08-07 14:58:57 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-07 14:58:57 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-07 14:58:57 Train INFO: Using single GPU training...
2025-08-07 14:58:57 Train INFO: Using Model EMA...
2025-08-07 14:58:57 Train INFO: Using Automatic Mixed Precision...
2025-08-07 14:58:57 Train INFO: GPU Memory: 24.0 GB
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.pos_embed
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-07 14:58:57 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-07 14:58:57 Train INFO: Training Starts...

2025-08-07 14:58:57 Train INFO: Running validation check with 1 validation steps...
2025-08-07 14:58:57 Train INFO: [Val]: Epoch -1 Loss
2025-08-07 15:53:45 Train INFO: [Val]: [-01]  Loss=2.1701  cls_loss=1.1683  reg_loss=1.0018  Average-mAP=0.00%
2025-08-07 15:53:46 Train INFO: Validation check completed.

2025-08-07 15:53:46 Train INFO: [Train]: Epoch 0 started (Total iterations: 52)
2025-08-07 16:04:59 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-07 16:04:59 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.1,
        0.3,
        0.5,
        0.7,
        0.9,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.3)
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=500,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=True)
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=5,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=1,
    val_eval_interval=5,
    val_loss_interval=5,
    val_start_epoch=5)

2025-08-07 16:05:00 Train INFO: training subset: 831 videos
2025-08-07 16:05:00 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-07 16:05:00 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-07 16:05:00 Train INFO: Using single GPU training...
2025-08-07 16:05:00 Train INFO: Using Model EMA...
2025-08-07 16:05:00 Train INFO: Using Automatic Mixed Precision...
2025-08-07 16:05:00 Train INFO: GPU Memory: 24.0 GB
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.pos_embed
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-07 16:05:00 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-07 16:05:00 Train INFO: Training Starts...

2025-08-07 16:05:00 Train INFO: Running validation check with 1 validation steps...
2025-08-07 16:05:00 Train INFO: [Val]: Epoch -1 Loss
2025-08-07 16:06:36 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-07 16:06:37 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.1,
        0.3,
        0.5,
        0.7,
        0.9,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.3)
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=500,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.7),
    save_dict=True)
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=5,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=0,
    val_eval_interval=5,
    val_loss_interval=5,
    val_start_epoch=5)

2025-08-07 16:06:37 Train INFO: training subset: 831 videos
2025-08-07 16:06:37 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-07 16:06:37 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-07 16:06:37 Train INFO: Using single GPU training...
2025-08-07 16:06:37 Train INFO: Using Model EMA...
2025-08-07 16:06:37 Train INFO: Using Automatic Mixed Precision...
2025-08-07 16:06:37 Train INFO: GPU Memory: 24.0 GB
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.pos_embed
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-07 16:06:37 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-07 16:06:37 Train INFO: Training Starts...

2025-08-07 16:06:37 Train INFO: [Train]: Epoch 0 started (Total iterations: 52)
2025-08-07 16:15:42 Train INFO: [Train]: [000][00005/00051] (11.5%)  Loss=1.6272  cls_loss=0.8681  reg_loss=0.7591  lr_backbone=1.9e-07  lr_det=1.9e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=4172s  iter_time=544.183s  fwd=4.227s/bwd=47.302s/opt=4.124s
2025-08-07 16:20:15 Train INFO: [Train]: [000][00010/00051] (21.2%)  Loss=1.6351  cls_loss=0.8832  reg_loss=0.7518  lr_backbone=3.9e-07  lr_det=3.9e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=3048s  iter_time=273.555s
2025-08-07 16:24:44 Train INFO: [Train]: [000][00015/00051] (30.8%)  Loss=1.6662  cls_loss=0.9263  reg_loss=0.7399  lr_backbone=5.8e-07  lr_det=5.8e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=2444s  iter_time=268.469s
2025-08-07 16:29:05 Train INFO: [Train]: [000][00020/00051] (40.4%)  Loss=1.6711  cls_loss=0.9595  reg_loss=0.7116  lr_backbone=7.7e-07  lr_det=7.7e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1989s  iter_time=261.182s
2025-08-07 16:33:23 Train INFO: [Train]: [000][00025/00051] (50.0%)  Loss=1.6093  cls_loss=0.9571  reg_loss=0.6523  lr_backbone=9.7e-07  lr_det=9.7e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1606s  iter_time=258.287s
2025-08-07 16:37:47 Train INFO: [Train]: [000][00030/00051] (59.6%)  Loss=1.6148  cls_loss=0.9997  reg_loss=0.6151  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1266s  iter_time=263.407s
2025-08-07 16:42:18 Train INFO: [Train]: [000][00035/00051] (69.2%)  Loss=1.5724  cls_loss=0.9998  reg_loss=0.5726  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=952s  iter_time=271.978s
2025-08-07 16:47:03 Train INFO: [Train]: [000][00040/00051] (78.8%)  Loss=1.5411  cls_loss=0.9990  reg_loss=0.5421  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=651s  iter_time=284.980s
2025-08-07 16:50:20 Train INFO: [Train]: [000][00045/00051] (88.5%)  Loss=1.5227  cls_loss=1.0028  reg_loss=0.5199  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=342s  iter_time=196.475s
2025-08-07 16:53:20 Train INFO: [Train]: [000][00050/00051] (98.1%)  Loss=1.5154  cls_loss=1.0115  reg_loss=0.5038  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=55s  iter_time=179.707s
2025-08-07 16:53:35 Train INFO: [Train]: [000][00051/00051] (100.0%)  Loss=1.5079  cls_loss=1.0082  reg_loss=0.4997  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1404MB(alloc)/16714MB(reserved)/16159MB(max)  ETA=0s  iter_time=14.871s
2025-08-07 16:53:35 Train INFO: [Train]: Epoch 0 completed in 2817.8s (avg 54.189s/iter)
2025-08-07 16:53:35 Train INFO: [Train]: Final Loss=1.5079
2025-08-07 16:53:35 Train INFO: [Train]: Epoch 1 started (Total iterations: 52)
2025-08-07 17:02:30 Train INFO: [Train]: [001][00005/00051] (11.5%)  Loss=1.3502  cls_loss=1.0118  reg_loss=0.3384  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4102s  iter_time=535.047s  fwd=34.402s/bwd=6.208s/opt=13.922s
2025-08-07 17:07:21 Train INFO: [Train]: [001][00010/00051] (21.2%)  Loss=1.3498  cls_loss=1.0125  reg_loss=0.3373  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3079s  iter_time=290.969s
2025-08-07 17:12:18 Train INFO: [Train]: [001][00015/00051] (30.8%)  Loss=1.3284  cls_loss=0.9979  reg_loss=0.3305  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2526s  iter_time=296.760s
2025-08-07 17:17:13 Train INFO: [Train]: [001][00020/00051] (40.4%)  Loss=1.3146  cls_loss=0.9884  reg_loss=0.3262  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2093s  iter_time=294.770s
2025-08-07 17:22:11 Train INFO: [Train]: [001][00025/00051] (50.0%)  Loss=1.3168  cls_loss=0.9905  reg_loss=0.3263  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1716s  iter_time=298.232s
2025-08-07 17:27:14 Train INFO: [Train]: [001][00030/00051] (59.6%)  Loss=1.3218  cls_loss=0.9950  reg_loss=0.3268  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1368s  iter_time=303.117s
2025-08-07 17:32:16 Train INFO: [Train]: [001][00035/00051] (69.2%)  Loss=1.3187  cls_loss=0.9939  reg_loss=0.3248  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1031s  iter_time=301.799s
2025-08-07 17:37:27 Train INFO: [Train]: [001][00040/00051] (78.8%)  Loss=1.2966  cls_loss=0.9782  reg_loss=0.3184  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=706s  iter_time=310.723s
2025-08-07 17:42:21 Train INFO: [Train]: [001][00045/00051] (88.5%)  Loss=1.2977  cls_loss=0.9797  reg_loss=0.3179  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=382s  iter_time=293.839s
2025-08-07 17:46:52 Train INFO: [Train]: [001][00050/00051] (98.1%)  Loss=1.2951  cls_loss=0.9777  reg_loss=0.3174  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=63s  iter_time=271.010s
2025-08-07 17:48:18 Train INFO: [Train]: [001][00051/00051] (100.0%)  Loss=1.2962  cls_loss=0.9786  reg_loss=0.3175  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=86.486s
2025-08-07 17:48:19 Train INFO: [Train]: Epoch 1 completed in 3283.7s (avg 63.147s/iter)
2025-08-07 17:48:19 Train INFO: [Train]: Final Loss=1.2962
2025-08-07 17:48:19 Train INFO: [Train]: Epoch 2 started (Total iterations: 52)
2025-08-07 17:58:07 Train INFO: [Train]: [002][00005/00051] (11.5%)  Loss=1.1751  cls_loss=0.8979  reg_loss=0.2773  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4512s  iter_time=588.480s  fwd=36.228s/bwd=6.409s/opt=16.103s
2025-08-07 18:03:13 Train INFO: [Train]: [002][00010/00051] (21.2%)  Loss=1.3094  cls_loss=0.9903  reg_loss=0.3191  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3332s  iter_time=305.592s
2025-08-07 18:08:17 Train INFO: [Train]: [002][00015/00051] (30.8%)  Loss=1.3179  cls_loss=0.9942  reg_loss=0.3237  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2697s  iter_time=304.384s
2025-08-07 18:13:22 Train INFO: [Train]: [002][00020/00051] (40.4%)  Loss=1.3030  cls_loss=0.9840  reg_loss=0.3190  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2219s  iter_time=304.687s
2025-08-07 18:18:26 Train INFO: [Train]: [002][00025/00051] (50.0%)  Loss=1.3103  cls_loss=0.9904  reg_loss=0.3199  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1808s  iter_time=304.398s
2025-08-07 18:23:31 Train INFO: [Train]: [002][00030/00051] (59.6%)  Loss=1.2958  cls_loss=0.9803  reg_loss=0.3155  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1431s  iter_time=304.480s
2025-08-07 18:28:36 Train INFO: [Train]: [002][00035/00051] (69.2%)  Loss=1.2988  cls_loss=0.9816  reg_loss=0.3172  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1074s  iter_time=305.088s
2025-08-07 18:33:41 Train INFO: [Train]: [002][00040/00051] (78.8%)  Loss=1.2977  cls_loss=0.9796  reg_loss=0.3180  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=730s  iter_time=304.960s
2025-08-07 18:38:31 Train INFO: [Train]: [002][00045/00051] (88.5%)  Loss=1.2817  cls_loss=0.9685  reg_loss=0.3132  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=393s  iter_time=289.720s
2025-08-07 18:43:01 Train INFO: [Train]: [002][00050/00051] (98.1%)  Loss=1.2806  cls_loss=0.9677  reg_loss=0.3130  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=64s  iter_time=269.936s
2025-08-07 18:44:27 Train INFO: [Train]: [002][00051/00051] (100.0%)  Loss=1.2811  cls_loss=0.9680  reg_loss=0.3131  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.854s
2025-08-07 18:44:27 Train INFO: [Train]: Epoch 2 completed in 3368.4s (avg 64.777s/iter)
2025-08-07 18:44:27 Train INFO: [Train]: Final Loss=1.2811
2025-08-07 18:44:27 Train INFO: [Train]: Epoch 3 started (Total iterations: 52)
2025-08-07 18:53:57 Train INFO: [Train]: [003][00005/00051] (11.5%)  Loss=1.2225  cls_loss=0.9205  reg_loss=0.3020  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4368s  iter_time=569.695s  fwd=36.219s/bwd=6.379s/opt=15.541s
2025-08-07 18:59:00 Train INFO: [Train]: [003][00010/00051] (21.2%)  Loss=1.2360  cls_loss=0.9310  reg_loss=0.3050  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3251s  iter_time=302.571s
2025-08-07 19:04:02 Train INFO: [Train]: [003][00015/00051] (30.8%)  Loss=1.2553  cls_loss=0.9455  reg_loss=0.3098  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2642s  iter_time=301.922s
2025-08-07 19:09:03 Train INFO: [Train]: [003][00020/00051] (40.4%)  Loss=1.2474  cls_loss=0.9380  reg_loss=0.3094  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2179s  iter_time=301.907s
2025-08-07 19:14:07 Train INFO: [Train]: [003][00025/00051] (50.0%)  Loss=1.2545  cls_loss=0.9430  reg_loss=0.3115  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1780s  iter_time=304.024s
2025-08-07 19:19:08 Train INFO: [Train]: [003][00030/00051] (59.6%)  Loss=1.2469  cls_loss=0.9339  reg_loss=0.3130  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1410s  iter_time=301.002s
2025-08-07 19:24:10 Train INFO: [Train]: [003][00035/00051] (69.2%)  Loss=1.2320  cls_loss=0.9195  reg_loss=0.3125  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1059s  iter_time=301.084s
2025-08-07 19:29:11 Train INFO: [Train]: [003][00040/00051] (78.8%)  Loss=1.2247  cls_loss=0.9103  reg_loss=0.3143  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=720s  iter_time=301.743s
2025-08-07 19:33:58 Train INFO: [Train]: [003][00045/00051] (88.5%)  Loss=1.2049  cls_loss=0.8928  reg_loss=0.3120  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=388s  iter_time=287.208s
2025-08-07 19:38:27 Train INFO: [Train]: [003][00050/00051] (98.1%)  Loss=1.1888  cls_loss=0.8774  reg_loss=0.3114  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=64s  iter_time=268.425s
2025-08-07 19:39:53 Train INFO: [Train]: [003][00051/00051] (100.0%)  Loss=1.1839  cls_loss=0.8734  reg_loss=0.3105  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.771s
2025-08-07 19:39:53 Train INFO: [Train]: Epoch 3 completed in 3326.2s (avg 63.965s/iter)
2025-08-07 19:39:53 Train INFO: [Train]: Final Loss=1.1839
2025-08-07 19:39:53 Train INFO: [Train]: Epoch 4 started (Total iterations: 52)
2025-08-07 19:49:39 Train INFO: [Train]: [004][00005/00051] (11.5%)  Loss=1.0310  cls_loss=0.7310  reg_loss=0.3000  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4491s  iter_time=585.840s  fwd=36.343s/bwd=6.455s/opt=16.076s
2025-08-07 19:54:46 Train INFO: [Train]: [004][00010/00051] (21.2%)  Loss=1.0694  cls_loss=0.7584  reg_loss=0.3109  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3325s  iter_time=306.236s
2025-08-07 19:59:50 Train INFO: [Train]: [004][00015/00051] (30.8%)  Loss=1.0727  cls_loss=0.7599  reg_loss=0.3127  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2693s  iter_time=304.663s
2025-08-07 20:04:55 Train INFO: [Train]: [004][00020/00051] (40.4%)  Loss=1.0910  cls_loss=0.7713  reg_loss=0.3197  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2217s  iter_time=305.104s
2025-08-07 20:09:57 Train INFO: [Train]: [004][00025/00051] (50.0%)  Loss=1.0626  cls_loss=0.7505  reg_loss=0.3121  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1804s  iter_time=301.863s
2025-08-07 20:14:43 Train INFO: [Train]: [004][00030/00051] (59.6%)  Loss=1.0618  cls_loss=0.7491  reg_loss=0.3127  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1415s  iter_time=285.813s
2025-08-07 20:19:30 Train INFO: [Train]: [004][00035/00051] (69.2%)  Loss=1.0674  cls_loss=0.7522  reg_loss=0.3152  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1056s  iter_time=286.655s
2025-08-07 20:24:15 Train INFO: [Train]: [004][00040/00051] (78.8%)  Loss=1.0612  cls_loss=0.7467  reg_loss=0.3145  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=714s  iter_time=285.497s
2025-08-07 20:28:53 Train INFO: [Train]: [004][00045/00051] (88.5%)  Loss=1.0517  cls_loss=0.7391  reg_loss=0.3126  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=383s  iter_time=277.727s
2025-08-07 20:33:19 Train INFO: [Train]: [004][00050/00051] (98.1%)  Loss=1.0481  cls_loss=0.7354  reg_loss=0.3126  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=63s  iter_time=266.031s
2025-08-07 20:34:44 Train INFO: [Train]: [004][00051/00051] (100.0%)  Loss=1.0437  cls_loss=0.7324  reg_loss=0.3112  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.081s
2025-08-07 20:34:45 Train INFO: [Train]: Epoch 4 completed in 3291.3s (avg 63.294s/iter)
2025-08-07 20:34:45 Train INFO: [Train]: Final Loss=1.0437
2025-08-07 20:34:45 Train INFO: Checkpoint saved at epoch 4
2025-08-07 20:34:45 Train INFO: [Train]: Epoch 5 started (Total iterations: 52)
2025-08-07 20:43:42 Train INFO: [Train]: [005][00005/00051] (11.5%)  Loss=1.0826  cls_loss=0.7618  reg_loss=0.3208  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4117s  iter_time=537.042s  fwd=35.295s/bwd=6.306s/opt=14.373s
2025-08-07 20:48:32 Train INFO: [Train]: [005][00010/00051] (21.2%)  Loss=1.0232  cls_loss=0.7194  reg_loss=0.3038  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3082s  iter_time=289.704s
2025-08-07 20:53:19 Train INFO: [Train]: [005][00015/00051] (30.8%)  Loss=1.0061  cls_loss=0.7024  reg_loss=0.3037  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2506s  iter_time=286.901s
2025-08-07 20:58:05 Train INFO: [Train]: [005][00020/00051] (40.4%)  Loss=1.0315  cls_loss=0.7231  reg_loss=0.3084  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2066s  iter_time=286.143s
2025-08-07 21:02:51 Train INFO: [Train]: [005][00025/00051] (50.0%)  Loss=1.0168  cls_loss=0.7130  reg_loss=0.3038  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1686s  iter_time=285.763s
2025-08-07 21:07:38 Train INFO: [Train]: [005][00030/00051] (59.6%)  Loss=1.0304  cls_loss=0.7191  reg_loss=0.3114  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1336s  iter_time=286.570s
2025-08-07 21:12:24 Train INFO: [Train]: [005][00035/00051] (69.2%)  Loss=1.0253  cls_loss=0.7138  reg_loss=0.3114  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1004s  iter_time=286.162s
2025-08-07 21:17:10 Train INFO: [Train]: [005][00040/00051] (78.8%)  Loss=1.0245  cls_loss=0.7147  reg_loss=0.3099  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=683s  iter_time=286.630s
2025-08-07 21:21:48 Train INFO: [Train]: [005][00045/00051] (88.5%)  Loss=1.0198  cls_loss=0.7107  reg_loss=0.3091  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=368s  iter_time=277.293s
2025-08-07 21:26:14 Train INFO: [Train]: [005][00050/00051] (98.1%)  Loss=1.0256  cls_loss=0.7142  reg_loss=0.3113  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=61s  iter_time=266.500s
2025-08-07 21:27:39 Train INFO: [Train]: [005][00051/00051] (100.0%)  Loss=1.0247  cls_loss=0.7138  reg_loss=0.3109  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.176s
2025-08-07 21:27:40 Train INFO: [Train]: Epoch 5 completed in 3174.6s (avg 61.051s/iter)
2025-08-07 21:27:40 Train INFO: [Train]: Final Loss=1.0247
2025-08-07 21:27:40 Train INFO: [Train]: Epoch 6 started (Total iterations: 52)
2025-08-07 21:36:40 Train INFO: [Train]: [006][00005/00051] (11.5%)  Loss=0.9699  cls_loss=0.6769  reg_loss=0.2930  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4142s  iter_time=540.237s  fwd=35.032s/bwd=6.231s/opt=14.163s
2025-08-07 21:41:31 Train INFO: [Train]: [006][00010/00051] (21.2%)  Loss=0.9819  cls_loss=0.6808  reg_loss=0.3011  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3099s  iter_time=291.148s
2025-08-07 21:46:22 Train INFO: [Train]: [006][00015/00051] (30.8%)  Loss=0.9913  cls_loss=0.6898  reg_loss=0.3015  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2524s  iter_time=290.587s
2025-08-07 21:51:08 Train INFO: [Train]: [006][00020/00051] (40.4%)  Loss=0.9987  cls_loss=0.6948  reg_loss=0.3038  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2079s  iter_time=286.358s
2025-08-07 21:55:55 Train INFO: [Train]: [006][00025/00051] (50.0%)  Loss=1.0136  cls_loss=0.7058  reg_loss=0.3078  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1695s  iter_time=286.192s
2025-08-07 22:00:41 Train INFO: [Train]: [006][00030/00051] (59.6%)  Loss=0.9992  cls_loss=0.6944  reg_loss=0.3049  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1342s  iter_time=286.411s
2025-08-07 22:05:28 Train INFO: [Train]: [006][00035/00051] (69.2%)  Loss=0.9934  cls_loss=0.6912  reg_loss=0.3022  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1008s  iter_time=286.541s
2025-08-07 22:10:13 Train INFO: [Train]: [006][00040/00051] (78.8%)  Loss=0.9980  cls_loss=0.6951  reg_loss=0.3029  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=685s  iter_time=285.843s
2025-08-07 22:14:51 Train INFO: [Train]: [006][00045/00051] (88.5%)  Loss=1.0029  cls_loss=0.6986  reg_loss=0.3042  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=369s  iter_time=277.898s
2025-08-07 22:19:17 Train INFO: [Train]: [006][00050/00051] (98.1%)  Loss=0.9986  cls_loss=0.6963  reg_loss=0.3024  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=61s  iter_time=265.841s
2025-08-07 22:20:42 Train INFO: [Train]: [006][00051/00051] (100.0%)  Loss=0.9983  cls_loss=0.6960  reg_loss=0.3023  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=84.969s
2025-08-07 22:20:43 Train INFO: [Train]: Epoch 6 completed in 3182.8s (avg 61.207s/iter)
2025-08-07 22:20:43 Train INFO: [Train]: Final Loss=0.9983
2025-08-07 22:20:43 Train INFO: [Train]: Epoch 7 started (Total iterations: 52)
2025-08-07 22:29:34 Train INFO: [Train]: [007][00005/00051] (11.5%)  Loss=1.0032  cls_loss=0.6941  reg_loss=0.3092  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4074s  iter_time=531.456s  fwd=35.193s/bwd=6.274s/opt=13.926s
2025-08-07 22:34:21 Train INFO: [Train]: [007][00010/00051] (21.2%)  Loss=0.9994  cls_loss=0.6943  reg_loss=0.3051  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3050s  iter_time=286.920s
2025-08-07 22:39:07 Train INFO: [Train]: [007][00015/00051] (30.8%)  Loss=1.0076  cls_loss=0.7009  reg_loss=0.3066  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2485s  iter_time=286.145s
2025-08-07 22:43:53 Train INFO: [Train]: [007][00020/00051] (40.4%)  Loss=1.0083  cls_loss=0.6994  reg_loss=0.3089  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2052s  iter_time=285.504s
2025-08-07 22:48:39 Train INFO: [Train]: [007][00025/00051] (50.0%)  Loss=1.0032  cls_loss=0.6979  reg_loss=0.3053  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1676s  iter_time=285.894s
2025-08-07 22:53:25 Train INFO: [Train]: [007][00030/00051] (59.6%)  Loss=1.0035  cls_loss=0.6991  reg_loss=0.3043  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1329s  iter_time=285.808s
2025-08-07 22:58:10 Train INFO: [Train]: [007][00035/00051] (69.2%)  Loss=0.9936  cls_loss=0.6920  reg_loss=0.3015  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=999s  iter_time=285.439s
2025-08-07 23:02:56 Train INFO: [Train]: [007][00040/00051] (78.8%)  Loss=0.9952  cls_loss=0.6932  reg_loss=0.3020  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=680s  iter_time=285.723s
2025-08-07 23:07:34 Train INFO: [Train]: [007][00045/00051] (88.5%)  Loss=1.0023  cls_loss=0.6990  reg_loss=0.3033  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=367s  iter_time=277.930s
2025-08-07 23:12:00 Train INFO: [Train]: [007][00050/00051] (98.1%)  Loss=1.0045  cls_loss=0.7007  reg_loss=0.3038  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=60s  iter_time=266.039s
2025-08-07 23:13:25 Train INFO: [Train]: [007][00051/00051] (100.0%)  Loss=0.9980  cls_loss=0.6963  reg_loss=0.3017  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=84.992s
2025-08-07 23:13:25 Train INFO: [Train]: Epoch 7 completed in 3162.6s (avg 60.819s/iter)
2025-08-07 23:13:25 Train INFO: [Train]: Final Loss=0.9980
2025-08-07 23:13:25 Train INFO: [Train]: Epoch 8 started (Total iterations: 52)
2025-08-07 23:22:23 Train INFO: [Train]: [008][00005/00051] (11.5%)  Loss=1.0426  cls_loss=0.7251  reg_loss=0.3175  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4125s  iter_time=538.030s  fwd=35.074s/bwd=6.345s/opt=14.258s
2025-08-07 23:27:13 Train INFO: [Train]: [008][00010/00051] (21.2%)  Loss=1.0282  cls_loss=0.7145  reg_loss=0.3137  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3085s  iter_time=289.534s
2025-08-07 23:32:00 Train INFO: [Train]: [008][00015/00051] (30.8%)  Loss=1.0242  cls_loss=0.7106  reg_loss=0.3136  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2507s  iter_time=286.826s
2025-08-07 23:36:46 Train INFO: [Train]: [008][00020/00051] (40.4%)  Loss=1.0028  cls_loss=0.6979  reg_loss=0.3050  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2067s  iter_time=285.997s
2025-08-07 23:41:31 Train INFO: [Train]: [008][00025/00051] (50.0%)  Loss=1.0137  cls_loss=0.7059  reg_loss=0.3077  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1686s  iter_time=285.252s
2025-08-07 23:46:17 Train INFO: [Train]: [008][00030/00051] (59.6%)  Loss=1.0201  cls_loss=0.7089  reg_loss=0.3112  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1336s  iter_time=286.296s
2025-08-07 23:51:03 Train INFO: [Train]: [008][00035/00051] (69.2%)  Loss=1.0054  cls_loss=0.6989  reg_loss=0.3065  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1003s  iter_time=285.463s
2025-08-07 23:55:49 Train INFO: [Train]: [008][00040/00051] (78.8%)  Loss=0.9968  cls_loss=0.6922  reg_loss=0.3046  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=682s  iter_time=285.900s
2025-08-08 00:00:27 Train INFO: [Train]: [008][00045/00051] (88.5%)  Loss=0.9981  cls_loss=0.6924  reg_loss=0.3057  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=368s  iter_time=277.922s
2025-08-08 00:04:52 Train INFO: [Train]: [008][00050/00051] (98.1%)  Loss=0.9994  cls_loss=0.6925  reg_loss=0.3068  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=61s  iter_time=265.656s
2025-08-08 00:06:17 Train INFO: [Train]: [008][00051/00051] (100.0%)  Loss=0.9986  cls_loss=0.6919  reg_loss=0.3068  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.048s
2025-08-08 00:06:18 Train INFO: [Train]: Epoch 8 completed in 3172.7s (avg 61.013s/iter)
2025-08-08 00:06:18 Train INFO: [Train]: Final Loss=0.9986
2025-08-08 00:06:18 Train INFO: [Train]: Epoch 9 started (Total iterations: 52)
2025-08-08 00:15:19 Train INFO: [Train]: [009][00005/00051] (11.5%)  Loss=0.9551  cls_loss=0.6639  reg_loss=0.2912  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4145s  iter_time=540.709s  fwd=34.958s/bwd=6.409s/opt=14.468s
2025-08-08 00:20:09 Train INFO: [Train]: [009][00010/00051] (21.2%)  Loss=0.9854  cls_loss=0.6874  reg_loss=0.2981  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3096s  iter_time=289.957s
2025-08-08 00:24:57 Train INFO: [Train]: [009][00015/00051] (30.8%)  Loss=0.9911  cls_loss=0.6901  reg_loss=0.3010  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2518s  iter_time=288.308s
2025-08-08 00:29:43 Train INFO: [Train]: [009][00020/00051] (40.4%)  Loss=0.9834  cls_loss=0.6863  reg_loss=0.2971  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2074s  iter_time=285.960s
2025-08-08 00:34:29 Train INFO: [Train]: [009][00025/00051] (50.0%)  Loss=0.9862  cls_loss=0.6881  reg_loss=0.2981  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1691s  iter_time=286.341s
2025-08-08 00:39:15 Train INFO: [Train]: [009][00030/00051] (59.6%)  Loss=0.9899  cls_loss=0.6901  reg_loss=0.2998  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1339s  iter_time=285.929s
2025-08-08 00:44:02 Train INFO: [Train]: [009][00035/00051] (69.2%)  Loss=0.9928  cls_loss=0.6917  reg_loss=0.3011  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1006s  iter_time=286.286s
2025-08-08 00:48:47 Train INFO: [Train]: [009][00040/00051] (78.8%)  Loss=0.9863  cls_loss=0.6872  reg_loss=0.2991  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=684s  iter_time=285.629s
2025-08-08 00:53:24 Train INFO: [Train]: [009][00045/00051] (88.5%)  Loss=0.9933  cls_loss=0.6917  reg_loss=0.3015  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=369s  iter_time=277.178s
2025-08-08 00:57:50 Train INFO: [Train]: [009][00050/00051] (98.1%)  Loss=0.9938  cls_loss=0.6920  reg_loss=0.3018  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=61s  iter_time=265.854s
2025-08-08 00:59:15 Train INFO: [Train]: [009][00051/00051] (100.0%)  Loss=0.9936  cls_loss=0.6920  reg_loss=0.3016  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=85.085s
2025-08-08 00:59:16 Train INFO: [Train]: Epoch 9 completed in 3178.0s (avg 61.115s/iter)
2025-08-08 00:59:16 Train INFO: [Train]: Final Loss=0.9936
2025-08-08 00:59:16 Train INFO: [Val]: Epoch 9 Loss
2025-08-08 08:14:46 Train INFO: [Val]: [009]  Loss=1.3736  cls_loss=1.0338  reg_loss=0.3398  Average-mAP=0.21%
2025-08-08 08:14:48 Train INFO: Checkpoint saved at epoch 9
2025-08-08 08:14:48 Train INFO: [Train]: Epoch 10 started (Total iterations: 52)
2025-08-08 08:18:26 Train INFO: [Train]: [010][00005/00051] (11.5%)  Loss=0.9214  cls_loss=0.6322  reg_loss=0.2892  lr_backbone=1.0e-05  lr_det=1.0e-04  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1667s  iter_time=217.466s  fwd=2.127s/bwd=4.489s/opt=3.211s
2025-08-08 08:20:08 Train INFO: [Train]: [010][00010/00051] (21.2%)  Loss=0.9282  cls_loss=0.6386  reg_loss=0.2896  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1192s  iter_time=102.303s
2025-08-08 08:21:53 Train INFO: [Train]: [010][00015/00051] (30.8%)  Loss=0.9543  cls_loss=0.6595  reg_loss=0.2947  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=957s  iter_time=105.485s
2025-08-08 08:24:25 Train INFO: [Train]: [010][00020/00051] (40.4%)  Loss=0.9876  cls_loss=0.6832  reg_loss=0.3044  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=852s  iter_time=151.843s
2025-08-08 08:26:08 Train INFO: [Train]: [010][00025/00051] (50.0%)  Loss=1.0002  cls_loss=0.6928  reg_loss=0.3074  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=102.923s
2025-08-08 08:28:05 Train INFO: [Train]: [010][00030/00051] (59.6%)  Loss=1.0012  cls_loss=0.6940  reg_loss=0.3072  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=540s  iter_time=116.659s
2025-08-08 08:29:54 Train INFO: [Train]: [010][00035/00051] (69.2%)  Loss=0.9997  cls_loss=0.6922  reg_loss=0.3076  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=108.771s
2025-08-08 08:32:29 Train INFO: [Train]: [010][00040/00051] (78.8%)  Loss=1.0041  cls_loss=0.6952  reg_loss=0.3090  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=285s  iter_time=155.472s
2025-08-08 08:34:10 Train INFO: [Train]: [010][00045/00051] (88.5%)  Loss=1.0028  cls_loss=0.6941  reg_loss=0.3087  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=100.763s
2025-08-08 08:35:53 Train INFO: [Train]: [010][00050/00051] (98.1%)  Loss=1.0038  cls_loss=0.6951  reg_loss=0.3087  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=103.272s
2025-08-08 08:36:04 Train INFO: [Train]: [010][00051/00051] (100.0%)  Loss=1.0007  cls_loss=0.6928  reg_loss=0.3079  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.666s
2025-08-08 08:36:05 Train INFO: [Train]: Epoch 10 completed in 1276.5s (avg 24.548s/iter)
2025-08-08 08:36:05 Train INFO: [Train]: Final Loss=1.0007
2025-08-08 08:36:05 Train INFO: [Train]: Epoch 11 started (Total iterations: 52)
2025-08-08 08:39:55 Train INFO: [Train]: [011][00005/00051] (11.5%)  Loss=0.8799  cls_loss=0.6066  reg_loss=0.2733  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1769s  iter_time=230.718s  fwd=2.136s/bwd=4.501s/opt=3.217s
2025-08-08 08:41:46 Train INFO: [Train]: [011][00010/00051] (21.2%)  Loss=0.9198  cls_loss=0.6329  reg_loss=0.2870  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1272s  iter_time=110.609s
2025-08-08 08:43:32 Train INFO: [Train]: [011][00015/00051] (30.8%)  Loss=0.9524  cls_loss=0.6574  reg_loss=0.2951  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1008s  iter_time=106.493s
2025-08-08 08:46:21 Train INFO: [Train]: [011][00020/00051] (40.4%)  Loss=0.9750  cls_loss=0.6743  reg_loss=0.3006  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=911s  iter_time=169.056s
2025-08-08 08:48:10 Train INFO: [Train]: [011][00025/00051] (50.0%)  Loss=0.9980  cls_loss=0.6913  reg_loss=0.3067  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=725s  iter_time=108.378s
2025-08-08 08:49:51 Train INFO: [Train]: [011][00030/00051] (59.6%)  Loss=0.9958  cls_loss=0.6892  reg_loss=0.3066  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=560s  iter_time=101.609s
2025-08-08 08:51:35 Train INFO: [Train]: [011][00035/00051] (69.2%)  Loss=1.0043  cls_loss=0.6952  reg_loss=0.3091  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=414s  iter_time=103.674s
2025-08-08 08:54:10 Train INFO: [Train]: [011][00040/00051] (78.8%)  Loss=0.9930  cls_loss=0.6884  reg_loss=0.3046  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=291s  iter_time=154.869s
2025-08-08 08:55:54 Train INFO: [Train]: [011][00045/00051] (88.5%)  Loss=1.0007  cls_loss=0.6941  reg_loss=0.3066  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=104.422s
2025-08-08 08:57:30 Train INFO: [Train]: [011][00050/00051] (98.1%)  Loss=0.9923  cls_loss=0.6881  reg_loss=0.3042  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=95.552s
2025-08-08 08:57:41 Train INFO: [Train]: [011][00051/00051] (100.0%)  Loss=0.9922  cls_loss=0.6880  reg_loss=0.3042  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.687s
2025-08-08 08:57:41 Train INFO: [Train]: Epoch 11 completed in 1296.8s (avg 24.938s/iter)
2025-08-08 08:57:41 Train INFO: [Train]: Final Loss=0.9922
2025-08-08 08:57:41 Train INFO: [Train]: Epoch 12 started (Total iterations: 52)
2025-08-08 09:01:32 Train INFO: [Train]: [012][00005/00051] (11.5%)  Loss=0.9267  cls_loss=0.6458  reg_loss=0.2809  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1766s  iter_time=230.353s  fwd=2.123s/bwd=4.443s/opt=3.201s
2025-08-08 09:03:16 Train INFO: [Train]: [012][00010/00051] (21.2%)  Loss=0.9714  cls_loss=0.6733  reg_loss=0.2980  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1248s  iter_time=104.348s
2025-08-08 09:05:15 Train INFO: [Train]: [012][00015/00051] (30.8%)  Loss=1.0016  cls_loss=0.6927  reg_loss=0.3089  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1020s  iter_time=118.465s
2025-08-08 09:07:55 Train INFO: [Train]: [012][00020/00051] (40.4%)  Loss=0.9782  cls_loss=0.6781  reg_loss=0.3001  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=905s  iter_time=160.160s
2025-08-08 09:09:55 Train INFO: [Train]: [012][00025/00051] (50.0%)  Loss=0.9848  cls_loss=0.6832  reg_loss=0.3017  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=734s  iter_time=120.687s
2025-08-08 09:12:02 Train INFO: [Train]: [012][00030/00051] (59.6%)  Loss=0.9806  cls_loss=0.6805  reg_loss=0.3001  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=583s  iter_time=126.946s
2025-08-08 09:13:52 Train INFO: [Train]: [012][00035/00051] (69.2%)  Loss=0.9959  cls_loss=0.6902  reg_loss=0.3056  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=431s  iter_time=109.857s
2025-08-08 09:16:30 Train INFO: [Train]: [012][00040/00051] (78.8%)  Loss=1.0000  cls_loss=0.6935  reg_loss=0.3064  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=303s  iter_time=158.293s
2025-08-08 09:18:24 Train INFO: [Train]: [012][00045/00051] (88.5%)  Loss=0.9977  cls_loss=0.6922  reg_loss=0.3055  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=162s  iter_time=113.424s
2025-08-08 09:20:11 Train INFO: [Train]: [012][00050/00051] (98.1%)  Loss=0.9968  cls_loss=0.6909  reg_loss=0.3058  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=107.398s
2025-08-08 09:20:23 Train INFO: [Train]: [012][00051/00051] (100.0%)  Loss=0.9910  cls_loss=0.6869  reg_loss=0.3041  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=11.379s
2025-08-08 09:20:23 Train INFO: [Train]: Epoch 12 completed in 1362.2s (avg 26.195s/iter)
2025-08-08 09:20:23 Train INFO: [Train]: Final Loss=0.9910
2025-08-08 09:20:23 Train INFO: [Train]: Epoch 13 started (Total iterations: 52)
2025-08-08 09:24:27 Train INFO: [Train]: [013][00005/00051] (11.5%)  Loss=0.9663  cls_loss=0.6783  reg_loss=0.2880  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1870s  iter_time=243.942s  fwd=2.202s/bwd=4.527s/opt=3.215s
2025-08-08 09:26:13 Train INFO: [Train]: [013][00010/00051] (21.2%)  Loss=1.0045  cls_loss=0.6984  reg_loss=0.3061  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1302s  iter_time=105.269s
2025-08-08 09:28:00 Train INFO: [Train]: [013][00015/00051] (30.8%)  Loss=1.0020  cls_loss=0.6950  reg_loss=0.3070  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1028s  iter_time=107.597s
2025-08-08 09:30:35 Train INFO: [Train]: [013][00020/00051] (40.4%)  Loss=0.9916  cls_loss=0.6875  reg_loss=0.3041  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=902s  iter_time=154.302s
2025-08-08 09:32:20 Train INFO: [Train]: [013][00025/00051] (50.0%)  Loss=0.9916  cls_loss=0.6887  reg_loss=0.3029  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=716s  iter_time=105.100s
2025-08-08 09:34:04 Train INFO: [Train]: [013][00030/00051] (59.6%)  Loss=0.9958  cls_loss=0.6915  reg_loss=0.3043  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=556s  iter_time=104.020s
2025-08-08 09:35:59 Train INFO: [Train]: [013][00035/00051] (69.2%)  Loss=0.9985  cls_loss=0.6930  reg_loss=0.3055  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=416s  iter_time=115.518s
2025-08-08 09:38:40 Train INFO: [Train]: [013][00040/00051] (78.8%)  Loss=0.9996  cls_loss=0.6934  reg_loss=0.3062  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=294s  iter_time=161.114s
2025-08-08 09:40:35 Train INFO: [Train]: [013][00045/00051] (88.5%)  Loss=0.9920  cls_loss=0.6883  reg_loss=0.3037  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=158s  iter_time=114.537s
2025-08-08 09:42:20 Train INFO: [Train]: [013][00050/00051] (98.1%)  Loss=0.9973  cls_loss=0.6918  reg_loss=0.3055  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=105.191s
2025-08-08 09:42:31 Train INFO: [Train]: [013][00051/00051] (100.0%)  Loss=0.9943  cls_loss=0.6896  reg_loss=0.3046  lr_backbone=9.9e-06  lr_det=9.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.935s
2025-08-08 09:42:32 Train INFO: [Train]: Epoch 13 completed in 1328.4s (avg 25.546s/iter)
2025-08-08 09:42:32 Train INFO: [Train]: Final Loss=0.9943
2025-08-08 09:42:32 Train INFO: [Train]: Epoch 14 started (Total iterations: 52)
2025-08-08 09:46:16 Train INFO: [Train]: [014][00005/00051] (11.5%)  Loss=0.9783  cls_loss=0.6704  reg_loss=0.3078  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1716s  iter_time=223.808s  fwd=2.074s/bwd=4.305s/opt=3.083s
2025-08-08 09:47:57 Train INFO: [Train]: [014][00010/00051] (21.2%)  Loss=0.9799  cls_loss=0.6789  reg_loss=0.3010  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1213s  iter_time=101.562s
2025-08-08 09:49:40 Train INFO: [Train]: [014][00015/00051] (30.8%)  Loss=0.9963  cls_loss=0.6893  reg_loss=0.3070  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=963s  iter_time=102.719s
2025-08-08 09:52:11 Train INFO: [Train]: [014][00020/00051] (40.4%)  Loss=0.9726  cls_loss=0.6751  reg_loss=0.2976  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=856s  iter_time=151.457s
2025-08-08 09:53:59 Train INFO: [Train]: [014][00025/00051] (50.0%)  Loss=0.9731  cls_loss=0.6756  reg_loss=0.2974  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=687s  iter_time=107.689s
2025-08-08 09:55:48 Train INFO: [Train]: [014][00030/00051] (59.6%)  Loss=0.9898  cls_loss=0.6870  reg_loss=0.3028  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=539s  iter_time=108.370s
2025-08-08 09:57:34 Train INFO: [Train]: [014][00035/00051] (69.2%)  Loss=0.9834  cls_loss=0.6826  reg_loss=0.3008  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=106.787s
2025-08-08 10:00:01 Train INFO: [Train]: [014][00040/00051] (78.8%)  Loss=0.9842  cls_loss=0.6828  reg_loss=0.3014  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=147.159s
2025-08-08 10:01:38 Train INFO: [Train]: [014][00045/00051] (88.5%)  Loss=0.9767  cls_loss=0.6775  reg_loss=0.2992  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=96.705s
2025-08-08 10:03:27 Train INFO: [Train]: [014][00050/00051] (98.1%)  Loss=0.9816  cls_loss=0.6809  reg_loss=0.3007  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=109.047s
2025-08-08 10:03:38 Train INFO: [Train]: [014][00051/00051] (100.0%)  Loss=0.9799  cls_loss=0.6798  reg_loss=0.3001  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.351s
2025-08-08 10:03:38 Train INFO: [Train]: Epoch 14 completed in 1266.4s (avg 24.354s/iter)
2025-08-08 10:03:38 Train INFO: [Train]: Final Loss=0.9799
2025-08-08 10:03:38 Train INFO: [Val]: Epoch 14 Loss
2025-08-08 10:53:17 Train INFO: [Val]: [014]  Loss=1.2918  cls_loss=0.9759  reg_loss=0.3160  Average-mAP=0.56%
2025-08-08 10:53:20 Train INFO: Checkpoint saved at epoch 14
2025-08-08 10:53:20 Train INFO: [Train]: Epoch 15 started (Total iterations: 52)
2025-08-08 10:57:04 Train INFO: [Train]: [015][00005/00051] (11.5%)  Loss=1.0595  cls_loss=0.7403  reg_loss=0.3192  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1717s  iter_time=223.978s  fwd=2.046s/bwd=4.274s/opt=3.072s
2025-08-08 10:58:42 Train INFO: [Train]: [015][00010/00051] (21.2%)  Loss=1.0181  cls_loss=0.7123  reg_loss=0.3058  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1202s  iter_time=98.422s
2025-08-08 11:00:29 Train INFO: [Train]: [015][00015/00051] (30.8%)  Loss=1.0268  cls_loss=0.7147  reg_loss=0.3121  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=967s  iter_time=107.219s
2025-08-08 11:02:56 Train INFO: [Train]: [015][00020/00051] (40.4%)  Loss=1.0173  cls_loss=0.7089  reg_loss=0.3084  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=851s  iter_time=147.107s
2025-08-08 11:04:36 Train INFO: [Train]: [015][00025/00051] (50.0%)  Loss=1.0214  cls_loss=0.7117  reg_loss=0.3098  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=676s  iter_time=99.557s
2025-08-08 11:06:23 Train INFO: [Train]: [015][00030/00051] (59.6%)  Loss=0.9999  cls_loss=0.6965  reg_loss=0.3034  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=531s  iter_time=106.974s
2025-08-08 11:08:07 Train INFO: [Train]: [015][00035/00051] (69.2%)  Loss=1.0039  cls_loss=0.6991  reg_loss=0.3049  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=394s  iter_time=103.856s
2025-08-08 11:10:39 Train INFO: [Train]: [015][00040/00051] (78.8%)  Loss=0.9963  cls_loss=0.6943  reg_loss=0.3020  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=151.930s
2025-08-08 11:12:31 Train INFO: [Train]: [015][00045/00051] (88.5%)  Loss=1.0032  cls_loss=0.6976  reg_loss=0.3055  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=112.079s
2025-08-08 11:14:12 Train INFO: [Train]: [015][00050/00051] (98.1%)  Loss=1.0047  cls_loss=0.6999  reg_loss=0.3048  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=101.291s
2025-08-08 11:14:22 Train INFO: [Train]: [015][00051/00051] (100.0%)  Loss=1.0036  cls_loss=0.6989  reg_loss=0.3047  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.351s
2025-08-08 11:14:23 Train INFO: [Train]: Epoch 15 completed in 1263.5s (avg 24.298s/iter)
2025-08-08 11:14:23 Train INFO: [Train]: Final Loss=1.0036
2025-08-08 11:14:23 Train INFO: [Train]: Epoch 16 started (Total iterations: 52)
2025-08-08 11:18:10 Train INFO: [Train]: [016][00005/00051] (11.5%)  Loss=0.8929  cls_loss=0.6204  reg_loss=0.2725  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1736s  iter_time=226.446s  fwd=2.073s/bwd=4.279s/opt=3.083s
2025-08-08 11:19:53 Train INFO: [Train]: [016][00010/00051] (21.2%)  Loss=0.9422  cls_loss=0.6546  reg_loss=0.2876  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1230s  iter_time=103.552s
2025-08-08 11:21:35 Train INFO: [Train]: [016][00015/00051] (30.8%)  Loss=0.9439  cls_loss=0.6570  reg_loss=0.2869  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=971s  iter_time=101.748s
2025-08-08 11:24:17 Train INFO: [Train]: [016][00020/00051] (40.4%)  Loss=0.9622  cls_loss=0.6680  reg_loss=0.2941  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=877s  iter_time=162.276s
2025-08-08 11:26:03 Train INFO: [Train]: [016][00025/00051] (50.0%)  Loss=0.9665  cls_loss=0.6694  reg_loss=0.2971  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=700s  iter_time=106.140s
2025-08-08 11:27:48 Train INFO: [Train]: [016][00030/00051] (59.6%)  Loss=0.9859  cls_loss=0.6820  reg_loss=0.3039  lr_backbone=9.8e-06  lr_det=9.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=545s  iter_time=104.754s
2025-08-08 11:29:32 Train INFO: [Train]: [016][00035/00051] (69.2%)  Loss=0.9814  cls_loss=0.6804  reg_loss=0.3010  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=404s  iter_time=103.607s
2025-08-08 11:32:01 Train INFO: [Train]: [016][00040/00051] (78.8%)  Loss=0.9867  cls_loss=0.6840  reg_loss=0.3027  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=148.950s
2025-08-08 11:33:43 Train INFO: [Train]: [016][00045/00051] (88.5%)  Loss=0.9848  cls_loss=0.6836  reg_loss=0.3013  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=102.074s
2025-08-08 11:35:23 Train INFO: [Train]: [016][00050/00051] (98.1%)  Loss=0.9846  cls_loss=0.6838  reg_loss=0.3008  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.773s
2025-08-08 11:35:34 Train INFO: [Train]: [016][00051/00051] (100.0%)  Loss=0.9846  cls_loss=0.6837  reg_loss=0.3009  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-08 11:35:35 Train INFO: [Train]: Epoch 16 completed in 1271.4s (avg 24.451s/iter)
2025-08-08 11:35:35 Train INFO: [Train]: Final Loss=0.9846
2025-08-08 11:35:35 Train INFO: [Train]: Epoch 17 started (Total iterations: 52)
2025-08-08 11:39:43 Train INFO: [Train]: [017][00005/00051] (11.5%)  Loss=1.0167  cls_loss=0.7064  reg_loss=0.3103  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1907s  iter_time=248.686s  fwd=2.051s/bwd=4.314s/opt=3.088s
2025-08-08 11:41:21 Train INFO: [Train]: [017][00010/00051] (21.2%)  Loss=1.0033  cls_loss=0.6959  reg_loss=0.3074  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1293s  iter_time=98.272s
2025-08-08 11:43:08 Train INFO: [Train]: [017][00015/00051] (30.8%)  Loss=0.9968  cls_loss=0.6894  reg_loss=0.3074  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1021s  iter_time=107.010s
2025-08-08 11:45:32 Train INFO: [Train]: [017][00020/00051] (40.4%)  Loss=0.9909  cls_loss=0.6860  reg_loss=0.3050  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=882s  iter_time=143.395s
2025-08-08 11:47:09 Train INFO: [Train]: [017][00025/00051] (50.0%)  Loss=0.9723  cls_loss=0.6743  reg_loss=0.2980  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=695s  iter_time=97.586s
2025-08-08 11:48:50 Train INFO: [Train]: [017][00030/00051] (59.6%)  Loss=0.9880  cls_loss=0.6852  reg_loss=0.3028  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=539s  iter_time=100.444s
2025-08-08 11:50:42 Train INFO: [Train]: [017][00035/00051] (69.2%)  Loss=0.9869  cls_loss=0.6842  reg_loss=0.3026  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=403s  iter_time=112.429s
2025-08-08 11:53:11 Train INFO: [Train]: [017][00040/00051] (78.8%)  Loss=0.9945  cls_loss=0.6892  reg_loss=0.3053  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=148.886s
2025-08-08 11:54:49 Train INFO: [Train]: [017][00045/00051] (88.5%)  Loss=0.9881  cls_loss=0.6843  reg_loss=0.3038  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=97.707s
2025-08-08 11:56:23 Train INFO: [Train]: [017][00050/00051] (98.1%)  Loss=0.9891  cls_loss=0.6854  reg_loss=0.3036  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=94.019s
2025-08-08 11:56:33 Train INFO: [Train]: [017][00051/00051] (100.0%)  Loss=0.9857  cls_loss=0.6834  reg_loss=0.3022  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-08 11:56:34 Train INFO: [Train]: Epoch 17 completed in 1259.5s (avg 24.222s/iter)
2025-08-08 11:56:34 Train INFO: [Train]: Final Loss=0.9857
2025-08-08 11:56:34 Train INFO: [Train]: Epoch 18 started (Total iterations: 52)
2025-08-08 12:00:20 Train INFO: [Train]: [018][00005/00051] (11.5%)  Loss=0.9348  cls_loss=0.6554  reg_loss=0.2794  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1731s  iter_time=225.795s  fwd=2.035s/bwd=4.264s/opt=3.066s
2025-08-08 12:01:57 Train INFO: [Train]: [018][00010/00051] (21.2%)  Loss=0.9869  cls_loss=0.6898  reg_loss=0.2972  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1204s  iter_time=97.198s
2025-08-08 12:03:39 Train INFO: [Train]: [018][00015/00051] (30.8%)  Loss=1.0098  cls_loss=0.7026  reg_loss=0.3073  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=955s  iter_time=101.448s
2025-08-08 12:06:13 Train INFO: [Train]: [018][00020/00051] (40.4%)  Loss=0.9789  cls_loss=0.6821  reg_loss=0.2968  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=855s  iter_time=154.787s
2025-08-08 12:08:05 Train INFO: [Train]: [018][00025/00051] (50.0%)  Loss=0.9806  cls_loss=0.6842  reg_loss=0.2963  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=112.201s
2025-08-08 12:09:48 Train INFO: [Train]: [018][00030/00051] (59.6%)  Loss=0.9825  cls_loss=0.6859  reg_loss=0.2966  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=538s  iter_time=102.678s
2025-08-08 12:11:33 Train INFO: [Train]: [018][00035/00051] (69.2%)  Loss=0.9788  cls_loss=0.6833  reg_loss=0.2956  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=104.390s
2025-08-08 12:14:09 Train INFO: [Train]: [018][00040/00051] (78.8%)  Loss=0.9783  cls_loss=0.6828  reg_loss=0.2955  lr_backbone=9.7e-06  lr_det=9.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=156.882s
2025-08-08 12:15:51 Train INFO: [Train]: [018][00045/00051] (88.5%)  Loss=0.9768  cls_loss=0.6809  reg_loss=0.2959  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=101.509s
2025-08-08 12:17:29 Train INFO: [Train]: [018][00050/00051] (98.1%)  Loss=0.9832  cls_loss=0.6847  reg_loss=0.2985  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=97.785s
2025-08-08 12:17:39 Train INFO: [Train]: [018][00051/00051] (100.0%)  Loss=0.9847  cls_loss=0.6850  reg_loss=0.2997  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.359s
2025-08-08 12:17:40 Train INFO: [Train]: Epoch 18 completed in 1265.8s (avg 24.342s/iter)
2025-08-08 12:17:40 Train INFO: [Train]: Final Loss=0.9847
2025-08-08 12:17:40 Train INFO: [Train]: Epoch 19 started (Total iterations: 52)
2025-08-08 12:21:36 Train INFO: [Train]: [019][00005/00051] (11.5%)  Loss=1.0090  cls_loss=0.7071  reg_loss=0.3019  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1814s  iter_time=236.563s  fwd=2.081s/bwd=4.309s/opt=3.065s
2025-08-08 12:23:23 Train INFO: [Train]: [019][00010/00051] (21.2%)  Loss=1.0109  cls_loss=0.7058  reg_loss=0.3052  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1278s  iter_time=106.288s
2025-08-08 12:25:08 Train INFO: [Train]: [019][00015/00051] (30.8%)  Loss=1.0116  cls_loss=0.7051  reg_loss=0.3065  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1008s  iter_time=104.971s
2025-08-08 12:27:49 Train INFO: [Train]: [019][00020/00051] (40.4%)  Loss=0.9725  cls_loss=0.6761  reg_loss=0.2964  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=899s  iter_time=161.272s
2025-08-08 12:29:30 Train INFO: [Train]: [019][00025/00051] (50.0%)  Loss=0.9913  cls_loss=0.6880  reg_loss=0.3033  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=711s  iter_time=101.471s
2025-08-08 12:31:16 Train INFO: [Train]: [019][00030/00051] (59.6%)  Loss=0.9843  cls_loss=0.6826  reg_loss=0.3017  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=553s  iter_time=105.908s
2025-08-08 12:33:09 Train INFO: [Train]: [019][00035/00051] (69.2%)  Loss=0.9756  cls_loss=0.6759  reg_loss=0.2997  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=413s  iter_time=113.159s
2025-08-08 12:35:44 Train INFO: [Train]: [019][00040/00051] (78.8%)  Loss=0.9812  cls_loss=0.6794  reg_loss=0.3017  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=291s  iter_time=154.603s
2025-08-08 12:37:31 Train INFO: [Train]: [019][00045/00051] (88.5%)  Loss=0.9944  cls_loss=0.6888  reg_loss=0.3056  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=107.052s
2025-08-08 12:39:13 Train INFO: [Train]: [019][00050/00051] (98.1%)  Loss=0.9975  cls_loss=0.6911  reg_loss=0.3064  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=102.039s
2025-08-08 12:39:24 Train INFO: [Train]: [019][00051/00051] (100.0%)  Loss=0.9988  cls_loss=0.6920  reg_loss=0.3067  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.531s
2025-08-08 12:39:24 Train INFO: [Train]: Epoch 19 completed in 1304.7s (avg 25.089s/iter)
2025-08-08 12:39:24 Train INFO: [Train]: Final Loss=0.9988
2025-08-08 12:39:25 Train INFO: [Val]: Epoch 19 Loss
2025-08-08 13:31:18 Train INFO: [Val]: [019]  Loss=1.1627  cls_loss=0.8494  reg_loss=0.3133  Average-mAP=0.78%
2025-08-08 13:31:20 Train INFO: Checkpoint saved at epoch 19
2025-08-08 13:31:20 Train INFO: [Train]: Epoch 20 started (Total iterations: 52)
2025-08-08 13:35:10 Train INFO: [Train]: [020][00005/00051] (11.5%)  Loss=0.9453  cls_loss=0.6509  reg_loss=0.2944  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1767s  iter_time=230.537s  fwd=2.212s/bwd=4.652s/opt=3.313s
2025-08-08 13:36:59 Train INFO: [Train]: [020][00010/00051] (21.2%)  Loss=0.9576  cls_loss=0.6607  reg_loss=0.2969  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1264s  iter_time=108.495s
2025-08-08 13:38:37 Train INFO: [Train]: [020][00015/00051] (30.8%)  Loss=0.9448  cls_loss=0.6516  reg_loss=0.2932  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=985s  iter_time=98.605s
2025-08-08 13:41:03 Train INFO: [Train]: [020][00020/00051] (40.4%)  Loss=0.9628  cls_loss=0.6650  reg_loss=0.2978  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=860s  iter_time=145.132s
2025-08-08 13:42:45 Train INFO: [Train]: [020][00025/00051] (50.0%)  Loss=0.9545  cls_loss=0.6590  reg_loss=0.2955  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=685s  iter_time=102.307s
2025-08-08 13:44:28 Train INFO: [Train]: [020][00030/00051] (59.6%)  Loss=0.9534  cls_loss=0.6599  reg_loss=0.2935  lr_backbone=9.6e-06  lr_det=9.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=103.286s
2025-08-08 13:46:14 Train INFO: [Train]: [020][00035/00051] (69.2%)  Loss=0.9618  cls_loss=0.6651  reg_loss=0.2967  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=105.907s
2025-08-08 13:48:46 Train INFO: [Train]: [020][00040/00051] (78.8%)  Loss=0.9707  cls_loss=0.6710  reg_loss=0.2997  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=151.418s
2025-08-08 13:50:30 Train INFO: [Train]: [020][00045/00051] (88.5%)  Loss=0.9749  cls_loss=0.6737  reg_loss=0.3012  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=104.967s
2025-08-08 13:52:11 Train INFO: [Train]: [020][00050/00051] (98.1%)  Loss=0.9764  cls_loss=0.6741  reg_loss=0.3023  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.040s
2025-08-08 13:52:21 Train INFO: [Train]: [020][00051/00051] (100.0%)  Loss=0.9733  cls_loss=0.6719  reg_loss=0.3014  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.831s
2025-08-08 13:52:23 Train INFO: [Train]: Epoch 20 completed in 1262.8s (avg 24.284s/iter)
2025-08-08 13:52:23 Train INFO: [Train]: Final Loss=0.9733
2025-08-08 13:52:23 Train INFO: [Train]: Epoch 21 started (Total iterations: 52)
2025-08-08 13:56:18 Train INFO: [Train]: [021][00005/00051] (11.5%)  Loss=0.9541  cls_loss=0.6638  reg_loss=0.2903  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1804s  iter_time=235.366s  fwd=2.042s/bwd=4.295s/opt=3.067s
2025-08-08 13:58:01 Train INFO: [Train]: [021][00010/00051] (21.2%)  Loss=0.9984  cls_loss=0.6935  reg_loss=0.3049  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1260s  iter_time=102.587s
2025-08-08 13:59:47 Train INFO: [Train]: [021][00015/00051] (30.8%)  Loss=1.0247  cls_loss=0.7100  reg_loss=0.3147  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1001s  iter_time=106.858s
2025-08-08 14:02:23 Train INFO: [Train]: [021][00020/00051] (40.4%)  Loss=1.0122  cls_loss=0.6984  reg_loss=0.3138  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=886s  iter_time=155.210s
2025-08-08 14:04:09 Train INFO: [Train]: [021][00025/00051] (50.0%)  Loss=1.0088  cls_loss=0.6965  reg_loss=0.3123  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=706s  iter_time=105.966s
2025-08-08 14:05:56 Train INFO: [Train]: [021][00030/00051] (59.6%)  Loss=1.0076  cls_loss=0.6938  reg_loss=0.3138  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=551s  iter_time=106.922s
2025-08-08 14:07:39 Train INFO: [Train]: [021][00035/00051] (69.2%)  Loss=1.0113  cls_loss=0.6967  reg_loss=0.3147  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=407s  iter_time=103.734s
2025-08-08 14:10:13 Train INFO: [Train]: [021][00040/00051] (78.8%)  Loss=1.0030  cls_loss=0.6919  reg_loss=0.3111  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=153.650s
2025-08-08 14:12:02 Train INFO: [Train]: [021][00045/00051] (88.5%)  Loss=0.9980  cls_loss=0.6887  reg_loss=0.3093  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=109.209s
2025-08-08 14:13:35 Train INFO: [Train]: [021][00050/00051] (98.1%)  Loss=0.9922  cls_loss=0.6848  reg_loss=0.3074  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=93.389s
2025-08-08 14:13:46 Train INFO: [Train]: [021][00051/00051] (100.0%)  Loss=0.9902  cls_loss=0.6833  reg_loss=0.3069  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.412s
2025-08-08 14:13:47 Train INFO: [Train]: Epoch 21 completed in 1284.1s (avg 24.694s/iter)
2025-08-08 14:13:47 Train INFO: [Train]: Final Loss=0.9902
2025-08-08 14:13:47 Train INFO: [Train]: Epoch 22 started (Total iterations: 52)
2025-08-08 14:17:36 Train INFO: [Train]: [022][00005/00051] (11.5%)  Loss=0.9149  cls_loss=0.6368  reg_loss=0.2781  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1755s  iter_time=228.962s  fwd=2.110s/bwd=4.366s/opt=3.140s
2025-08-08 14:19:31 Train INFO: [Train]: [022][00010/00051] (21.2%)  Loss=0.9643  cls_loss=0.6678  reg_loss=0.2965  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1285s  iter_time=115.746s
2025-08-08 14:21:18 Train INFO: [Train]: [022][00015/00051] (30.8%)  Loss=0.9662  cls_loss=0.6682  reg_loss=0.2980  lr_backbone=9.5e-06  lr_det=9.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1016s  iter_time=106.669s
2025-08-08 14:23:51 Train INFO: [Train]: [022][00020/00051] (40.4%)  Loss=0.9819  cls_loss=0.6768  reg_loss=0.3050  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=893s  iter_time=153.278s
2025-08-08 14:25:38 Train INFO: [Train]: [022][00025/00051] (50.0%)  Loss=0.9933  cls_loss=0.6850  reg_loss=0.3083  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=711s  iter_time=106.677s
2025-08-08 14:27:25 Train INFO: [Train]: [022][00030/00051] (59.6%)  Loss=0.9920  cls_loss=0.6846  reg_loss=0.3074  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=554s  iter_time=107.137s
2025-08-08 14:29:12 Train INFO: [Train]: [022][00035/00051] (69.2%)  Loss=0.9795  cls_loss=0.6771  reg_loss=0.3024  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=411s  iter_time=107.078s
2025-08-08 14:31:37 Train INFO: [Train]: [022][00040/00051] (78.8%)  Loss=0.9812  cls_loss=0.6779  reg_loss=0.3033  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=144.450s
2025-08-08 14:33:27 Train INFO: [Train]: [022][00045/00051] (88.5%)  Loss=0.9913  cls_loss=0.6848  reg_loss=0.3065  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=110.558s
2025-08-08 14:35:25 Train INFO: [Train]: [022][00050/00051] (98.1%)  Loss=0.9796  cls_loss=0.6770  reg_loss=0.3026  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=117.376s
2025-08-08 14:35:35 Train INFO: [Train]: [022][00051/00051] (100.0%)  Loss=0.9781  cls_loss=0.6758  reg_loss=0.3023  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.739s
2025-08-08 14:35:36 Train INFO: [Train]: Epoch 22 completed in 1309.4s (avg 25.181s/iter)
2025-08-08 14:35:36 Train INFO: [Train]: Final Loss=0.9781
2025-08-08 14:35:36 Train INFO: [Train]: Epoch 23 started (Total iterations: 52)
2025-08-08 14:39:30 Train INFO: [Train]: [023][00005/00051] (11.5%)  Loss=1.0289  cls_loss=0.7212  reg_loss=0.3077  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1796s  iter_time=234.262s  fwd=2.139s/bwd=4.360s/opt=3.097s
2025-08-08 14:41:13 Train INFO: [Train]: [023][00010/00051] (21.2%)  Loss=1.0351  cls_loss=0.7239  reg_loss=0.3112  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1257s  iter_time=102.915s
2025-08-08 14:43:02 Train INFO: [Train]: [023][00015/00051] (30.8%)  Loss=1.0111  cls_loss=0.7048  reg_loss=0.3063  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1004s  iter_time=108.972s
2025-08-08 14:45:36 Train INFO: [Train]: [023][00020/00051] (40.4%)  Loss=1.0037  cls_loss=0.6982  reg_loss=0.3055  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=886s  iter_time=154.176s
2025-08-08 14:47:23 Train INFO: [Train]: [023][00025/00051] (50.0%)  Loss=0.9991  cls_loss=0.6945  reg_loss=0.3047  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=707s  iter_time=107.012s
2025-08-08 14:49:06 Train INFO: [Train]: [023][00030/00051] (59.6%)  Loss=1.0035  cls_loss=0.6981  reg_loss=0.3054  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=548s  iter_time=102.079s
2025-08-08 14:50:51 Train INFO: [Train]: [023][00035/00051] (69.2%)  Loss=1.0056  cls_loss=0.6992  reg_loss=0.3065  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=406s  iter_time=105.081s
2025-08-08 14:53:27 Train INFO: [Train]: [023][00040/00051] (78.8%)  Loss=1.0002  cls_loss=0.6951  reg_loss=0.3051  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=156.678s
2025-08-08 14:55:07 Train INFO: [Train]: [023][00045/00051] (88.5%)  Loss=0.9986  cls_loss=0.6937  reg_loss=0.3049  lr_backbone=9.4e-06  lr_det=9.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=99.910s
2025-08-08 14:56:55 Train INFO: [Train]: [023][00050/00051] (98.1%)  Loss=0.9940  cls_loss=0.6904  reg_loss=0.3036  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=107.809s
2025-08-08 14:57:05 Train INFO: [Train]: [023][00051/00051] (100.0%)  Loss=0.9939  cls_loss=0.6899  reg_loss=0.3040  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.359s
2025-08-08 14:57:06 Train INFO: [Train]: Epoch 23 completed in 1290.0s (avg 24.807s/iter)
2025-08-08 14:57:06 Train INFO: [Train]: Final Loss=0.9939
2025-08-08 14:57:06 Train INFO: [Train]: Epoch 24 started (Total iterations: 52)
2025-08-08 15:00:51 Train INFO: [Train]: [024][00005/00051] (11.5%)  Loss=0.9651  cls_loss=0.6671  reg_loss=0.2980  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1727s  iter_time=225.208s  fwd=2.068s/bwd=4.307s/opt=3.081s
2025-08-08 15:02:30 Train INFO: [Train]: [024][00010/00051] (21.2%)  Loss=0.9589  cls_loss=0.6612  reg_loss=0.2978  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1206s  iter_time=98.481s
2025-08-08 15:04:18 Train INFO: [Train]: [024][00015/00051] (30.8%)  Loss=1.0090  cls_loss=0.6999  reg_loss=0.3091  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=972s  iter_time=108.432s
2025-08-08 15:06:52 Train INFO: [Train]: [024][00020/00051] (40.4%)  Loss=1.0183  cls_loss=0.7072  reg_loss=0.3111  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=864s  iter_time=153.418s
2025-08-08 15:08:49 Train INFO: [Train]: [024][00025/00051] (50.0%)  Loss=1.0173  cls_loss=0.7075  reg_loss=0.3098  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=703s  iter_time=117.325s
2025-08-08 15:10:27 Train INFO: [Train]: [024][00030/00051] (59.6%)  Loss=1.0115  cls_loss=0.7027  reg_loss=0.3088  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=542s  iter_time=97.682s
2025-08-08 15:12:11 Train INFO: [Train]: [024][00035/00051] (69.2%)  Loss=1.0041  cls_loss=0.6977  reg_loss=0.3064  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=104.591s
2025-08-08 15:14:40 Train INFO: [Train]: [024][00040/00051] (78.8%)  Loss=1.0049  cls_loss=0.6970  reg_loss=0.3079  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=148.496s
2025-08-08 15:16:27 Train INFO: [Train]: [024][00045/00051] (88.5%)  Loss=0.9985  cls_loss=0.6925  reg_loss=0.3060  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=107.337s
2025-08-08 15:18:15 Train INFO: [Train]: [024][00050/00051] (98.1%)  Loss=0.9981  cls_loss=0.6914  reg_loss=0.3067  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=108.065s
2025-08-08 15:18:26 Train INFO: [Train]: [024][00051/00051] (100.0%)  Loss=1.0014  cls_loss=0.6938  reg_loss=0.3076  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.760s
2025-08-08 15:18:27 Train INFO: [Train]: Epoch 24 completed in 1281.1s (avg 24.637s/iter)
2025-08-08 15:18:27 Train INFO: [Train]: Final Loss=1.0014
2025-08-08 15:18:27 Train INFO: [Val]: Epoch 24 Loss
2025-08-08 16:13:13 Train INFO: [Val]: [024]  Loss=1.0726  cls_loss=0.7593  reg_loss=0.3133  Average-mAP=0.83%
2025-08-08 16:13:15 Train INFO: Checkpoint saved at epoch 24
2025-08-08 16:13:15 Train INFO: [Train]: Epoch 25 started (Total iterations: 52)
2025-08-08 16:17:05 Train INFO: [Train]: [025][00005/00051] (11.5%)  Loss=0.9973  cls_loss=0.6855  reg_loss=0.3118  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1762s  iter_time=229.863s  fwd=2.062s/bwd=4.310s/opt=3.087s
2025-08-08 16:18:54 Train INFO: [Train]: [025][00010/00051] (21.2%)  Loss=0.9419  cls_loss=0.6518  reg_loss=0.2901  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1264s  iter_time=109.390s
2025-08-08 16:20:45 Train INFO: [Train]: [025][00015/00051] (30.8%)  Loss=0.9736  cls_loss=0.6746  reg_loss=0.2991  lr_backbone=9.3e-06  lr_det=9.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1012s  iter_time=110.455s
2025-08-08 16:23:15 Train INFO: [Train]: [025][00020/00051] (40.4%)  Loss=0.9767  cls_loss=0.6754  reg_loss=0.3013  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=885s  iter_time=149.993s
2025-08-08 16:25:04 Train INFO: [Train]: [025][00025/00051] (50.0%)  Loss=0.9732  cls_loss=0.6728  reg_loss=0.3004  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=709s  iter_time=108.853s
2025-08-08 16:27:00 Train INFO: [Train]: [025][00030/00051] (59.6%)  Loss=0.9775  cls_loss=0.6776  reg_loss=0.3000  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=559s  iter_time=116.593s
2025-08-08 16:28:55 Train INFO: [Train]: [025][00035/00051] (69.2%)  Loss=0.9730  cls_loss=0.6740  reg_loss=0.2991  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=418s  iter_time=114.934s
2025-08-08 16:31:15 Train INFO: [Train]: [025][00040/00051] (78.8%)  Loss=0.9716  cls_loss=0.6734  reg_loss=0.2982  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=290s  iter_time=140.156s
2025-08-08 16:33:22 Train INFO: [Train]: [025][00045/00051] (88.5%)  Loss=0.9761  cls_loss=0.6755  reg_loss=0.3006  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=157s  iter_time=126.484s
2025-08-08 16:35:01 Train INFO: [Train]: [025][00050/00051] (98.1%)  Loss=0.9707  cls_loss=0.6717  reg_loss=0.2990  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=99.544s
2025-08-08 16:35:12 Train INFO: [Train]: [025][00051/00051] (100.0%)  Loss=0.9637  cls_loss=0.6670  reg_loss=0.2967  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=11.037s
2025-08-08 16:35:13 Train INFO: [Train]: Epoch 25 completed in 1318.4s (avg 25.355s/iter)
2025-08-08 16:35:13 Train INFO: [Train]: Final Loss=0.9637
2025-08-08 16:35:13 Train INFO: [Train]: Epoch 26 started (Total iterations: 52)
2025-08-08 16:39:11 Train INFO: [Train]: [026][00005/00051] (11.5%)  Loss=1.0645  cls_loss=0.7468  reg_loss=0.3177  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1820s  iter_time=237.445s  fwd=2.076s/bwd=4.317s/opt=3.091s
2025-08-08 16:40:59 Train INFO: [Train]: [026][00010/00051] (21.2%)  Loss=1.0356  cls_loss=0.7282  reg_loss=0.3074  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1288s  iter_time=108.152s
2025-08-08 16:42:46 Train INFO: [Train]: [026][00015/00051] (30.8%)  Loss=1.0202  cls_loss=0.7161  reg_loss=0.3041  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1019s  iter_time=107.390s
2025-08-08 16:45:21 Train INFO: [Train]: [026][00020/00051] (40.4%)  Loss=1.0079  cls_loss=0.7085  reg_loss=0.2994  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=897s  iter_time=154.740s
2025-08-08 16:47:08 Train INFO: [Train]: [026][00025/00051] (50.0%)  Loss=1.0097  cls_loss=0.7082  reg_loss=0.3016  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=714s  iter_time=106.722s
2025-08-08 16:48:56 Train INFO: [Train]: [026][00030/00051] (59.6%)  Loss=1.0000  cls_loss=0.7026  reg_loss=0.2974  lr_backbone=9.2e-06  lr_det=9.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=557s  iter_time=108.325s
2025-08-08 16:50:40 Train INFO: [Train]: [026][00035/00051] (69.2%)  Loss=0.9966  cls_loss=0.7002  reg_loss=0.2964  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=412s  iter_time=103.811s
2025-08-08 16:53:19 Train INFO: [Train]: [026][00040/00051] (78.8%)  Loss=1.0019  cls_loss=0.7027  reg_loss=0.2993  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=291s  iter_time=158.864s
2025-08-08 16:55:06 Train INFO: [Train]: [026][00045/00051] (88.5%)  Loss=0.9995  cls_loss=0.7011  reg_loss=0.2983  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=156s  iter_time=106.721s
2025-08-08 16:57:00 Train INFO: [Train]: [026][00050/00051] (98.1%)  Loss=0.9987  cls_loss=0.7004  reg_loss=0.2983  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=114.587s
2025-08-08 16:57:11 Train INFO: [Train]: [026][00051/00051] (100.0%)  Loss=0.9977  cls_loss=0.6994  reg_loss=0.2983  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.888s
2025-08-08 16:57:12 Train INFO: [Train]: Epoch 26 completed in 1318.6s (avg 25.358s/iter)
2025-08-08 16:57:12 Train INFO: [Train]: Final Loss=0.9977
2025-08-08 16:57:12 Train INFO: [Train]: Epoch 27 started (Total iterations: 52)
2025-08-08 17:01:20 Train INFO: [Train]: [027][00005/00051] (11.5%)  Loss=0.9662  cls_loss=0.6685  reg_loss=0.2978  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1901s  iter_time=248.008s  fwd=2.077s/bwd=4.295s/opt=3.100s
2025-08-08 17:03:01 Train INFO: [Train]: [027][00010/00051] (21.2%)  Loss=0.9535  cls_loss=0.6626  reg_loss=0.2909  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1300s  iter_time=100.827s
2025-08-08 17:04:51 Train INFO: [Train]: [027][00015/00051] (30.8%)  Loss=0.9875  cls_loss=0.6860  reg_loss=0.3015  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1032s  iter_time=109.788s
2025-08-08 17:07:31 Train INFO: [Train]: [027][00020/00051] (40.4%)  Loss=0.9623  cls_loss=0.6675  reg_loss=0.2948  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=914s  iter_time=160.347s
2025-08-08 17:09:13 Train INFO: [Train]: [027][00025/00051] (50.0%)  Loss=0.9753  cls_loss=0.6777  reg_loss=0.2976  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=721s  iter_time=102.176s
2025-08-08 17:11:10 Train INFO: [Train]: [027][00030/00051] (59.6%)  Loss=0.9762  cls_loss=0.6793  reg_loss=0.2969  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=567s  iter_time=116.315s
2025-08-08 17:13:03 Train INFO: [Train]: [027][00035/00051] (69.2%)  Loss=0.9757  cls_loss=0.6785  reg_loss=0.2972  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=423s  iter_time=113.317s
2025-08-08 17:15:41 Train INFO: [Train]: [027][00040/00051] (78.8%)  Loss=0.9677  cls_loss=0.6734  reg_loss=0.2943  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=298s  iter_time=158.230s
2025-08-08 17:17:18 Train INFO: [Train]: [027][00045/00051] (88.5%)  Loss=0.9731  cls_loss=0.6761  reg_loss=0.2970  lr_backbone=9.1e-06  lr_det=9.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=157s  iter_time=97.089s
2025-08-08 17:19:04 Train INFO: [Train]: [027][00050/00051] (98.1%)  Loss=0.9787  cls_loss=0.6795  reg_loss=0.2993  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=105.380s
2025-08-08 17:19:14 Train INFO: [Train]: [027][00051/00051] (100.0%)  Loss=0.9823  cls_loss=0.6819  reg_loss=0.3004  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.352s
2025-08-08 17:19:15 Train INFO: [Train]: Epoch 27 completed in 1322.6s (avg 25.434s/iter)
2025-08-08 17:19:15 Train INFO: [Train]: Final Loss=0.9823
2025-08-08 17:19:15 Train INFO: [Train]: Epoch 28 started (Total iterations: 52)
2025-08-08 17:23:17 Train INFO: [Train]: [028][00005/00051] (11.5%)  Loss=0.9943  cls_loss=0.7023  reg_loss=0.2920  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1856s  iter_time=242.138s  fwd=2.055s/bwd=4.278s/opt=3.083s
2025-08-08 17:24:59 Train INFO: [Train]: [028][00010/00051] (21.2%)  Loss=0.9932  cls_loss=0.6982  reg_loss=0.2950  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1282s  iter_time=101.812s
2025-08-08 17:26:39 Train INFO: [Train]: [028][00015/00051] (30.8%)  Loss=0.9789  cls_loss=0.6854  reg_loss=0.2936  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1000s  iter_time=100.559s
2025-08-08 17:29:18 Train INFO: [Train]: [028][00020/00051] (40.4%)  Loss=0.9670  cls_loss=0.6748  reg_loss=0.2922  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=891s  iter_time=159.168s
2025-08-08 17:30:57 Train INFO: [Train]: [028][00025/00051] (50.0%)  Loss=0.9655  cls_loss=0.6737  reg_loss=0.2918  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=703s  iter_time=99.146s
2025-08-08 17:32:36 Train INFO: [Train]: [028][00030/00051] (59.6%)  Loss=0.9759  cls_loss=0.6790  reg_loss=0.2969  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=98.989s
2025-08-08 17:34:23 Train INFO: [Train]: [028][00035/00051] (69.2%)  Loss=0.9885  cls_loss=0.6869  reg_loss=0.3016  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=404s  iter_time=106.105s
2025-08-08 17:36:49 Train INFO: [Train]: [028][00040/00051] (78.8%)  Loss=0.9861  cls_loss=0.6847  reg_loss=0.3014  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=146.107s
2025-08-08 17:38:38 Train INFO: [Train]: [028][00045/00051] (88.5%)  Loss=0.9912  cls_loss=0.6884  reg_loss=0.3028  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=109.593s
2025-08-08 17:40:23 Train INFO: [Train]: [028][00050/00051] (98.1%)  Loss=0.9926  cls_loss=0.6898  reg_loss=0.3028  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.423s
2025-08-08 17:40:33 Train INFO: [Train]: [028][00051/00051] (100.0%)  Loss=0.9861  cls_loss=0.6852  reg_loss=0.3009  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.355s
2025-08-08 17:40:34 Train INFO: [Train]: Epoch 28 completed in 1279.3s (avg 24.602s/iter)
2025-08-08 17:40:34 Train INFO: [Train]: Final Loss=0.9861
2025-08-08 17:40:34 Train INFO: [Train]: Epoch 29 started (Total iterations: 52)
2025-08-08 17:44:22 Train INFO: [Train]: [029][00005/00051] (11.5%)  Loss=0.9959  cls_loss=0.6825  reg_loss=0.3134  lr_backbone=9.0e-06  lr_det=9.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1748s  iter_time=227.988s  fwd=2.070s/bwd=4.267s/opt=3.075s
2025-08-08 17:46:00 Train INFO: [Train]: [029][00010/00051] (21.2%)  Loss=0.9660  cls_loss=0.6691  reg_loss=0.2969  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1217s  iter_time=98.576s
2025-08-08 17:47:48 Train INFO: [Train]: [029][00015/00051] (30.8%)  Loss=0.9899  cls_loss=0.6869  reg_loss=0.3030  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=978s  iter_time=108.016s
2025-08-08 17:50:26 Train INFO: [Train]: [029][00020/00051] (40.4%)  Loss=0.9639  cls_loss=0.6692  reg_loss=0.2946  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=874s  iter_time=157.765s
2025-08-08 17:52:05 Train INFO: [Train]: [029][00025/00051] (50.0%)  Loss=0.9839  cls_loss=0.6823  reg_loss=0.3016  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=98.304s
2025-08-08 17:53:42 Train INFO: [Train]: [029][00030/00051] (59.6%)  Loss=0.9684  cls_loss=0.6717  reg_loss=0.2966  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=97.606s
2025-08-08 17:55:27 Train INFO: [Train]: [029][00035/00051] (69.2%)  Loss=0.9673  cls_loss=0.6709  reg_loss=0.2964  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=104.560s
2025-08-08 17:58:07 Train INFO: [Train]: [029][00040/00051] (78.8%)  Loss=0.9725  cls_loss=0.6735  reg_loss=0.2989  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=160.228s
2025-08-08 17:59:50 Train INFO: [Train]: [029][00045/00051] (88.5%)  Loss=0.9705  cls_loss=0.6716  reg_loss=0.2990  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=103.502s
2025-08-08 18:01:23 Train INFO: [Train]: [029][00050/00051] (98.1%)  Loss=0.9741  cls_loss=0.6746  reg_loss=0.2995  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=92.763s
2025-08-08 18:01:34 Train INFO: [Train]: [029][00051/00051] (100.0%)  Loss=0.9737  cls_loss=0.6743  reg_loss=0.2994  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.385s
2025-08-08 18:01:34 Train INFO: [Train]: Epoch 29 completed in 1260.4s (avg 24.238s/iter)
2025-08-08 18:01:34 Train INFO: [Train]: Final Loss=0.9737
2025-08-08 18:01:34 Train INFO: [Val]: Epoch 29 Loss
2025-08-08 18:50:46 Train INFO: [Val]: [029]  Loss=1.0344  cls_loss=0.7210  reg_loss=0.3134  Average-mAP=0.69%
2025-08-08 18:50:48 Train INFO: Checkpoint saved at epoch 29
2025-08-08 18:50:48 Train INFO: [Train]: Epoch 30 started (Total iterations: 52)
2025-08-08 18:54:27 Train INFO: [Train]: [030][00005/00051] (11.5%)  Loss=0.9815  cls_loss=0.6873  reg_loss=0.2942  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1676s  iter_time=218.585s  fwd=2.103s/bwd=4.315s/opt=3.069s
2025-08-08 18:56:05 Train INFO: [Train]: [030][00010/00051] (21.2%)  Loss=0.9767  cls_loss=0.6818  reg_loss=0.2949  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1179s  iter_time=97.722s
2025-08-08 18:57:48 Train INFO: [Train]: [030][00015/00051] (30.8%)  Loss=0.9839  cls_loss=0.6857  reg_loss=0.2981  lr_backbone=8.9e-06  lr_det=8.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=945s  iter_time=103.808s
2025-08-08 19:00:12 Train INFO: [Train]: [030][00020/00051] (40.4%)  Loss=0.9808  cls_loss=0.6820  reg_loss=0.2988  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=832s  iter_time=143.240s
2025-08-08 19:02:01 Train INFO: [Train]: [030][00025/00051] (50.0%)  Loss=0.9843  cls_loss=0.6841  reg_loss=0.3002  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=672s  iter_time=109.136s
2025-08-08 19:03:47 Train INFO: [Train]: [030][00030/00051] (59.6%)  Loss=1.0000  cls_loss=0.6940  reg_loss=0.3059  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=527s  iter_time=105.831s
2025-08-08 19:05:30 Train INFO: [Train]: [030][00035/00051] (69.2%)  Loss=0.9860  cls_loss=0.6842  reg_loss=0.3017  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=392s  iter_time=103.318s
2025-08-08 19:08:02 Train INFO: [Train]: [030][00040/00051] (78.8%)  Loss=0.9879  cls_loss=0.6861  reg_loss=0.3018  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=152.043s
2025-08-08 19:09:53 Train INFO: [Train]: [030][00045/00051] (88.5%)  Loss=0.9877  cls_loss=0.6863  reg_loss=0.3014  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=111.477s
2025-08-08 19:11:37 Train INFO: [Train]: [030][00050/00051] (98.1%)  Loss=0.9901  cls_loss=0.6873  reg_loss=0.3028  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=103.152s
2025-08-08 19:11:47 Train INFO: [Train]: [030][00051/00051] (100.0%)  Loss=0.9876  cls_loss=0.6859  reg_loss=0.3017  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.357s
2025-08-08 19:11:48 Train INFO: [Train]: Epoch 30 completed in 1259.4s (avg 24.220s/iter)
2025-08-08 19:11:48 Train INFO: [Train]: Final Loss=0.9876
2025-08-08 19:11:48 Train INFO: [Train]: Epoch 31 started (Total iterations: 52)
2025-08-08 19:15:41 Train INFO: [Train]: [031][00005/00051] (11.5%)  Loss=0.8990  cls_loss=0.6223  reg_loss=0.2766  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1786s  iter_time=232.949s  fwd=2.067s/bwd=4.346s/opt=3.070s
2025-08-08 19:17:23 Train INFO: [Train]: [031][00010/00051] (21.2%)  Loss=0.9649  cls_loss=0.6736  reg_loss=0.2912  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1249s  iter_time=102.250s
2025-08-08 19:19:11 Train INFO: [Train]: [031][00015/00051] (30.8%)  Loss=1.0001  cls_loss=0.7028  reg_loss=0.2973  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=997s  iter_time=107.832s
2025-08-08 19:21:39 Train INFO: [Train]: [031][00020/00051] (40.4%)  Loss=0.9969  cls_loss=0.6960  reg_loss=0.3009  lr_backbone=8.8e-06  lr_det=8.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=872s  iter_time=147.909s
2025-08-08 19:23:19 Train INFO: [Train]: [031][00025/00051] (50.0%)  Loss=0.9742  cls_loss=0.6792  reg_loss=0.2950  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=100.317s
2025-08-08 19:25:00 Train INFO: [Train]: [031][00030/00051] (59.6%)  Loss=0.9716  cls_loss=0.6769  reg_loss=0.2947  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=537s  iter_time=100.848s
2025-08-08 19:26:45 Train INFO: [Train]: [031][00035/00051] (69.2%)  Loss=0.9728  cls_loss=0.6761  reg_loss=0.2967  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=104.810s
2025-08-08 19:29:22 Train INFO: [Train]: [031][00040/00051] (78.8%)  Loss=0.9755  cls_loss=0.6779  reg_loss=0.2976  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=157.711s
2025-08-08 19:31:05 Train INFO: [Train]: [031][00045/00051] (88.5%)  Loss=0.9805  cls_loss=0.6810  reg_loss=0.2995  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=102.937s
2025-08-08 19:32:40 Train INFO: [Train]: [031][00050/00051] (98.1%)  Loss=0.9792  cls_loss=0.6807  reg_loss=0.2985  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=95.216s
2025-08-08 19:32:51 Train INFO: [Train]: [031][00051/00051] (100.0%)  Loss=0.9779  cls_loss=0.6794  reg_loss=0.2985  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.370s
2025-08-08 19:32:52 Train INFO: [Train]: Epoch 31 completed in 1263.9s (avg 24.305s/iter)
2025-08-08 19:32:52 Train INFO: [Train]: Final Loss=0.9779
2025-08-08 19:32:52 Train INFO: [Train]: Epoch 32 started (Total iterations: 52)
2025-08-08 19:36:39 Train INFO: [Train]: [032][00005/00051] (11.5%)  Loss=1.0115  cls_loss=0.6992  reg_loss=0.3123  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1745s  iter_time=227.600s  fwd=2.068s/bwd=4.308s/opt=3.082s
2025-08-08 19:38:16 Train INFO: [Train]: [032][00010/00051] (21.2%)  Loss=0.9927  cls_loss=0.6889  reg_loss=0.3038  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1209s  iter_time=96.891s
2025-08-08 19:39:57 Train INFO: [Train]: [032][00015/00051] (30.8%)  Loss=1.0117  cls_loss=0.7026  reg_loss=0.3092  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=958s  iter_time=101.190s
2025-08-08 19:42:35 Train INFO: [Train]: [032][00020/00051] (40.4%)  Loss=0.9952  cls_loss=0.6873  reg_loss=0.3079  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=861s  iter_time=157.264s
2025-08-08 19:44:22 Train INFO: [Train]: [032][00025/00051] (50.0%)  Loss=0.9777  cls_loss=0.6764  reg_loss=0.3013  lr_backbone=8.7e-06  lr_det=8.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=107.594s
2025-08-08 19:46:10 Train INFO: [Train]: [032][00030/00051] (59.6%)  Loss=0.9971  cls_loss=0.6907  reg_loss=0.3064  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=108.358s
2025-08-08 19:47:48 Train INFO: [Train]: [032][00035/00051] (69.2%)  Loss=0.9974  cls_loss=0.6911  reg_loss=0.3063  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=97.984s
2025-08-08 19:50:10 Train INFO: [Train]: [032][00040/00051] (78.8%)  Loss=0.9933  cls_loss=0.6877  reg_loss=0.3055  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=141.214s
2025-08-08 19:51:58 Train INFO: [Train]: [032][00045/00051] (88.5%)  Loss=0.9958  cls_loss=0.6903  reg_loss=0.3055  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=108.060s
2025-08-08 19:53:34 Train INFO: [Train]: [032][00050/00051] (98.1%)  Loss=0.9885  cls_loss=0.6857  reg_loss=0.3027  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.382s
2025-08-08 19:53:44 Train INFO: [Train]: [032][00051/00051] (100.0%)  Loss=0.9901  cls_loss=0.6869  reg_loss=0.3032  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.366s
2025-08-08 19:53:45 Train INFO: [Train]: Epoch 32 completed in 1253.6s (avg 24.108s/iter)
2025-08-08 19:53:45 Train INFO: [Train]: Final Loss=0.9901
2025-08-08 19:53:45 Train INFO: [Train]: Epoch 33 started (Total iterations: 52)
2025-08-08 19:57:34 Train INFO: [Train]: [033][00005/00051] (11.5%)  Loss=0.9063  cls_loss=0.6262  reg_loss=0.2800  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1752s  iter_time=228.494s  fwd=2.074s/bwd=4.279s/opt=3.078s
2025-08-08 19:59:13 Train INFO: [Train]: [033][00010/00051] (21.2%)  Loss=0.9093  cls_loss=0.6329  reg_loss=0.2765  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1223s  iter_time=99.743s
2025-08-08 20:01:05 Train INFO: [Train]: [033][00015/00051] (30.8%)  Loss=0.9553  cls_loss=0.6631  reg_loss=0.2922  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=990s  iter_time=111.668s
2025-08-08 20:03:37 Train INFO: [Train]: [033][00020/00051] (40.4%)  Loss=0.9502  cls_loss=0.6597  reg_loss=0.2905  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=873s  iter_time=151.541s
2025-08-08 20:05:27 Train INFO: [Train]: [033][00025/00051] (50.0%)  Loss=0.9635  cls_loss=0.6702  reg_loss=0.2933  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=702s  iter_time=110.254s
2025-08-08 20:07:08 Train INFO: [Train]: [033][00030/00051] (59.6%)  Loss=0.9758  cls_loss=0.6786  reg_loss=0.2972  lr_backbone=8.6e-06  lr_det=8.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=544s  iter_time=101.336s
2025-08-08 20:08:46 Train INFO: [Train]: [033][00035/00051] (69.2%)  Loss=0.9786  cls_loss=0.6794  reg_loss=0.2992  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=97.321s
2025-08-08 20:11:11 Train INFO: [Train]: [033][00040/00051] (78.8%)  Loss=0.9762  cls_loss=0.6770  reg_loss=0.2991  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=145.795s
2025-08-08 20:12:50 Train INFO: [Train]: [033][00045/00051] (88.5%)  Loss=0.9821  cls_loss=0.6811  reg_loss=0.3011  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=99.106s
2025-08-08 20:14:24 Train INFO: [Train]: [033][00050/00051] (98.1%)  Loss=0.9723  cls_loss=0.6743  reg_loss=0.2981  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=93.527s
2025-08-08 20:14:34 Train INFO: [Train]: [033][00051/00051] (100.0%)  Loss=0.9720  cls_loss=0.6737  reg_loss=0.2983  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.367s
2025-08-08 20:14:35 Train INFO: [Train]: Epoch 33 completed in 1249.9s (avg 24.036s/iter)
2025-08-08 20:14:35 Train INFO: [Train]: Final Loss=0.9720
2025-08-08 20:14:35 Train INFO: [Train]: Epoch 34 started (Total iterations: 52)
2025-08-08 20:18:25 Train INFO: [Train]: [034][00005/00051] (11.5%)  Loss=1.0067  cls_loss=0.6960  reg_loss=0.3107  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1762s  iter_time=229.806s  fwd=2.048s/bwd=4.279s/opt=3.075s
2025-08-08 20:20:11 Train INFO: [Train]: [034][00010/00051] (21.2%)  Loss=0.9963  cls_loss=0.6928  reg_loss=0.3035  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1251s  iter_time=105.793s
2025-08-08 20:21:52 Train INFO: [Train]: [034][00015/00051] (30.8%)  Loss=0.9641  cls_loss=0.6712  reg_loss=0.2928  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=983s  iter_time=101.328s
2025-08-08 20:24:44 Train INFO: [Train]: [034][00020/00051] (40.4%)  Loss=0.9758  cls_loss=0.6764  reg_loss=0.2994  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=898s  iter_time=171.660s
2025-08-08 20:26:25 Train INFO: [Train]: [034][00025/00051] (50.0%)  Loss=0.9829  cls_loss=0.6809  reg_loss=0.3021  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=710s  iter_time=101.347s
2025-08-08 20:28:10 Train INFO: [Train]: [034][00030/00051] (59.6%)  Loss=0.9678  cls_loss=0.6698  reg_loss=0.2981  lr_backbone=8.5e-06  lr_det=8.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=552s  iter_time=104.927s
2025-08-08 20:29:54 Train INFO: [Train]: [034][00035/00051] (69.2%)  Loss=0.9771  cls_loss=0.6774  reg_loss=0.2998  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=409s  iter_time=104.384s
2025-08-08 20:32:13 Train INFO: [Train]: [034][00040/00051] (78.8%)  Loss=0.9809  cls_loss=0.6804  reg_loss=0.3005  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=139.019s
2025-08-08 20:33:55 Train INFO: [Train]: [034][00045/00051] (88.5%)  Loss=0.9718  cls_loss=0.6737  reg_loss=0.2982  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=102.016s
2025-08-08 20:35:39 Train INFO: [Train]: [034][00050/00051] (98.1%)  Loss=0.9758  cls_loss=0.6763  reg_loss=0.2994  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=103.686s
2025-08-08 20:35:49 Train INFO: [Train]: [034][00051/00051] (100.0%)  Loss=0.9768  cls_loss=0.6768  reg_loss=0.3000  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.365s
2025-08-08 20:35:50 Train INFO: [Train]: Epoch 34 completed in 1275.1s (avg 24.520s/iter)
2025-08-08 20:35:50 Train INFO: [Train]: Final Loss=0.9768
2025-08-08 20:35:50 Train INFO: [Val]: Epoch 34 Loss
2025-08-08 21:23:21 Train INFO: [Val]: [034]  Loss=1.0183  cls_loss=0.7052  reg_loss=0.3131  Average-mAP=0.73%
2025-08-08 21:23:23 Train INFO: Checkpoint saved at epoch 34
2025-08-08 21:23:23 Train INFO: [Train]: Epoch 35 started (Total iterations: 52)
2025-08-08 21:27:06 Train INFO: [Train]: [035][00005/00051] (11.5%)  Loss=0.9971  cls_loss=0.6941  reg_loss=0.3031  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1710s  iter_time=223.105s  fwd=2.064s/bwd=4.298s/opt=3.083s
2025-08-08 21:28:49 Train INFO: [Train]: [035][00010/00051] (21.2%)  Loss=0.9749  cls_loss=0.6787  reg_loss=0.2962  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1214s  iter_time=102.693s
2025-08-08 21:30:36 Train INFO: [Train]: [035][00015/00051] (30.8%)  Loss=0.9782  cls_loss=0.6778  reg_loss=0.3004  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=973s  iter_time=106.772s
2025-08-08 21:33:10 Train INFO: [Train]: [035][00020/00051] (40.4%)  Loss=0.9816  cls_loss=0.6796  reg_loss=0.3020  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=866s  iter_time=154.205s
2025-08-08 21:34:57 Train INFO: [Train]: [035][00025/00051] (50.0%)  Loss=0.9909  cls_loss=0.6857  reg_loss=0.3053  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=694s  iter_time=107.189s
2025-08-08 21:36:42 Train INFO: [Train]: [035][00030/00051] (59.6%)  Loss=0.9907  cls_loss=0.6859  reg_loss=0.3048  lr_backbone=8.4e-06  lr_det=8.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=104.527s
2025-08-08 21:38:21 Train INFO: [Train]: [035][00035/00051] (69.2%)  Loss=0.9783  cls_loss=0.6777  reg_loss=0.3005  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=99.012s
2025-08-08 21:40:55 Train INFO: [Train]: [035][00040/00051] (78.8%)  Loss=0.9836  cls_loss=0.6819  reg_loss=0.3017  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=153.967s
2025-08-08 21:42:37 Train INFO: [Train]: [035][00045/00051] (88.5%)  Loss=0.9923  cls_loss=0.6873  reg_loss=0.3050  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=102.092s
2025-08-08 21:44:17 Train INFO: [Train]: [035][00050/00051] (98.1%)  Loss=0.9891  cls_loss=0.6856  reg_loss=0.3035  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.343s
2025-08-08 21:44:27 Train INFO: [Train]: [035][00051/00051] (100.0%)  Loss=0.9877  cls_loss=0.6844  reg_loss=0.3033  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.371s
2025-08-08 21:44:28 Train INFO: [Train]: Epoch 35 completed in 1265.0s (avg 24.327s/iter)
2025-08-08 21:44:28 Train INFO: [Train]: Final Loss=0.9877
2025-08-08 21:44:28 Train INFO: [Train]: Epoch 36 started (Total iterations: 52)
2025-08-08 21:48:16 Train INFO: [Train]: [036][00005/00051] (11.5%)  Loss=1.0089  cls_loss=0.7016  reg_loss=0.3073  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1745s  iter_time=227.647s  fwd=2.073s/bwd=4.305s/opt=3.072s
2025-08-08 21:49:54 Train INFO: [Train]: [036][00010/00051] (21.2%)  Loss=1.0046  cls_loss=0.7029  reg_loss=0.3016  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1215s  iter_time=98.390s
2025-08-08 21:51:46 Train INFO: [Train]: [036][00015/00051] (30.8%)  Loss=1.0074  cls_loss=0.7045  reg_loss=0.3029  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=986s  iter_time=112.328s
2025-08-08 21:54:18 Train INFO: [Train]: [036][00020/00051] (40.4%)  Loss=0.9918  cls_loss=0.6903  reg_loss=0.3015  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=870s  iter_time=151.216s
2025-08-08 21:56:02 Train INFO: [Train]: [036][00025/00051] (50.0%)  Loss=0.9999  cls_loss=0.6952  reg_loss=0.3047  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=694s  iter_time=104.707s
2025-08-08 21:57:40 Train INFO: [Train]: [036][00030/00051] (59.6%)  Loss=1.0067  cls_loss=0.6992  reg_loss=0.3075  lr_backbone=8.3e-06  lr_det=8.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=536s  iter_time=97.211s
2025-08-08 21:59:21 Train INFO: [Train]: [036][00035/00051] (69.2%)  Loss=0.9954  cls_loss=0.6902  reg_loss=0.3052  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=101.495s
2025-08-08 22:01:51 Train INFO: [Train]: [036][00040/00051] (78.8%)  Loss=0.9884  cls_loss=0.6850  reg_loss=0.3034  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=149.585s
2025-08-08 22:03:34 Train INFO: [Train]: [036][00045/00051] (88.5%)  Loss=0.9893  cls_loss=0.6855  reg_loss=0.3038  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=103.716s
2025-08-08 22:05:16 Train INFO: [Train]: [036][00050/00051] (98.1%)  Loss=0.9895  cls_loss=0.6857  reg_loss=0.3038  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=101.160s
2025-08-08 22:05:26 Train INFO: [Train]: [036][00051/00051] (100.0%)  Loss=0.9891  cls_loss=0.6851  reg_loss=0.3040  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.371s
2025-08-08 22:05:27 Train INFO: [Train]: Epoch 36 completed in 1258.6s (avg 24.203s/iter)
2025-08-08 22:05:27 Train INFO: [Train]: Final Loss=0.9891
2025-08-08 22:05:27 Train INFO: [Train]: Epoch 37 started (Total iterations: 52)
2025-08-08 22:09:10 Train INFO: [Train]: [037][00005/00051] (11.5%)  Loss=0.9697  cls_loss=0.6725  reg_loss=0.2972  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1715s  iter_time=223.651s  fwd=2.057s/bwd=4.308s/opt=3.090s
2025-08-08 22:10:54 Train INFO: [Train]: [037][00010/00051] (21.2%)  Loss=0.9353  cls_loss=0.6486  reg_loss=0.2867  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1220s  iter_time=103.617s
2025-08-08 22:12:49 Train INFO: [Train]: [037][00015/00051] (30.8%)  Loss=0.9233  cls_loss=0.6366  reg_loss=0.2867  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=996s  iter_time=115.400s
2025-08-08 22:15:23 Train INFO: [Train]: [037][00020/00051] (40.4%)  Loss=0.9468  cls_loss=0.6534  reg_loss=0.2934  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=880s  iter_time=153.702s
2025-08-08 22:17:04 Train INFO: [Train]: [037][00025/00051] (50.0%)  Loss=0.9625  cls_loss=0.6646  reg_loss=0.2979  lr_backbone=8.2e-06  lr_det=8.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=697s  iter_time=100.440s
2025-08-08 22:18:41 Train INFO: [Train]: [037][00030/00051] (59.6%)  Loss=0.9678  cls_loss=0.6684  reg_loss=0.2994  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=538s  iter_time=97.490s
2025-08-08 22:20:30 Train INFO: [Train]: [037][00035/00051] (69.2%)  Loss=0.9739  cls_loss=0.6742  reg_loss=0.2997  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=108.678s
2025-08-08 22:22:51 Train INFO: [Train]: [037][00040/00051] (78.8%)  Loss=0.9683  cls_loss=0.6703  reg_loss=0.2980  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=141.137s
2025-08-08 22:24:42 Train INFO: [Train]: [037][00045/00051] (88.5%)  Loss=0.9672  cls_loss=0.6707  reg_loss=0.2965  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=111.581s
2025-08-08 22:26:23 Train INFO: [Train]: [037][00050/00051] (98.1%)  Loss=0.9683  cls_loss=0.6708  reg_loss=0.2975  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.547s
2025-08-08 22:26:33 Train INFO: [Train]: [037][00051/00051] (100.0%)  Loss=0.9672  cls_loss=0.6701  reg_loss=0.2971  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-08 22:26:34 Train INFO: [Train]: Epoch 37 completed in 1267.3s (avg 24.372s/iter)
2025-08-08 22:26:34 Train INFO: [Train]: Final Loss=0.9672
2025-08-08 22:26:34 Train INFO: [Train]: Epoch 38 started (Total iterations: 52)
2025-08-08 22:30:19 Train INFO: [Train]: [038][00005/00051] (11.5%)  Loss=0.9344  cls_loss=0.6509  reg_loss=0.2835  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1728s  iter_time=225.436s  fwd=2.045s/bwd=4.306s/opt=3.086s
2025-08-08 22:31:56 Train INFO: [Train]: [038][00010/00051] (21.2%)  Loss=0.9537  cls_loss=0.6657  reg_loss=0.2880  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1199s  iter_time=96.191s
2025-08-08 22:33:37 Train INFO: [Train]: [038][00015/00051] (30.8%)  Loss=0.9776  cls_loss=0.6853  reg_loss=0.2924  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=952s  iter_time=101.595s
2025-08-08 22:36:13 Train INFO: [Train]: [038][00020/00051] (40.4%)  Loss=0.9979  cls_loss=0.6959  reg_loss=0.3020  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=855s  iter_time=155.864s
2025-08-08 22:37:59 Train INFO: [Train]: [038][00025/00051] (50.0%)  Loss=0.9933  cls_loss=0.6915  reg_loss=0.3019  lr_backbone=8.1e-06  lr_det=8.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=685s  iter_time=106.269s
2025-08-08 22:39:38 Train INFO: [Train]: [038][00030/00051] (59.6%)  Loss=0.9950  cls_loss=0.6909  reg_loss=0.3041  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=531s  iter_time=98.121s
2025-08-08 22:41:21 Train INFO: [Train]: [038][00035/00051] (69.2%)  Loss=0.9935  cls_loss=0.6884  reg_loss=0.3050  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=394s  iter_time=103.419s
2025-08-08 22:43:59 Train INFO: [Train]: [038][00040/00051] (78.8%)  Loss=0.9943  cls_loss=0.6888  reg_loss=0.3055  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=158.138s
2025-08-08 22:45:38 Train INFO: [Train]: [038][00045/00051] (88.5%)  Loss=0.9929  cls_loss=0.6882  reg_loss=0.3047  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=98.656s
2025-08-08 22:47:18 Train INFO: [Train]: [038][00050/00051] (98.1%)  Loss=0.9864  cls_loss=0.6840  reg_loss=0.3024  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=100.583s
2025-08-08 22:47:29 Train INFO: [Train]: [038][00051/00051] (100.0%)  Loss=0.9836  cls_loss=0.6818  reg_loss=0.3018  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.370s
2025-08-08 22:47:29 Train INFO: [Train]: Epoch 38 completed in 1255.4s (avg 24.142s/iter)
2025-08-08 22:47:29 Train INFO: [Train]: Final Loss=0.9836
2025-08-08 22:47:29 Train INFO: [Train]: Epoch 39 started (Total iterations: 52)
2025-08-08 22:51:26 Train INFO: [Train]: [039][00005/00051] (11.5%)  Loss=0.9897  cls_loss=0.6808  reg_loss=0.3088  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1812s  iter_time=236.356s  fwd=2.055s/bwd=4.284s/opt=2.520s
2025-08-08 22:53:03 Train INFO: [Train]: [039][00010/00051] (21.2%)  Loss=0.9626  cls_loss=0.6674  reg_loss=0.2952  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1244s  iter_time=97.449s
2025-08-08 22:54:45 Train INFO: [Train]: [039][00015/00051] (30.8%)  Loss=0.9720  cls_loss=0.6721  reg_loss=0.2999  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=979s  iter_time=101.457s
2025-08-08 22:57:30 Train INFO: [Train]: [039][00020/00051] (40.4%)  Loss=0.9685  cls_loss=0.6680  reg_loss=0.3005  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=887s  iter_time=165.407s
2025-08-08 22:59:17 Train INFO: [Train]: [039][00025/00051] (50.0%)  Loss=0.9719  cls_loss=0.6716  reg_loss=0.3003  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=708s  iter_time=107.012s
2025-08-08 23:01:10 Train INFO: [Train]: [039][00030/00051] (59.6%)  Loss=0.9746  cls_loss=0.6737  reg_loss=0.3009  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=556s  iter_time=113.239s
2025-08-08 23:02:58 Train INFO: [Train]: [039][00035/00051] (69.2%)  Loss=0.9733  cls_loss=0.6732  reg_loss=0.3002  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=413s  iter_time=107.539s
2025-08-08 23:05:29 Train INFO: [Train]: [039][00040/00051] (78.8%)  Loss=0.9772  cls_loss=0.6747  reg_loss=0.3024  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=290s  iter_time=151.347s
2025-08-08 23:07:15 Train INFO: [Train]: [039][00045/00051] (88.5%)  Loss=0.9885  cls_loss=0.6828  reg_loss=0.3057  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=105.332s
2025-08-08 23:08:53 Train INFO: [Train]: [039][00050/00051] (98.1%)  Loss=0.9853  cls_loss=0.6795  reg_loss=0.3058  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.111s
2025-08-08 23:09:03 Train INFO: [Train]: [039][00051/00051] (100.0%)  Loss=0.9824  cls_loss=0.6776  reg_loss=0.3048  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.374s
2025-08-08 23:09:04 Train INFO: [Train]: Epoch 39 completed in 1294.4s (avg 24.892s/iter)
2025-08-08 23:09:04 Train INFO: [Train]: Final Loss=0.9824
2025-08-08 23:09:04 Train INFO: [Val]: Epoch 39 Loss
2025-08-08 23:56:30 Train INFO: [Val]: [039]  Loss=1.0117  cls_loss=0.6986  reg_loss=0.3131  Average-mAP=0.75%
2025-08-08 23:56:31 Train INFO: Checkpoint saved at epoch 39
2025-08-08 23:56:31 Train INFO: [Train]: Epoch 40 started (Total iterations: 52)
2025-08-09 00:00:20 Train INFO: [Train]: [040][00005/00051] (11.5%)  Loss=1.0046  cls_loss=0.6945  reg_loss=0.3101  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1754s  iter_time=228.756s  fwd=2.026s/bwd=4.261s/opt=3.079s
2025-08-09 00:02:07 Train INFO: [Train]: [040][00010/00051] (21.2%)  Loss=0.9694  cls_loss=0.6725  reg_loss=0.2968  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1249s  iter_time=106.419s
2025-08-09 00:03:51 Train INFO: [Train]: [040][00015/00051] (30.8%)  Loss=0.9610  cls_loss=0.6685  reg_loss=0.2925  lr_backbone=7.9e-06  lr_det=7.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=989s  iter_time=104.466s
2025-08-09 00:06:15 Train INFO: [Train]: [040][00020/00051] (40.4%)  Loss=0.9600  cls_loss=0.6658  reg_loss=0.2942  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=861s  iter_time=143.560s
2025-08-09 00:07:56 Train INFO: [Train]: [040][00025/00051] (50.0%)  Loss=0.9739  cls_loss=0.6752  reg_loss=0.2988  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=685s  iter_time=101.749s
2025-08-09 00:09:41 Train INFO: [Train]: [040][00030/00051] (59.6%)  Loss=0.9727  cls_loss=0.6741  reg_loss=0.2985  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=535s  iter_time=105.091s
2025-08-09 00:11:24 Train INFO: [Train]: [040][00035/00051] (69.2%)  Loss=0.9628  cls_loss=0.6677  reg_loss=0.2951  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=102.397s
2025-08-09 00:14:03 Train INFO: [Train]: [040][00040/00051] (78.8%)  Loss=0.9684  cls_loss=0.6727  reg_loss=0.2957  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=159.279s
2025-08-09 00:15:53 Train INFO: [Train]: [040][00045/00051] (88.5%)  Loss=0.9768  cls_loss=0.6775  reg_loss=0.2992  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=110.161s
2025-08-09 00:17:33 Train INFO: [Train]: [040][00050/00051] (98.1%)  Loss=0.9783  cls_loss=0.6796  reg_loss=0.2987  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.496s
2025-08-09 00:17:43 Train INFO: [Train]: [040][00051/00051] (100.0%)  Loss=0.9763  cls_loss=0.6781  reg_loss=0.2982  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.356s
2025-08-09 00:17:44 Train INFO: [Train]: Epoch 40 completed in 1272.4s (avg 24.470s/iter)
2025-08-09 00:17:44 Train INFO: [Train]: Final Loss=0.9763
2025-08-09 00:17:44 Train INFO: [Train]: Epoch 41 started (Total iterations: 52)
2025-08-09 00:21:31 Train INFO: [Train]: [041][00005/00051] (11.5%)  Loss=0.9355  cls_loss=0.6552  reg_loss=0.2803  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1745s  iter_time=227.628s  fwd=2.046s/bwd=4.286s/opt=3.072s
2025-08-09 00:23:07 Train INFO: [Train]: [041][00010/00051] (21.2%)  Loss=0.9126  cls_loss=0.6374  reg_loss=0.2752  lr_backbone=7.8e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1206s  iter_time=95.878s
2025-08-09 00:24:47 Train INFO: [Train]: [041][00015/00051] (30.8%)  Loss=0.9532  cls_loss=0.6627  reg_loss=0.2905  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=952s  iter_time=99.792s
2025-08-09 00:27:14 Train INFO: [Train]: [041][00020/00051] (40.4%)  Loss=0.9693  cls_loss=0.6752  reg_loss=0.2942  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=842s  iter_time=147.106s
2025-08-09 00:29:05 Train INFO: [Train]: [041][00025/00051] (50.0%)  Loss=0.9810  cls_loss=0.6830  reg_loss=0.2980  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=110.691s
2025-08-09 00:30:47 Train INFO: [Train]: [041][00030/00051] (59.6%)  Loss=0.9855  cls_loss=0.6834  reg_loss=0.3021  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=530s  iter_time=101.559s
2025-08-09 00:32:27 Train INFO: [Train]: [041][00035/00051] (69.2%)  Loss=0.9850  cls_loss=0.6822  reg_loss=0.3029  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=393s  iter_time=100.965s
2025-08-09 00:35:02 Train INFO: [Train]: [041][00040/00051] (78.8%)  Loss=0.9773  cls_loss=0.6766  reg_loss=0.3007  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=154.669s
2025-08-09 00:36:47 Train INFO: [Train]: [041][00045/00051] (88.5%)  Loss=0.9820  cls_loss=0.6796  reg_loss=0.3024  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=104.890s
2025-08-09 00:38:30 Train INFO: [Train]: [041][00050/00051] (98.1%)  Loss=0.9879  cls_loss=0.6836  reg_loss=0.3042  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=102.945s
2025-08-09 00:38:40 Train INFO: [Train]: [041][00051/00051] (100.0%)  Loss=0.9857  cls_loss=0.6818  reg_loss=0.3039  lr_backbone=7.7e-06  lr_det=7.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.351s
2025-08-09 00:38:41 Train INFO: [Train]: Epoch 41 completed in 1257.2s (avg 24.177s/iter)
2025-08-09 00:38:41 Train INFO: [Train]: Final Loss=0.9857
2025-08-09 00:38:41 Train INFO: [Train]: Epoch 42 started (Total iterations: 52)
2025-08-09 00:42:21 Train INFO: [Train]: [042][00005/00051] (11.5%)  Loss=0.9570  cls_loss=0.6594  reg_loss=0.2976  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1683s  iter_time=219.513s  fwd=2.058s/bwd=4.294s/opt=3.068s
2025-08-09 00:44:00 Train INFO: [Train]: [042][00010/00051] (21.2%)  Loss=0.9489  cls_loss=0.6546  reg_loss=0.2943  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1188s  iter_time=99.277s
2025-08-09 00:45:43 Train INFO: [Train]: [042][00015/00051] (30.8%)  Loss=0.9889  cls_loss=0.6825  reg_loss=0.3064  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=949s  iter_time=102.905s
2025-08-09 00:48:28 Train INFO: [Train]: [042][00020/00051] (40.4%)  Loss=0.9723  cls_loss=0.6696  reg_loss=0.3027  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=866s  iter_time=164.811s
2025-08-09 00:50:08 Train INFO: [Train]: [042][00025/00051] (50.0%)  Loss=0.9665  cls_loss=0.6655  reg_loss=0.3010  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=687s  iter_time=100.844s
2025-08-09 00:51:57 Train INFO: [Train]: [042][00030/00051] (59.6%)  Loss=0.9673  cls_loss=0.6658  reg_loss=0.3015  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=539s  iter_time=108.236s
2025-08-09 00:53:41 Train INFO: [Train]: [042][00035/00051] (69.2%)  Loss=0.9793  cls_loss=0.6738  reg_loss=0.3055  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=104.455s
2025-08-09 00:56:20 Train INFO: [Train]: [042][00040/00051] (78.8%)  Loss=0.9834  cls_loss=0.6769  reg_loss=0.3065  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=158.731s
2025-08-09 00:58:04 Train INFO: [Train]: [042][00045/00051] (88.5%)  Loss=0.9892  cls_loss=0.6800  reg_loss=0.3093  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=103.951s
2025-08-09 00:59:51 Train INFO: [Train]: [042][00050/00051] (98.1%)  Loss=0.9870  cls_loss=0.6787  reg_loss=0.3083  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=107.307s
2025-08-09 01:00:01 Train INFO: [Train]: [042][00051/00051] (100.0%)  Loss=0.9836  cls_loss=0.6767  reg_loss=0.3069  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.361s
2025-08-09 01:00:02 Train INFO: [Train]: Epoch 42 completed in 1281.2s (avg 24.638s/iter)
2025-08-09 01:00:02 Train INFO: [Train]: Final Loss=0.9836
2025-08-09 01:00:02 Train INFO: [Train]: Epoch 43 started (Total iterations: 52)
2025-08-09 01:03:49 Train INFO: [Train]: [043][00005/00051] (11.5%)  Loss=0.9002  cls_loss=0.6236  reg_loss=0.2765  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1737s  iter_time=226.543s  fwd=2.045s/bwd=4.290s/opt=3.076s
2025-08-09 01:05:28 Train INFO: [Train]: [043][00010/00051] (21.2%)  Loss=0.9632  cls_loss=0.6716  reg_loss=0.2915  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1213s  iter_time=98.845s
2025-08-09 01:07:07 Train INFO: [Train]: [043][00015/00051] (30.8%)  Loss=0.9458  cls_loss=0.6601  reg_loss=0.2857  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=956s  iter_time=99.578s
2025-08-09 01:09:37 Train INFO: [Train]: [043][00020/00051] (40.4%)  Loss=0.9626  cls_loss=0.6700  reg_loss=0.2925  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=849s  iter_time=150.000s
2025-08-09 01:11:23 Train INFO: [Train]: [043][00025/00051] (50.0%)  Loss=0.9767  cls_loss=0.6780  reg_loss=0.2987  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=105.336s
2025-08-09 01:13:14 Train INFO: [Train]: [043][00030/00051] (59.6%)  Loss=0.9764  cls_loss=0.6768  reg_loss=0.2996  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=537s  iter_time=111.865s
2025-08-09 01:15:01 Train INFO: [Train]: [043][00035/00051] (69.2%)  Loss=0.9817  cls_loss=0.6796  reg_loss=0.3022  lr_backbone=7.5e-06  lr_det=7.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=106.619s
2025-08-09 01:17:19 Train INFO: [Train]: [043][00040/00051] (78.8%)  Loss=0.9839  cls_loss=0.6811  reg_loss=0.3028  lr_backbone=7.5e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=278s  iter_time=137.979s
2025-08-09 01:19:12 Train INFO: [Train]: [043][00045/00051] (88.5%)  Loss=0.9916  cls_loss=0.6854  reg_loss=0.3063  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=112.898s
2025-08-09 01:20:44 Train INFO: [Train]: [043][00050/00051] (98.1%)  Loss=0.9866  cls_loss=0.6825  reg_loss=0.3042  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=91.609s
2025-08-09 01:20:54 Train INFO: [Train]: [043][00051/00051] (100.0%)  Loss=0.9864  cls_loss=0.6822  reg_loss=0.3043  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.364s
2025-08-09 01:20:55 Train INFO: [Train]: Epoch 43 completed in 1252.3s (avg 24.084s/iter)
2025-08-09 01:20:55 Train INFO: [Train]: Final Loss=0.9864
2025-08-09 01:20:55 Train INFO: [Train]: Epoch 44 started (Total iterations: 52)
2025-08-09 01:24:53 Train INFO: [Train]: [044][00005/00051] (11.5%)  Loss=0.9965  cls_loss=0.6969  reg_loss=0.2997  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1829s  iter_time=238.518s  fwd=2.051s/bwd=4.305s/opt=3.069s
2025-08-09 01:26:34 Train INFO: [Train]: [044][00010/00051] (21.2%)  Loss=0.9808  cls_loss=0.6856  reg_loss=0.2952  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1267s  iter_time=101.334s
2025-08-09 01:28:13 Train INFO: [Train]: [044][00015/00051] (30.8%)  Loss=1.0072  cls_loss=0.7017  reg_loss=0.3056  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=987s  iter_time=99.000s
2025-08-09 01:30:57 Train INFO: [Train]: [044][00020/00051] (40.4%)  Loss=0.9957  cls_loss=0.6921  reg_loss=0.3035  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=890s  iter_time=163.833s
2025-08-09 01:32:45 Train INFO: [Train]: [044][00025/00051] (50.0%)  Loss=0.9963  cls_loss=0.6911  reg_loss=0.3051  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=710s  iter_time=107.796s
2025-08-09 01:34:32 Train INFO: [Train]: [044][00030/00051] (59.6%)  Loss=0.9877  cls_loss=0.6857  reg_loss=0.3020  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=553s  iter_time=106.545s
2025-08-09 01:36:19 Train INFO: [Train]: [044][00035/00051] (69.2%)  Loss=0.9718  cls_loss=0.6752  reg_loss=0.2966  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=411s  iter_time=107.075s
2025-08-09 01:38:52 Train INFO: [Train]: [044][00040/00051] (78.8%)  Loss=0.9790  cls_loss=0.6795  reg_loss=0.2995  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=289s  iter_time=152.866s
2025-08-09 01:40:32 Train INFO: [Train]: [044][00045/00051] (88.5%)  Loss=0.9760  cls_loss=0.6788  reg_loss=0.2972  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=100.878s
2025-08-09 01:42:10 Train INFO: [Train]: [044][00050/00051] (98.1%)  Loss=0.9746  cls_loss=0.6782  reg_loss=0.2964  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=97.575s
2025-08-09 01:42:20 Train INFO: [Train]: [044][00051/00051] (100.0%)  Loss=0.9761  cls_loss=0.6793  reg_loss=0.2968  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.341s
2025-08-09 01:42:21 Train INFO: [Train]: Epoch 44 completed in 1286.5s (avg 24.741s/iter)
2025-08-09 01:42:21 Train INFO: [Train]: Final Loss=0.9761
2025-08-09 01:42:21 Train INFO: [Val]: Epoch 44 Loss
2025-08-09 02:29:43 Train INFO: [Val]: [044]  Loss=1.0088  cls_loss=0.6957  reg_loss=0.3131  Average-mAP=0.64%
2025-08-09 02:29:45 Train INFO: Checkpoint saved at epoch 44
2025-08-09 02:29:45 Train INFO: [Train]: Epoch 45 started (Total iterations: 52)
2025-08-09 02:33:24 Train INFO: [Train]: [045][00005/00051] (11.5%)  Loss=1.0462  cls_loss=0.7209  reg_loss=0.3252  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1683s  iter_time=219.516s  fwd=2.029s/bwd=4.264s/opt=3.083s
2025-08-09 02:35:06 Train INFO: [Train]: [045][00010/00051] (21.2%)  Loss=0.9969  cls_loss=0.6849  reg_loss=0.3119  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1199s  iter_time=102.073s
2025-08-09 02:36:45 Train INFO: [Train]: [045][00015/00051] (30.8%)  Loss=0.9892  cls_loss=0.6822  reg_loss=0.3070  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=945s  iter_time=98.617s
2025-08-09 02:39:12 Train INFO: [Train]: [045][00020/00051] (40.4%)  Loss=0.9910  cls_loss=0.6814  reg_loss=0.3096  lr_backbone=7.3e-06  lr_det=7.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=838s  iter_time=147.529s
2025-08-09 02:40:54 Train INFO: [Train]: [045][00025/00051] (50.0%)  Loss=0.9811  cls_loss=0.6767  reg_loss=0.3045  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=670s  iter_time=102.065s
2025-08-09 02:42:46 Train INFO: [Train]: [045][00030/00051] (59.6%)  Loss=0.9847  cls_loss=0.6786  reg_loss=0.3061  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=529s  iter_time=111.351s
2025-08-09 02:44:34 Train INFO: [Train]: [045][00035/00051] (69.2%)  Loss=0.9722  cls_loss=0.6711  reg_loss=0.3011  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=395s  iter_time=107.885s
2025-08-09 02:46:56 Train INFO: [Train]: [045][00040/00051] (78.8%)  Loss=0.9732  cls_loss=0.6723  reg_loss=0.3009  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=142.777s
2025-08-09 02:48:57 Train INFO: [Train]: [045][00045/00051] (88.5%)  Loss=0.9730  cls_loss=0.6728  reg_loss=0.3002  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=120.499s
2025-08-09 02:50:28 Train INFO: [Train]: [045][00050/00051] (98.1%)  Loss=0.9781  cls_loss=0.6763  reg_loss=0.3018  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=90.855s
2025-08-09 02:50:38 Train INFO: [Train]: [045][00051/00051] (100.0%)  Loss=0.9778  cls_loss=0.6763  reg_loss=0.3016  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.380s
2025-08-09 02:50:39 Train INFO: [Train]: Epoch 45 completed in 1254.3s (avg 24.121s/iter)
2025-08-09 02:50:39 Train INFO: [Train]: Final Loss=0.9778
2025-08-09 02:50:39 Train INFO: [Train]: Epoch 46 started (Total iterations: 52)
2025-08-09 02:54:19 Train INFO: [Train]: [046][00005/00051] (11.5%)  Loss=0.9348  cls_loss=0.6464  reg_loss=0.2884  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1689s  iter_time=220.263s  fwd=2.030s/bwd=4.305s/opt=3.070s
2025-08-09 02:56:00 Train INFO: [Train]: [046][00010/00051] (21.2%)  Loss=0.9623  cls_loss=0.6638  reg_loss=0.2985  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1199s  iter_time=101.334s
2025-08-09 02:57:53 Train INFO: [Train]: [046][00015/00051] (30.8%)  Loss=0.9917  cls_loss=0.6862  reg_loss=0.3056  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=978s  iter_time=112.993s
2025-08-09 03:00:41 Train INFO: [Train]: [046][00020/00051] (40.4%)  Loss=0.9664  cls_loss=0.6698  reg_loss=0.2966  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=890s  iter_time=168.000s
2025-08-09 03:02:37 Train INFO: [Train]: [046][00025/00051] (50.0%)  Loss=0.9679  cls_loss=0.6700  reg_loss=0.2979  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=718s  iter_time=115.209s
2025-08-09 03:04:20 Train INFO: [Train]: [046][00030/00051] (59.6%)  Loss=0.9844  cls_loss=0.6807  reg_loss=0.3037  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=556s  iter_time=103.202s
2025-08-09 03:06:02 Train INFO: [Train]: [046][00035/00051] (69.2%)  Loss=0.9771  cls_loss=0.6759  reg_loss=0.3012  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=410s  iter_time=102.512s
2025-08-09 03:08:43 Train INFO: [Train]: [046][00040/00051] (78.8%)  Loss=0.9693  cls_loss=0.6720  reg_loss=0.2973  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=291s  iter_time=161.145s
2025-08-09 03:10:33 Train INFO: [Train]: [046][00045/00051] (88.5%)  Loss=0.9748  cls_loss=0.6750  reg_loss=0.2999  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=156s  iter_time=109.849s
2025-08-09 03:12:09 Train INFO: [Train]: [046][00050/00051] (98.1%)  Loss=0.9716  cls_loss=0.6717  reg_loss=0.2998  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=95.611s
2025-08-09 03:12:19 Train INFO: [Train]: [046][00051/00051] (100.0%)  Loss=0.9676  cls_loss=0.6691  reg_loss=0.2985  lr_backbone=7.1e-06  lr_det=7.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-09 03:12:20 Train INFO: [Train]: Epoch 46 completed in 1301.2s (avg 25.024s/iter)
2025-08-09 03:12:20 Train INFO: [Train]: Final Loss=0.9676
2025-08-09 03:12:20 Train INFO: [Train]: Epoch 47 started (Total iterations: 52)
2025-08-09 03:16:01 Train INFO: [Train]: [047][00005/00051] (11.5%)  Loss=1.0401  cls_loss=0.7177  reg_loss=0.3224  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1693s  iter_time=220.770s  fwd=2.052s/bwd=4.289s/opt=3.072s
2025-08-09 03:17:49 Train INFO: [Train]: [047][00010/00051] (21.2%)  Loss=1.0140  cls_loss=0.7020  reg_loss=0.3120  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1226s  iter_time=108.186s
2025-08-09 03:19:42 Train INFO: [Train]: [047][00015/00051] (30.8%)  Loss=1.0120  cls_loss=0.6992  reg_loss=0.3128  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=993s  iter_time=112.566s
2025-08-09 03:22:07 Train INFO: [Train]: [047][00020/00051] (40.4%)  Loss=0.9965  cls_loss=0.6869  reg_loss=0.3096  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=866s  iter_time=145.155s
2025-08-09 03:23:55 Train INFO: [Train]: [047][00025/00051] (50.0%)  Loss=0.9775  cls_loss=0.6747  reg_loss=0.3028  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=695s  iter_time=107.989s
2025-08-09 03:25:42 Train INFO: [Train]: [047][00030/00051] (59.6%)  Loss=0.9902  cls_loss=0.6838  reg_loss=0.3064  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=544s  iter_time=107.691s
2025-08-09 03:27:23 Train INFO: [Train]: [047][00035/00051] (69.2%)  Loss=0.9751  cls_loss=0.6735  reg_loss=0.3017  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=100.172s
2025-08-09 03:29:53 Train INFO: [Train]: [047][00040/00051] (78.8%)  Loss=0.9760  cls_loss=0.6749  reg_loss=0.3011  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=150.412s
2025-08-09 03:31:49 Train INFO: [Train]: [047][00045/00051] (88.5%)  Loss=0.9790  cls_loss=0.6771  reg_loss=0.3019  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=115.870s
2025-08-09 03:33:34 Train INFO: [Train]: [047][00050/00051] (98.1%)  Loss=0.9760  cls_loss=0.6755  reg_loss=0.3004  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=105.229s
2025-08-09 03:33:44 Train INFO: [Train]: [047][00051/00051] (100.0%)  Loss=0.9749  cls_loss=0.6748  reg_loss=0.3001  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.390s
2025-08-09 03:33:45 Train INFO: [Train]: Epoch 47 completed in 1285.1s (avg 24.714s/iter)
2025-08-09 03:33:45 Train INFO: [Train]: Final Loss=0.9749
2025-08-09 03:33:45 Train INFO: [Train]: Epoch 48 started (Total iterations: 52)
2025-08-09 03:37:24 Train INFO: [Train]: [048][00005/00051] (11.5%)  Loss=0.9739  cls_loss=0.6781  reg_loss=0.2958  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1679s  iter_time=219.036s  fwd=2.033s/bwd=4.284s/opt=3.085s
2025-08-09 03:39:14 Train INFO: [Train]: [048][00010/00051] (21.2%)  Loss=0.9708  cls_loss=0.6779  reg_loss=0.2929  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1225s  iter_time=109.564s
2025-08-09 03:40:57 Train INFO: [Train]: [048][00015/00051] (30.8%)  Loss=0.9530  cls_loss=0.6642  reg_loss=0.2887  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=971s  iter_time=103.040s
2025-08-09 03:43:38 Train INFO: [Train]: [048][00020/00051] (40.4%)  Loss=0.9809  cls_loss=0.6838  reg_loss=0.2971  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=875s  iter_time=161.073s
2025-08-09 03:45:24 Train INFO: [Train]: [048][00025/00051] (50.0%)  Loss=0.9927  cls_loss=0.6910  reg_loss=0.3017  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=699s  iter_time=105.903s
2025-08-09 03:47:04 Train INFO: [Train]: [048][00030/00051] (59.6%)  Loss=1.0084  cls_loss=0.7004  reg_loss=0.3080  lr_backbone=6.9e-06  lr_det=6.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=100.656s
2025-08-09 03:48:46 Train INFO: [Train]: [048][00035/00051] (69.2%)  Loss=0.9970  cls_loss=0.6916  reg_loss=0.3054  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=101.201s
2025-08-09 03:51:21 Train INFO: [Train]: [048][00040/00051] (78.8%)  Loss=0.9937  cls_loss=0.6900  reg_loss=0.3037  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=155.662s
2025-08-09 03:53:13 Train INFO: [Train]: [048][00045/00051] (88.5%)  Loss=0.9895  cls_loss=0.6861  reg_loss=0.3034  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=111.688s
2025-08-09 03:54:50 Train INFO: [Train]: [048][00050/00051] (98.1%)  Loss=0.9930  cls_loss=0.6885  reg_loss=0.3045  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=96.978s
2025-08-09 03:55:00 Train INFO: [Train]: [048][00051/00051] (100.0%)  Loss=0.9927  cls_loss=0.6881  reg_loss=0.3046  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.356s
2025-08-09 03:55:01 Train INFO: [Train]: Epoch 48 completed in 1275.9s (avg 24.536s/iter)
2025-08-09 03:55:01 Train INFO: [Train]: Final Loss=0.9927
2025-08-09 03:55:01 Train INFO: [Train]: Epoch 49 started (Total iterations: 52)
2025-08-09 03:58:48 Train INFO: [Train]: [049][00005/00051] (11.5%)  Loss=0.9415  cls_loss=0.6562  reg_loss=0.2854  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1741s  iter_time=227.058s  fwd=2.044s/bwd=4.297s/opt=3.079s
2025-08-09 04:00:33 Train INFO: [Train]: [049][00010/00051] (21.2%)  Loss=0.9342  cls_loss=0.6515  reg_loss=0.2827  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1237s  iter_time=104.866s
2025-08-09 04:02:11 Train INFO: [Train]: [049][00015/00051] (30.8%)  Loss=0.9554  cls_loss=0.6638  reg_loss=0.2915  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=967s  iter_time=97.892s
2025-08-09 04:04:36 Train INFO: [Train]: [049][00020/00051] (40.4%)  Loss=0.9570  cls_loss=0.6632  reg_loss=0.2938  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=849s  iter_time=145.600s
2025-08-09 04:06:23 Train INFO: [Train]: [049][00025/00051] (50.0%)  Loss=0.9636  cls_loss=0.6687  reg_loss=0.2950  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=106.052s
2025-08-09 04:08:12 Train INFO: [Train]: [049][00030/00051] (59.6%)  Loss=0.9679  cls_loss=0.6715  reg_loss=0.2964  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=536s  iter_time=109.793s
2025-08-09 04:10:00 Train INFO: [Train]: [049][00035/00051] (69.2%)  Loss=0.9697  cls_loss=0.6736  reg_loss=0.2962  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=107.698s
2025-08-09 04:12:23 Train INFO: [Train]: [049][00040/00051] (78.8%)  Loss=0.9696  cls_loss=0.6735  reg_loss=0.2961  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=142.684s
2025-08-09 04:14:04 Train INFO: [Train]: [049][00045/00051] (88.5%)  Loss=0.9742  cls_loss=0.6765  reg_loss=0.2978  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=101.144s
2025-08-09 04:15:47 Train INFO: [Train]: [049][00050/00051] (98.1%)  Loss=0.9667  cls_loss=0.6722  reg_loss=0.2945  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=102.887s
2025-08-09 04:15:57 Train INFO: [Train]: [049][00051/00051] (100.0%)  Loss=0.9648  cls_loss=0.6708  reg_loss=0.2940  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.345s
2025-08-09 04:15:58 Train INFO: [Train]: Epoch 49 completed in 1256.7s (avg 24.168s/iter)
2025-08-09 04:15:58 Train INFO: [Train]: Final Loss=0.9648
2025-08-09 04:15:58 Train INFO: [Val]: Epoch 49 Loss
2025-08-09 05:03:41 Train INFO: [Val]: [049]  Loss=1.0071  cls_loss=0.6942  reg_loss=0.3130  Average-mAP=0.71%
2025-08-09 05:03:43 Train INFO: Checkpoint saved at epoch 49
2025-08-09 05:03:43 Train INFO: [Train]: Epoch 50 started (Total iterations: 52)
2025-08-09 05:07:24 Train INFO: [Train]: [050][00005/00051] (11.5%)  Loss=0.9469  cls_loss=0.6680  reg_loss=0.2789  lr_backbone=6.7e-06  lr_det=6.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1694s  iter_time=220.948s  fwd=2.076s/bwd=4.333s/opt=3.083s
2025-08-09 05:09:11 Train INFO: [Train]: [050][00010/00051] (21.2%)  Loss=0.9806  cls_loss=0.6887  reg_loss=0.2919  lr_backbone=6.7e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1222s  iter_time=106.972s
2025-08-09 05:10:50 Train INFO: [Train]: [050][00015/00051] (30.8%)  Loss=0.9650  cls_loss=0.6743  reg_loss=0.2906  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=961s  iter_time=99.049s
2025-08-09 05:13:36 Train INFO: [Train]: [050][00020/00051] (40.4%)  Loss=0.9745  cls_loss=0.6808  reg_loss=0.2937  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=875s  iter_time=165.927s
2025-08-09 05:15:13 Train INFO: [Train]: [050][00025/00051] (50.0%)  Loss=0.9839  cls_loss=0.6861  reg_loss=0.2978  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=690s  iter_time=97.433s
2025-08-09 05:17:01 Train INFO: [Train]: [050][00030/00051] (59.6%)  Loss=0.9910  cls_loss=0.6914  reg_loss=0.2996  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=107.696s
2025-08-09 05:18:49 Train INFO: [Train]: [050][00035/00051] (69.2%)  Loss=0.9874  cls_loss=0.6870  reg_loss=0.3004  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=403s  iter_time=108.430s
2025-08-09 05:21:17 Train INFO: [Train]: [050][00040/00051] (78.8%)  Loss=0.9906  cls_loss=0.6891  reg_loss=0.3016  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=147.853s
2025-08-09 05:23:09 Train INFO: [Train]: [050][00045/00051] (88.5%)  Loss=0.9868  cls_loss=0.6857  reg_loss=0.3011  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=111.734s
2025-08-09 05:24:54 Train INFO: [Train]: [050][00050/00051] (98.1%)  Loss=0.9896  cls_loss=0.6880  reg_loss=0.3017  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=105.200s
2025-08-09 05:25:04 Train INFO: [Train]: [050][00051/00051] (100.0%)  Loss=0.9874  cls_loss=0.6863  reg_loss=0.3012  lr_backbone=6.6e-06  lr_det=6.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.365s
2025-08-09 05:25:05 Train INFO: [Train]: Epoch 50 completed in 1282.4s (avg 24.661s/iter)
2025-08-09 05:25:05 Train INFO: [Train]: Final Loss=0.9874
2025-08-09 05:25:05 Train INFO: [Train]: Epoch 51 started (Total iterations: 52)
2025-08-09 05:28:41 Train INFO: [Train]: [051][00005/00051] (11.5%)  Loss=0.9635  cls_loss=0.6719  reg_loss=0.2916  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1653s  iter_time=215.631s  fwd=2.074s/bwd=4.302s/opt=3.081s
2025-08-09 05:30:16 Train INFO: [Train]: [051][00010/00051] (21.2%)  Loss=0.9569  cls_loss=0.6617  reg_loss=0.2952  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1161s  iter_time=95.818s
2025-08-09 05:31:58 Train INFO: [Train]: [051][00015/00051] (30.8%)  Loss=0.9579  cls_loss=0.6647  reg_loss=0.2932  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=930s  iter_time=101.676s
2025-08-09 05:34:24 Train INFO: [Train]: [051][00020/00051] (40.4%)  Loss=0.9545  cls_loss=0.6599  reg_loss=0.2946  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=826s  iter_time=146.129s
2025-08-09 05:36:11 Train INFO: [Train]: [051][00025/00051] (50.0%)  Loss=0.9775  cls_loss=0.6771  reg_loss=0.3004  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=666s  iter_time=107.205s
2025-08-09 05:38:01 Train INFO: [Train]: [051][00030/00051] (59.6%)  Loss=0.9814  cls_loss=0.6794  reg_loss=0.3020  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=526s  iter_time=109.917s
2025-08-09 05:39:44 Train INFO: [Train]: [051][00035/00051] (69.2%)  Loss=0.9812  cls_loss=0.6784  reg_loss=0.3028  lr_backbone=6.5e-06  lr_det=6.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=390s  iter_time=102.128s
2025-08-09 05:42:11 Train INFO: [Train]: [051][00040/00051] (78.8%)  Loss=0.9774  cls_loss=0.6753  reg_loss=0.3022  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=275s  iter_time=147.645s
2025-08-09 05:43:50 Train INFO: [Train]: [051][00045/00051] (88.5%)  Loss=0.9751  cls_loss=0.6740  reg_loss=0.3010  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=99.172s
2025-08-09 05:45:26 Train INFO: [Train]: [051][00050/00051] (98.1%)  Loss=0.9813  cls_loss=0.6785  reg_loss=0.3028  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.107s
2025-08-09 05:45:37 Train INFO: [Train]: [051][00051/00051] (100.0%)  Loss=0.9794  cls_loss=0.6770  reg_loss=0.3024  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.369s
2025-08-09 05:45:38 Train INFO: [Train]: Epoch 51 completed in 1232.5s (avg 23.703s/iter)
2025-08-09 05:45:38 Train INFO: [Train]: Final Loss=0.9794
2025-08-09 05:45:38 Train INFO: [Train]: Epoch 52 started (Total iterations: 52)
2025-08-09 05:49:14 Train INFO: [Train]: [052][00005/00051] (11.5%)  Loss=0.9704  cls_loss=0.6700  reg_loss=0.3003  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1661s  iter_time=216.678s  fwd=2.039s/bwd=4.270s/opt=3.077s
2025-08-09 05:50:53 Train INFO: [Train]: [052][00010/00051] (21.2%)  Loss=0.9863  cls_loss=0.6837  reg_loss=0.3026  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1175s  iter_time=98.632s
2025-08-09 05:52:33 Train INFO: [Train]: [052][00015/00051] (30.8%)  Loss=0.9992  cls_loss=0.6946  reg_loss=0.3046  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=936s  iter_time=100.577s
2025-08-09 05:54:55 Train INFO: [Train]: [052][00020/00051] (40.4%)  Loss=1.0074  cls_loss=0.6979  reg_loss=0.3095  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=823s  iter_time=141.782s
2025-08-09 05:56:37 Train INFO: [Train]: [052][00025/00051] (50.0%)  Loss=0.9785  cls_loss=0.6795  reg_loss=0.2990  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=660s  iter_time=101.935s
2025-08-09 05:58:18 Train INFO: [Train]: [052][00030/00051] (59.6%)  Loss=0.9804  cls_loss=0.6816  reg_loss=0.2988  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=515s  iter_time=100.427s
2025-08-09 06:00:06 Train INFO: [Train]: [052][00035/00051] (69.2%)  Loss=0.9840  cls_loss=0.6841  reg_loss=0.2999  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=386s  iter_time=108.074s
2025-08-09 06:02:46 Train INFO: [Train]: [052][00040/00051] (78.8%)  Loss=0.9775  cls_loss=0.6799  reg_loss=0.2976  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=276s  iter_time=160.622s
2025-08-09 06:04:34 Train INFO: [Train]: [052][00045/00051] (88.5%)  Loss=0.9885  cls_loss=0.6861  reg_loss=0.3024  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=148s  iter_time=107.760s
2025-08-09 06:06:21 Train INFO: [Train]: [052][00050/00051] (98.1%)  Loss=0.9881  cls_loss=0.6859  reg_loss=0.3022  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=106.496s
2025-08-09 06:06:31 Train INFO: [Train]: [052][00051/00051] (100.0%)  Loss=0.9853  cls_loss=0.6845  reg_loss=0.3009  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.354s
2025-08-09 06:06:32 Train INFO: [Train]: Epoch 52 completed in 1254.1s (avg 24.117s/iter)
2025-08-09 06:06:32 Train INFO: [Train]: Final Loss=0.9853
2025-08-09 06:06:32 Train INFO: [Train]: Epoch 53 started (Total iterations: 52)
2025-08-09 06:10:03 Train INFO: [Train]: [053][00005/00051] (11.5%)  Loss=0.9494  cls_loss=0.6578  reg_loss=0.2916  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1623s  iter_time=211.631s  fwd=2.041s/bwd=4.265s/opt=3.086s
2025-08-09 06:11:51 Train INFO: [Train]: [053][00010/00051] (21.2%)  Loss=0.9584  cls_loss=0.6653  reg_loss=0.2931  lr_backbone=6.3e-06  lr_det=6.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1190s  iter_time=107.756s
2025-08-09 06:13:31 Train INFO: [Train]: [053][00015/00051] (30.8%)  Loss=0.9459  cls_loss=0.6579  reg_loss=0.2880  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=943s  iter_time=99.501s
2025-08-09 06:15:54 Train INFO: [Train]: [053][00020/00051] (40.4%)  Loss=0.9399  cls_loss=0.6525  reg_loss=0.2874  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=831s  iter_time=143.902s
2025-08-09 06:17:36 Train INFO: [Train]: [053][00025/00051] (50.0%)  Loss=0.9444  cls_loss=0.6555  reg_loss=0.2889  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=665s  iter_time=102.011s
2025-08-09 06:19:15 Train INFO: [Train]: [053][00030/00051] (59.6%)  Loss=0.9524  cls_loss=0.6595  reg_loss=0.2930  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=517s  iter_time=98.785s
2025-08-09 06:20:57 Train INFO: [Train]: [053][00035/00051] (69.2%)  Loss=0.9584  cls_loss=0.6633  reg_loss=0.2951  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=385s  iter_time=101.848s
2025-08-09 06:23:35 Train INFO: [Train]: [053][00040/00051] (78.8%)  Loss=0.9661  cls_loss=0.6692  reg_loss=0.2969  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=274s  iter_time=157.637s
2025-08-09 06:25:22 Train INFO: [Train]: [053][00045/00051] (88.5%)  Loss=0.9655  cls_loss=0.6691  reg_loss=0.2964  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=107.150s
2025-08-09 06:27:00 Train INFO: [Train]: [053][00050/00051] (98.1%)  Loss=0.9703  cls_loss=0.6730  reg_loss=0.2973  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=97.737s
2025-08-09 06:27:10 Train INFO: [Train]: [053][00051/00051] (100.0%)  Loss=0.9683  cls_loss=0.6714  reg_loss=0.2969  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.351s
2025-08-09 06:27:11 Train INFO: [Train]: Epoch 53 completed in 1239.0s (avg 23.828s/iter)
2025-08-09 06:27:11 Train INFO: [Train]: Final Loss=0.9683
2025-08-09 06:27:11 Train INFO: [Train]: Epoch 54 started (Total iterations: 52)
2025-08-09 06:31:00 Train INFO: [Train]: [054][00005/00051] (11.5%)  Loss=0.8681  cls_loss=0.6041  reg_loss=0.2640  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1761s  iter_time=229.731s  fwd=2.043s/bwd=4.278s/opt=3.071s
2025-08-09 06:32:36 Train INFO: [Train]: [054][00010/00051] (21.2%)  Loss=0.9385  cls_loss=0.6545  reg_loss=0.2839  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1212s  iter_time=95.558s
2025-08-09 06:34:19 Train INFO: [Train]: [054][00015/00051] (30.8%)  Loss=0.9709  cls_loss=0.6755  reg_loss=0.2954  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=964s  iter_time=103.056s
2025-08-09 06:36:54 Train INFO: [Train]: [054][00020/00051] (40.4%)  Loss=0.9663  cls_loss=0.6705  reg_loss=0.2958  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=861s  iter_time=154.705s
2025-08-09 06:38:49 Train INFO: [Train]: [054][00025/00051] (50.0%)  Loss=0.9856  cls_loss=0.6839  reg_loss=0.3017  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=114.944s
2025-08-09 06:40:31 Train INFO: [Train]: [054][00030/00051] (59.6%)  Loss=0.9942  cls_loss=0.6900  reg_loss=0.3042  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=542s  iter_time=102.178s
2025-08-09 06:42:13 Train INFO: [Train]: [054][00035/00051] (69.2%)  Loss=0.9977  cls_loss=0.6917  reg_loss=0.3060  lr_backbone=6.1e-06  lr_det=6.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=101.658s
2025-08-09 06:44:46 Train INFO: [Train]: [054][00040/00051] (78.8%)  Loss=0.9875  cls_loss=0.6842  reg_loss=0.3033  lr_backbone=6.1e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=153.240s
2025-08-09 06:46:28 Train INFO: [Train]: [054][00045/00051] (88.5%)  Loss=0.9943  cls_loss=0.6889  reg_loss=0.3053  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=102.238s
2025-08-09 06:48:17 Train INFO: [Train]: [054][00050/00051] (98.1%)  Loss=0.9925  cls_loss=0.6871  reg_loss=0.3054  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=108.878s
2025-08-09 06:48:27 Train INFO: [Train]: [054][00051/00051] (100.0%)  Loss=0.9915  cls_loss=0.6867  reg_loss=0.3048  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.350s
2025-08-09 06:48:28 Train INFO: [Train]: Epoch 54 completed in 1277.3s (avg 24.563s/iter)
2025-08-09 06:48:28 Train INFO: [Train]: Final Loss=0.9915
2025-08-09 06:48:28 Train INFO: [Val]: Epoch 54 Loss
2025-08-09 07:35:49 Train INFO: [Val]: [054]  Loss=1.0066  cls_loss=0.6937  reg_loss=0.3129  Average-mAP=0.67%
2025-08-09 07:35:52 Train INFO: Checkpoint saved at epoch 54
2025-08-09 07:35:52 Train INFO: [Train]: Epoch 55 started (Total iterations: 52)
2025-08-09 07:39:37 Train INFO: [Train]: [055][00005/00051] (11.5%)  Loss=0.8932  cls_loss=0.6169  reg_loss=0.2763  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1727s  iter_time=225.310s  fwd=2.036s/bwd=4.270s/opt=3.081s
2025-08-09 07:41:15 Train INFO: [Train]: [055][00010/00051] (21.2%)  Loss=0.9433  cls_loss=0.6497  reg_loss=0.2936  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1206s  iter_time=98.170s
2025-08-09 07:42:53 Train INFO: [Train]: [055][00015/00051] (30.8%)  Loss=0.9499  cls_loss=0.6552  reg_loss=0.2947  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=946s  iter_time=97.093s
2025-08-09 07:45:30 Train INFO: [Train]: [055][00020/00051] (40.4%)  Loss=0.9693  cls_loss=0.6692  reg_loss=0.3001  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=853s  iter_time=156.969s
2025-08-09 07:47:12 Train INFO: [Train]: [055][00025/00051] (50.0%)  Loss=0.9617  cls_loss=0.6631  reg_loss=0.2986  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=102.246s
2025-08-09 07:48:49 Train INFO: [Train]: [055][00030/00051] (59.6%)  Loss=0.9666  cls_loss=0.6666  reg_loss=0.3000  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=526s  iter_time=96.706s
2025-08-09 07:50:26 Train INFO: [Train]: [055][00035/00051] (69.2%)  Loss=0.9685  cls_loss=0.6670  reg_loss=0.3015  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=389s  iter_time=97.925s
2025-08-09 07:52:45 Train INFO: [Train]: [055][00040/00051] (78.8%)  Loss=0.9633  cls_loss=0.6633  reg_loss=0.3000  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=272s  iter_time=138.292s
2025-08-09 07:54:23 Train INFO: [Train]: [055][00045/00051] (88.5%)  Loss=0.9703  cls_loss=0.6675  reg_loss=0.3028  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=145s  iter_time=98.688s
2025-08-09 07:55:58 Train INFO: [Train]: [055][00050/00051] (98.1%)  Loss=0.9724  cls_loss=0.6699  reg_loss=0.3025  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=95.031s
2025-08-09 07:56:09 Train INFO: [Train]: [055][00051/00051] (100.0%)  Loss=0.9692  cls_loss=0.6678  reg_loss=0.3013  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.344s
2025-08-09 07:56:10 Train INFO: [Train]: Epoch 55 completed in 1217.6s (avg 23.416s/iter)
2025-08-09 07:56:10 Train INFO: [Train]: Final Loss=0.9692
2025-08-09 07:56:10 Train INFO: [Train]: Epoch 56 started (Total iterations: 52)
2025-08-09 08:00:12 Train INFO: [Train]: [056][00005/00051] (11.5%)  Loss=0.9553  cls_loss=0.6703  reg_loss=0.2850  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1859s  iter_time=242.532s  fwd=2.062s/bwd=4.292s/opt=3.094s
2025-08-09 08:01:58 Train INFO: [Train]: [056][00010/00051] (21.2%)  Loss=0.9732  cls_loss=0.6810  reg_loss=0.2923  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1299s  iter_time=105.876s
2025-08-09 08:03:37 Train INFO: [Train]: [056][00015/00051] (30.8%)  Loss=0.9783  cls_loss=0.6812  reg_loss=0.2971  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1007s  iter_time=99.362s
2025-08-09 08:06:08 Train INFO: [Train]: [056][00020/00051] (40.4%)  Loss=0.9651  cls_loss=0.6712  reg_loss=0.2939  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=884s  iter_time=151.010s
2025-08-09 08:07:45 Train INFO: [Train]: [056][00025/00051] (50.0%)  Loss=0.9640  cls_loss=0.6690  reg_loss=0.2950  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=695s  iter_time=96.179s
2025-08-09 08:09:24 Train INFO: [Train]: [056][00030/00051] (59.6%)  Loss=0.9700  cls_loss=0.6727  reg_loss=0.2973  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=538s  iter_time=99.466s
2025-08-09 08:11:06 Train INFO: [Train]: [056][00035/00051] (69.2%)  Loss=0.9708  cls_loss=0.6736  reg_loss=0.2971  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=101.532s
2025-08-09 08:13:44 Train INFO: [Train]: [056][00040/00051] (78.8%)  Loss=0.9742  cls_loss=0.6760  reg_loss=0.2982  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=158.727s
2025-08-09 08:15:38 Train INFO: [Train]: [056][00045/00051] (88.5%)  Loss=0.9694  cls_loss=0.6725  reg_loss=0.2969  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=113.929s
2025-08-09 08:17:19 Train INFO: [Train]: [056][00050/00051] (98.1%)  Loss=0.9747  cls_loss=0.6762  reg_loss=0.2985  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.723s
2025-08-09 08:17:29 Train INFO: [Train]: [056][00051/00051] (100.0%)  Loss=0.9729  cls_loss=0.6746  reg_loss=0.2983  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.350s
2025-08-09 08:17:30 Train INFO: [Train]: Epoch 56 completed in 1280.4s (avg 24.623s/iter)
2025-08-09 08:17:30 Train INFO: [Train]: Final Loss=0.9729
2025-08-09 08:17:30 Train INFO: [Train]: Epoch 57 started (Total iterations: 52)
2025-08-09 08:21:20 Train INFO: [Train]: [057][00005/00051] (11.5%)  Loss=0.9423  cls_loss=0.6509  reg_loss=0.2914  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1762s  iter_time=229.839s  fwd=2.074s/bwd=4.279s/opt=3.079s
2025-08-09 08:23:06 Train INFO: [Train]: [057][00010/00051] (21.2%)  Loss=0.9385  cls_loss=0.6523  reg_loss=0.2861  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1253s  iter_time=106.206s
2025-08-09 08:24:50 Train INFO: [Train]: [057][00015/00051] (30.8%)  Loss=0.9881  cls_loss=0.6829  reg_loss=0.3053  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=991s  iter_time=104.204s
2025-08-09 08:27:22 Train INFO: [Train]: [057][00020/00051] (40.4%)  Loss=0.9900  cls_loss=0.6847  reg_loss=0.3054  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=874s  iter_time=151.993s
2025-08-09 08:29:11 Train INFO: [Train]: [057][00025/00051] (50.0%)  Loss=0.9838  cls_loss=0.6806  reg_loss=0.3032  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=701s  iter_time=109.074s
2025-08-09 08:30:56 Train INFO: [Train]: [057][00030/00051] (59.6%)  Loss=0.9888  cls_loss=0.6842  reg_loss=0.3046  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=546s  iter_time=104.274s
2025-08-09 08:32:44 Train INFO: [Train]: [057][00035/00051] (69.2%)  Loss=0.9782  cls_loss=0.6765  reg_loss=0.3017  lr_backbone=5.7e-06  lr_det=5.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=406s  iter_time=108.770s
2025-08-09 08:35:11 Train INFO: [Train]: [057][00040/00051] (78.8%)  Loss=0.9803  cls_loss=0.6773  reg_loss=0.3030  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=285s  iter_time=146.664s
2025-08-09 08:37:06 Train INFO: [Train]: [057][00045/00051] (88.5%)  Loss=0.9882  cls_loss=0.6833  reg_loss=0.3050  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=114.665s
2025-08-09 08:38:53 Train INFO: [Train]: [057][00050/00051] (98.1%)  Loss=0.9866  cls_loss=0.6824  reg_loss=0.3042  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=107.048s
2025-08-09 08:39:03 Train INFO: [Train]: [057][00051/00051] (100.0%)  Loss=0.9845  cls_loss=0.6811  reg_loss=0.3034  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.365s
2025-08-09 08:39:04 Train INFO: [Train]: Epoch 57 completed in 1293.8s (avg 24.882s/iter)
2025-08-09 08:39:04 Train INFO: [Train]: Final Loss=0.9845
2025-08-09 08:39:04 Train INFO: [Train]: Epoch 58 started (Total iterations: 52)
2025-08-09 08:42:58 Train INFO: [Train]: [058][00005/00051] (11.5%)  Loss=0.9388  cls_loss=0.6533  reg_loss=0.2855  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1794s  iter_time=233.947s  fwd=2.034s/bwd=4.299s/opt=3.095s
2025-08-09 08:44:39 Train INFO: [Train]: [058][00010/00051] (21.2%)  Loss=1.0228  cls_loss=0.7075  reg_loss=0.3154  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1250s  iter_time=101.289s
2025-08-09 08:46:18 Train INFO: [Train]: [058][00015/00051] (30.8%)  Loss=1.0110  cls_loss=0.6966  reg_loss=0.3144  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=977s  iter_time=99.204s
2025-08-09 08:48:45 Train INFO: [Train]: [058][00020/00051] (40.4%)  Loss=0.9920  cls_loss=0.6834  reg_loss=0.3086  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=858s  iter_time=146.901s
2025-08-09 08:50:32 Train INFO: [Train]: [058][00025/00051] (50.0%)  Loss=0.9909  cls_loss=0.6820  reg_loss=0.3089  lr_backbone=5.6e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=688s  iter_time=106.695s
2025-08-09 08:52:15 Train INFO: [Train]: [058][00030/00051] (59.6%)  Loss=0.9938  cls_loss=0.6861  reg_loss=0.3076  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=536s  iter_time=103.369s
2025-08-09 08:53:55 Train INFO: [Train]: [058][00035/00051] (69.2%)  Loss=0.9923  cls_loss=0.6849  reg_loss=0.3074  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=396s  iter_time=99.631s
2025-08-09 08:56:22 Train INFO: [Train]: [058][00040/00051] (78.8%)  Loss=0.9894  cls_loss=0.6827  reg_loss=0.3066  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=147.482s
2025-08-09 08:58:04 Train INFO: [Train]: [058][00045/00051] (88.5%)  Loss=0.9858  cls_loss=0.6802  reg_loss=0.3057  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=101.907s
2025-08-09 08:59:42 Train INFO: [Train]: [058][00050/00051] (98.1%)  Loss=0.9839  cls_loss=0.6799  reg_loss=0.3040  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=97.950s
2025-08-09 08:59:53 Train INFO: [Train]: [058][00051/00051] (100.0%)  Loss=0.9794  cls_loss=0.6768  reg_loss=0.3026  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.367s
2025-08-09 08:59:53 Train INFO: [Train]: Epoch 58 completed in 1249.5s (avg 24.028s/iter)
2025-08-09 08:59:53 Train INFO: [Train]: Final Loss=0.9794
2025-08-09 08:59:53 Train INFO: [Train]: Epoch 59 started (Total iterations: 52)
2025-08-09 09:03:40 Train INFO: [Train]: [059][00005/00051] (11.5%)  Loss=0.9512  cls_loss=0.6501  reg_loss=0.3011  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1737s  iter_time=226.616s  fwd=2.056s/bwd=4.289s/opt=3.082s
2025-08-09 09:05:20 Train INFO: [Train]: [059][00010/00051] (21.2%)  Loss=0.9716  cls_loss=0.6670  reg_loss=0.3046  lr_backbone=5.5e-06  lr_det=5.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1216s  iter_time=99.727s
2025-08-09 09:07:09 Train INFO: [Train]: [059][00015/00051] (30.8%)  Loss=0.9646  cls_loss=0.6660  reg_loss=0.2986  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=981s  iter_time=109.735s
2025-08-09 09:09:41 Train INFO: [Train]: [059][00020/00051] (40.4%)  Loss=0.9796  cls_loss=0.6779  reg_loss=0.3018  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=868s  iter_time=151.689s
2025-08-09 09:11:21 Train INFO: [Train]: [059][00025/00051] (50.0%)  Loss=0.9798  cls_loss=0.6771  reg_loss=0.3027  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=688s  iter_time=100.306s
2025-08-09 09:13:01 Train INFO: [Train]: [059][00030/00051] (59.6%)  Loss=0.9843  cls_loss=0.6812  reg_loss=0.3031  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=99.833s
2025-08-09 09:14:49 Train INFO: [Train]: [059][00035/00051] (69.2%)  Loss=0.9772  cls_loss=0.6756  reg_loss=0.3016  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=107.803s
2025-08-09 09:17:16 Train INFO: [Train]: [059][00040/00051] (78.8%)  Loss=0.9800  cls_loss=0.6786  reg_loss=0.3014  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=146.736s
2025-08-09 09:19:04 Train INFO: [Train]: [059][00045/00051] (88.5%)  Loss=0.9785  cls_loss=0.6777  reg_loss=0.3008  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=108.069s
2025-08-09 09:20:52 Train INFO: [Train]: [059][00050/00051] (98.1%)  Loss=0.9754  cls_loss=0.6755  reg_loss=0.2999  lr_backbone=5.4e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=107.648s
2025-08-09 09:21:02 Train INFO: [Train]: [059][00051/00051] (100.0%)  Loss=0.9742  cls_loss=0.6747  reg_loss=0.2994  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.379s
2025-08-09 09:21:03 Train INFO: [Train]: Epoch 59 completed in 1269.3s (avg 24.409s/iter)
2025-08-09 09:21:03 Train INFO: [Train]: Final Loss=0.9742
2025-08-09 09:21:03 Train INFO: [Val]: Epoch 59 Loss
2025-08-09 10:08:25 Train INFO: [Val]: [059]  Loss=1.0064  cls_loss=0.6936  reg_loss=0.3128  Average-mAP=0.69%
2025-08-09 10:08:27 Train INFO: Checkpoint saved at epoch 59
2025-08-09 10:08:27 Train INFO: [Train]: Epoch 60 started (Total iterations: 52)
2025-08-09 10:12:09 Train INFO: [Train]: [060][00005/00051] (11.5%)  Loss=0.9719  cls_loss=0.6664  reg_loss=0.3055  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1699s  iter_time=221.615s  fwd=2.073s/bwd=4.296s/opt=3.089s
2025-08-09 10:13:56 Train INFO: [Train]: [060][00010/00051] (21.2%)  Loss=0.9745  cls_loss=0.6754  reg_loss=0.2991  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1227s  iter_time=107.637s
2025-08-09 10:15:39 Train INFO: [Train]: [060][00015/00051] (30.8%)  Loss=0.9787  cls_loss=0.6745  reg_loss=0.3042  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=972s  iter_time=102.773s
2025-08-09 10:18:23 Train INFO: [Train]: [060][00020/00051] (40.4%)  Loss=0.9987  cls_loss=0.6857  reg_loss=0.3129  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=879s  iter_time=163.346s
2025-08-09 10:20:09 Train INFO: [Train]: [060][00025/00051] (50.0%)  Loss=0.9909  cls_loss=0.6828  reg_loss=0.3081  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=701s  iter_time=105.966s
2025-08-09 10:22:04 Train INFO: [Train]: [060][00030/00051] (59.6%)  Loss=0.9915  cls_loss=0.6826  reg_loss=0.3089  lr_backbone=5.3e-06  lr_det=5.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=553s  iter_time=115.467s
2025-08-09 10:23:53 Train INFO: [Train]: [060][00035/00051] (69.2%)  Loss=0.9811  cls_loss=0.6743  reg_loss=0.3068  lr_backbone=5.3e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=412s  iter_time=109.324s
2025-08-09 10:26:21 Train INFO: [Train]: [060][00040/00051] (78.8%)  Loss=0.9782  cls_loss=0.6738  reg_loss=0.3044  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=288s  iter_time=147.232s
2025-08-09 10:28:07 Train INFO: [Train]: [060][00045/00051] (88.5%)  Loss=0.9772  cls_loss=0.6735  reg_loss=0.3036  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=106.046s
2025-08-09 10:29:45 Train INFO: [Train]: [060][00050/00051] (98.1%)  Loss=0.9812  cls_loss=0.6770  reg_loss=0.3042  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.405s
2025-08-09 10:29:55 Train INFO: [Train]: [060][00051/00051] (100.0%)  Loss=0.9801  cls_loss=0.6766  reg_loss=0.3035  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.342s
2025-08-09 10:29:56 Train INFO: [Train]: Epoch 60 completed in 1288.9s (avg 24.786s/iter)
2025-08-09 10:29:56 Train INFO: [Train]: Final Loss=0.9801
2025-08-09 10:29:56 Train INFO: [Train]: Epoch 61 started (Total iterations: 52)
2025-08-09 10:33:38 Train INFO: [Train]: [061][00005/00051] (11.5%)  Loss=0.9877  cls_loss=0.6775  reg_loss=0.3103  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1703s  iter_time=222.075s  fwd=2.045s/bwd=4.331s/opt=3.090s
2025-08-09 10:35:16 Train INFO: [Train]: [061][00010/00051] (21.2%)  Loss=0.9914  cls_loss=0.6874  reg_loss=0.3040  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1192s  iter_time=97.608s
2025-08-09 10:36:57 Train INFO: [Train]: [061][00015/00051] (30.8%)  Loss=0.9955  cls_loss=0.6881  reg_loss=0.3074  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=947s  iter_time=101.330s
2025-08-09 10:39:28 Train INFO: [Train]: [061][00020/00051] (40.4%)  Loss=0.9822  cls_loss=0.6783  reg_loss=0.3039  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=844s  iter_time=150.434s
2025-08-09 10:41:17 Train INFO: [Train]: [061][00025/00051] (50.0%)  Loss=0.9848  cls_loss=0.6761  reg_loss=0.3087  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=109.414s
2025-08-09 10:43:02 Train INFO: [Train]: [061][00030/00051] (59.6%)  Loss=0.9944  cls_loss=0.6826  reg_loss=0.3118  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=533s  iter_time=105.279s
2025-08-09 10:44:44 Train INFO: [Train]: [061][00035/00051] (69.2%)  Loss=0.9907  cls_loss=0.6795  reg_loss=0.3112  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=395s  iter_time=102.028s
2025-08-09 10:47:17 Train INFO: [Train]: [061][00040/00051] (78.8%)  Loss=0.9893  cls_loss=0.6792  reg_loss=0.3101  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=153.033s
2025-08-09 10:49:10 Train INFO: [Train]: [061][00045/00051] (88.5%)  Loss=0.9828  cls_loss=0.6753  reg_loss=0.3075  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=112.233s
2025-08-09 10:50:44 Train INFO: [Train]: [061][00050/00051] (98.1%)  Loss=0.9799  cls_loss=0.6734  reg_loss=0.3065  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=94.465s
2025-08-09 10:50:54 Train INFO: [Train]: [061][00051/00051] (100.0%)  Loss=0.9776  cls_loss=0.6718  reg_loss=0.3058  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.359s
2025-08-09 10:50:55 Train INFO: [Train]: Epoch 61 completed in 1259.0s (avg 24.211s/iter)
2025-08-09 10:50:55 Train INFO: [Train]: Final Loss=0.9776
2025-08-09 10:50:55 Train INFO: [Train]: Epoch 62 started (Total iterations: 52)
2025-08-09 10:54:43 Train INFO: [Train]: [062][00005/00051] (11.5%)  Loss=1.0409  cls_loss=0.7270  reg_loss=0.3139  lr_backbone=5.1e-06  lr_det=5.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1749s  iter_time=228.194s  fwd=2.076s/bwd=4.330s/opt=3.066s
2025-08-09 10:56:26 Train INFO: [Train]: [062][00010/00051] (21.2%)  Loss=0.9923  cls_loss=0.6926  reg_loss=0.2996  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1234s  iter_time=102.948s
2025-08-09 10:58:04 Train INFO: [Train]: [062][00015/00051] (30.8%)  Loss=0.9820  cls_loss=0.6818  reg_loss=0.3002  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=965s  iter_time=97.711s
2025-08-09 11:00:56 Train INFO: [Train]: [062][00020/00051] (40.4%)  Loss=0.9797  cls_loss=0.6795  reg_loss=0.3001  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=887s  iter_time=171.908s
2025-08-09 11:02:39 Train INFO: [Train]: [062][00025/00051] (50.0%)  Loss=0.9634  cls_loss=0.6681  reg_loss=0.2953  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=703s  iter_time=102.706s
2025-08-09 11:04:21 Train INFO: [Train]: [062][00030/00051] (59.6%)  Loss=0.9920  cls_loss=0.6870  reg_loss=0.3050  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=546s  iter_time=102.408s
2025-08-09 11:05:58 Train INFO: [Train]: [062][00035/00051] (69.2%)  Loss=0.9847  cls_loss=0.6815  reg_loss=0.3032  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=96.887s
2025-08-09 11:08:28 Train INFO: [Train]: [062][00040/00051] (78.8%)  Loss=0.9816  cls_loss=0.6794  reg_loss=0.3021  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=150.634s
2025-08-09 11:10:21 Train INFO: [Train]: [062][00045/00051] (88.5%)  Loss=0.9743  cls_loss=0.6744  reg_loss=0.2999  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=112.041s
2025-08-09 11:12:03 Train INFO: [Train]: [062][00050/00051] (98.1%)  Loss=0.9767  cls_loss=0.6767  reg_loss=0.3000  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=102.827s
2025-08-09 11:12:14 Train INFO: [Train]: [062][00051/00051] (100.0%)  Loss=0.9743  cls_loss=0.6752  reg_loss=0.2991  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.350s
2025-08-09 11:12:14 Train INFO: [Train]: Epoch 62 completed in 1279.4s (avg 24.603s/iter)
2025-08-09 11:12:14 Train INFO: [Train]: Final Loss=0.9743
2025-08-09 11:12:14 Train INFO: [Train]: Epoch 63 started (Total iterations: 52)
2025-08-09 11:16:02 Train INFO: [Train]: [063][00005/00051] (11.5%)  Loss=0.9628  cls_loss=0.6666  reg_loss=0.2962  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1743s  iter_time=227.410s  fwd=2.042s/bwd=4.283s/opt=3.073s
2025-08-09 11:17:41 Train INFO: [Train]: [063][00010/00051] (21.2%)  Loss=0.9867  cls_loss=0.6819  reg_loss=0.3049  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1216s  iter_time=98.708s
2025-08-09 11:19:28 Train INFO: [Train]: [063][00015/00051] (30.8%)  Loss=0.9925  cls_loss=0.6863  reg_loss=0.3062  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=975s  iter_time=107.011s
2025-08-09 11:22:17 Train INFO: [Train]: [063][00020/00051] (40.4%)  Loss=0.9980  cls_loss=0.6891  reg_loss=0.3089  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=890s  iter_time=169.433s
2025-08-09 11:24:01 Train INFO: [Train]: [063][00025/00051] (50.0%)  Loss=0.9836  cls_loss=0.6804  reg_loss=0.3032  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=707s  iter_time=104.124s
2025-08-09 11:25:48 Train INFO: [Train]: [063][00030/00051] (59.6%)  Loss=0.9963  cls_loss=0.6900  reg_loss=0.3064  lr_backbone=4.9e-06  lr_det=4.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=551s  iter_time=106.715s
2025-08-09 11:27:33 Train INFO: [Train]: [063][00035/00051] (69.2%)  Loss=0.9950  cls_loss=0.6891  reg_loss=0.3059  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=408s  iter_time=105.004s
2025-08-09 11:30:03 Train INFO: [Train]: [063][00040/00051] (78.8%)  Loss=0.9934  cls_loss=0.6882  reg_loss=0.3052  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=149.769s
2025-08-09 11:31:46 Train INFO: [Train]: [063][00045/00051] (88.5%)  Loss=0.9862  cls_loss=0.6845  reg_loss=0.3018  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=103.500s
2025-08-09 11:33:30 Train INFO: [Train]: [063][00050/00051] (98.1%)  Loss=0.9826  cls_loss=0.6826  reg_loss=0.3000  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.337s
2025-08-09 11:33:41 Train INFO: [Train]: [063][00051/00051] (100.0%)  Loss=0.9788  cls_loss=0.6798  reg_loss=0.2990  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.350s
2025-08-09 11:33:41 Train INFO: [Train]: Epoch 63 completed in 1287.1s (avg 24.751s/iter)
2025-08-09 11:33:41 Train INFO: [Train]: Final Loss=0.9788
2025-08-09 11:33:41 Train INFO: [Train]: Epoch 64 started (Total iterations: 52)
2025-08-09 11:37:39 Train INFO: [Train]: [064][00005/00051] (11.5%)  Loss=0.9898  cls_loss=0.6865  reg_loss=0.3034  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1817s  iter_time=237.048s  fwd=2.038s/bwd=4.264s/opt=3.078s
2025-08-09 11:39:16 Train INFO: [Train]: [064][00010/00051] (21.2%)  Loss=0.9710  cls_loss=0.6748  reg_loss=0.2962  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1249s  iter_time=97.924s
2025-08-09 11:40:55 Train INFO: [Train]: [064][00015/00051] (30.8%)  Loss=0.9709  cls_loss=0.6726  reg_loss=0.2983  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=976s  iter_time=98.594s
2025-08-09 11:43:26 Train INFO: [Train]: [064][00020/00051] (40.4%)  Loss=0.9562  cls_loss=0.6618  reg_loss=0.2944  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=863s  iter_time=151.211s
2025-08-09 11:45:03 Train INFO: [Train]: [064][00025/00051] (50.0%)  Loss=0.9685  cls_loss=0.6721  reg_loss=0.2964  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=682s  iter_time=97.140s
2025-08-09 11:46:39 Train INFO: [Train]: [064][00030/00051] (59.6%)  Loss=0.9761  cls_loss=0.6755  reg_loss=0.3006  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=527s  iter_time=95.958s
2025-08-09 11:48:19 Train INFO: [Train]: [064][00035/00051] (69.2%)  Loss=0.9792  cls_loss=0.6766  reg_loss=0.3026  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=390s  iter_time=99.233s
2025-08-09 11:51:00 Train INFO: [Train]: [064][00040/00051] (78.8%)  Loss=0.9828  cls_loss=0.6788  reg_loss=0.3040  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=278s  iter_time=160.922s
2025-08-09 11:52:49 Train INFO: [Train]: [064][00045/00051] (88.5%)  Loss=0.9834  cls_loss=0.6798  reg_loss=0.3036  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=109.529s
2025-08-09 11:54:26 Train INFO: [Train]: [064][00050/00051] (98.1%)  Loss=0.9832  cls_loss=0.6802  reg_loss=0.3030  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=97.174s
2025-08-09 11:54:37 Train INFO: [Train]: [064][00051/00051] (100.0%)  Loss=0.9822  cls_loss=0.6793  reg_loss=0.3029  lr_backbone=4.7e-06  lr_det=4.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.381s
2025-08-09 11:54:37 Train INFO: [Train]: Epoch 64 completed in 1255.8s (avg 24.150s/iter)
2025-08-09 11:54:37 Train INFO: [Train]: Final Loss=0.9822
2025-08-09 11:54:37 Train INFO: [Val]: Epoch 64 Loss
2025-08-09 12:43:08 Train INFO: [Val]: [064]  Loss=1.0060  cls_loss=0.6932  reg_loss=0.3127  Average-mAP=0.63%
2025-08-09 12:43:10 Train INFO: Checkpoint saved at epoch 64
2025-08-09 12:43:10 Train INFO: [Train]: Epoch 65 started (Total iterations: 52)
2025-08-09 12:46:59 Train INFO: [Train]: [065][00005/00051] (11.5%)  Loss=0.9035  cls_loss=0.6264  reg_loss=0.2771  lr_backbone=4.7e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1760s  iter_time=229.570s  fwd=2.065s/bwd=4.279s/opt=3.091s
2025-08-09 12:48:44 Train INFO: [Train]: [065][00010/00051] (21.2%)  Loss=0.9579  cls_loss=0.6636  reg_loss=0.2943  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1248s  iter_time=105.269s
2025-08-09 12:50:29 Train INFO: [Train]: [065][00015/00051] (30.8%)  Loss=0.9643  cls_loss=0.6619  reg_loss=0.3024  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=988s  iter_time=104.218s
2025-08-09 12:53:19 Train INFO: [Train]: [065][00020/00051] (40.4%)  Loss=0.9585  cls_loss=0.6554  reg_loss=0.3031  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=900s  iter_time=170.382s
2025-08-09 12:54:59 Train INFO: [Train]: [065][00025/00051] (50.0%)  Loss=0.9758  cls_loss=0.6695  reg_loss=0.3064  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=710s  iter_time=100.081s
2025-08-09 12:56:52 Train INFO: [Train]: [065][00030/00051] (59.6%)  Loss=0.9802  cls_loss=0.6728  reg_loss=0.3075  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=557s  iter_time=112.503s
2025-08-09 12:58:43 Train INFO: [Train]: [065][00035/00051] (69.2%)  Loss=0.9676  cls_loss=0.6635  reg_loss=0.3041  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=415s  iter_time=111.290s
2025-08-09 13:01:20 Train INFO: [Train]: [065][00040/00051] (78.8%)  Loss=0.9661  cls_loss=0.6628  reg_loss=0.3033  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=292s  iter_time=156.694s
2025-08-09 13:03:03 Train INFO: [Train]: [065][00045/00051] (88.5%)  Loss=0.9628  cls_loss=0.6620  reg_loss=0.3008  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=156s  iter_time=103.765s
2025-08-09 13:04:46 Train INFO: [Train]: [065][00050/00051] (98.1%)  Loss=0.9666  cls_loss=0.6651  reg_loss=0.3015  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=102.924s
2025-08-09 13:04:57 Train INFO: [Train]: [065][00051/00051] (100.0%)  Loss=0.9665  cls_loss=0.6651  reg_loss=0.3014  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.355s
2025-08-09 13:04:57 Train INFO: [Train]: Epoch 65 completed in 1307.8s (avg 25.150s/iter)
2025-08-09 13:04:57 Train INFO: [Train]: Final Loss=0.9665
2025-08-09 13:04:57 Train INFO: [Train]: Epoch 66 started (Total iterations: 52)
2025-08-09 13:08:46 Train INFO: [Train]: [066][00005/00051] (11.5%)  Loss=0.9813  cls_loss=0.6714  reg_loss=0.3099  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1753s  iter_time=228.628s  fwd=2.018s/bwd=4.260s/opt=3.087s
2025-08-09 13:10:34 Train INFO: [Train]: [066][00010/00051] (21.2%)  Loss=0.9743  cls_loss=0.6723  reg_loss=0.3019  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1256s  iter_time=108.402s
2025-08-09 13:12:16 Train INFO: [Train]: [066][00015/00051] (30.8%)  Loss=0.9838  cls_loss=0.6784  reg_loss=0.3053  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=986s  iter_time=101.143s
2025-08-09 13:14:55 Train INFO: [Train]: [066][00020/00051] (40.4%)  Loss=0.9726  cls_loss=0.6720  reg_loss=0.3006  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=882s  iter_time=159.130s
2025-08-09 13:16:37 Train INFO: [Train]: [066][00025/00051] (50.0%)  Loss=0.9711  cls_loss=0.6722  reg_loss=0.2989  lr_backbone=4.5e-06  lr_det=4.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=700s  iter_time=102.351s
2025-08-09 13:18:20 Train INFO: [Train]: [066][00030/00051] (59.6%)  Loss=0.9765  cls_loss=0.6763  reg_loss=0.3001  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=102.527s
2025-08-09 13:20:02 Train INFO: [Train]: [066][00035/00051] (69.2%)  Loss=0.9851  cls_loss=0.6815  reg_loss=0.3037  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=102.393s
2025-08-09 13:22:38 Train INFO: [Train]: [066][00040/00051] (78.8%)  Loss=0.9810  cls_loss=0.6794  reg_loss=0.3015  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=155.634s
2025-08-09 13:24:26 Train INFO: [Train]: [066][00045/00051] (88.5%)  Loss=0.9785  cls_loss=0.6784  reg_loss=0.3001  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=108.306s
2025-08-09 13:26:14 Train INFO: [Train]: [066][00050/00051] (98.1%)  Loss=0.9840  cls_loss=0.6820  reg_loss=0.3021  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=108.563s
2025-08-09 13:26:25 Train INFO: [Train]: [066][00051/00051] (100.0%)  Loss=0.9828  cls_loss=0.6813  reg_loss=0.3015  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.344s
2025-08-09 13:26:26 Train INFO: [Train]: Epoch 66 completed in 1288.2s (avg 24.772s/iter)
2025-08-09 13:26:26 Train INFO: [Train]: Final Loss=0.9828
2025-08-09 13:26:26 Train INFO: [Train]: Epoch 67 started (Total iterations: 52)
2025-08-09 13:30:31 Train INFO: [Train]: [067][00005/00051] (11.5%)  Loss=0.9120  cls_loss=0.6303  reg_loss=0.2817  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1878s  iter_time=245.005s  fwd=2.055s/bwd=4.323s/opt=3.092s
2025-08-09 13:32:16 Train INFO: [Train]: [067][00010/00051] (21.2%)  Loss=0.9438  cls_loss=0.6549  reg_loss=0.2889  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1306s  iter_time=105.475s
2025-08-09 13:34:03 Train INFO: [Train]: [067][00015/00051] (30.8%)  Loss=0.9666  cls_loss=0.6685  reg_loss=0.2982  lr_backbone=4.4e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1029s  iter_time=107.020s
2025-08-09 13:36:34 Train INFO: [Train]: [067][00020/00051] (40.4%)  Loss=0.9617  cls_loss=0.6648  reg_loss=0.2969  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=899s  iter_time=151.189s
2025-08-09 13:38:24 Train INFO: [Train]: [067][00025/00051] (50.0%)  Loss=0.9559  cls_loss=0.6623  reg_loss=0.2936  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=718s  iter_time=109.598s
2025-08-09 13:40:14 Train INFO: [Train]: [067][00030/00051] (59.6%)  Loss=0.9603  cls_loss=0.6654  reg_loss=0.2948  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=561s  iter_time=110.439s
2025-08-09 13:42:02 Train INFO: [Train]: [067][00035/00051] (69.2%)  Loss=0.9740  cls_loss=0.6749  reg_loss=0.2991  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=416s  iter_time=108.126s
2025-08-09 13:44:36 Train INFO: [Train]: [067][00040/00051] (78.8%)  Loss=0.9682  cls_loss=0.6699  reg_loss=0.2982  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=292s  iter_time=153.262s
2025-08-09 13:46:27 Train INFO: [Train]: [067][00045/00051] (88.5%)  Loss=0.9700  cls_loss=0.6710  reg_loss=0.2990  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=157s  iter_time=111.393s
2025-08-09 13:48:16 Train INFO: [Train]: [067][00050/00051] (98.1%)  Loss=0.9795  cls_loss=0.6779  reg_loss=0.3017  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=26s  iter_time=108.953s
2025-08-09 13:48:26 Train INFO: [Train]: [067][00051/00051] (100.0%)  Loss=0.9807  cls_loss=0.6785  reg_loss=0.3022  lr_backbone=4.3e-06  lr_det=4.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.355s
2025-08-09 13:48:27 Train INFO: [Train]: Epoch 67 completed in 1321.6s (avg 25.415s/iter)
2025-08-09 13:48:27 Train INFO: [Train]: Final Loss=0.9807
2025-08-09 13:48:27 Train INFO: [Train]: Epoch 68 started (Total iterations: 52)
2025-08-09 13:52:28 Train INFO: [Train]: [068][00005/00051] (11.5%)  Loss=0.9101  cls_loss=0.6343  reg_loss=0.2758  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1848s  iter_time=241.058s  fwd=2.077s/bwd=4.299s/opt=3.084s
2025-08-09 13:54:16 Train INFO: [Train]: [068][00010/00051] (21.2%)  Loss=0.9137  cls_loss=0.6358  reg_loss=0.2779  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1301s  iter_time=107.871s
2025-08-09 13:56:05 Train INFO: [Train]: [068][00015/00051] (30.8%)  Loss=0.9656  cls_loss=0.6686  reg_loss=0.2970  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1030s  iter_time=108.963s
2025-08-09 13:58:42 Train INFO: [Train]: [068][00020/00051] (40.4%)  Loss=0.9629  cls_loss=0.6679  reg_loss=0.2950  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=907s  iter_time=156.729s
2025-08-09 14:00:29 Train INFO: [Train]: [068][00025/00051] (50.0%)  Loss=0.9504  cls_loss=0.6588  reg_loss=0.2916  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=722s  iter_time=107.558s
2025-08-09 14:02:20 Train INFO: [Train]: [068][00030/00051] (59.6%)  Loss=0.9648  cls_loss=0.6684  reg_loss=0.2965  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=564s  iter_time=110.846s
2025-08-09 14:04:07 Train INFO: [Train]: [068][00035/00051] (69.2%)  Loss=0.9732  cls_loss=0.6728  reg_loss=0.3004  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=418s  iter_time=106.642s
2025-08-09 14:06:47 Train INFO: [Train]: [068][00040/00051] (78.8%)  Loss=0.9654  cls_loss=0.6668  reg_loss=0.2986  lr_backbone=4.2e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=295s  iter_time=160.614s
2025-08-09 14:08:28 Train INFO: [Train]: [068][00045/00051] (88.5%)  Loss=0.9595  cls_loss=0.6632  reg_loss=0.2963  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=157s  iter_time=100.741s
2025-08-09 14:10:06 Train INFO: [Train]: [068][00050/00051] (98.1%)  Loss=0.9619  cls_loss=0.6647  reg_loss=0.2972  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=97.793s
2025-08-09 14:10:16 Train INFO: [Train]: [068][00051/00051] (100.0%)  Loss=0.9679  cls_loss=0.6681  reg_loss=0.2998  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.349s
2025-08-09 14:10:17 Train INFO: [Train]: Epoch 68 completed in 1309.9s (avg 25.190s/iter)
2025-08-09 14:10:17 Train INFO: [Train]: Final Loss=0.9679
2025-08-09 14:10:17 Train INFO: [Train]: Epoch 69 started (Total iterations: 52)
2025-08-09 14:14:14 Train INFO: [Train]: [069][00005/00051] (11.5%)  Loss=0.9099  cls_loss=0.6304  reg_loss=0.2794  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1813s  iter_time=236.487s  fwd=2.098s/bwd=4.350s/opt=3.086s
2025-08-09 14:16:00 Train INFO: [Train]: [069][00010/00051] (21.2%)  Loss=0.9602  cls_loss=0.6656  reg_loss=0.2947  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1280s  iter_time=106.891s
2025-08-09 14:17:51 Train INFO: [Train]: [069][00015/00051] (30.8%)  Loss=0.9462  cls_loss=0.6582  reg_loss=0.2880  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1021s  iter_time=110.500s
2025-08-09 14:20:14 Train INFO: [Train]: [069][00020/00051] (40.4%)  Loss=0.9808  cls_loss=0.6808  reg_loss=0.3000  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=881s  iter_time=143.203s
2025-08-09 14:21:55 Train INFO: [Train]: [069][00025/00051] (50.0%)  Loss=0.9687  cls_loss=0.6712  reg_loss=0.2974  lr_backbone=4.1e-06  lr_det=4.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=101.342s
2025-08-09 14:23:43 Train INFO: [Train]: [069][00030/00051] (59.6%)  Loss=0.9829  cls_loss=0.6808  reg_loss=0.3021  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=546s  iter_time=107.617s
2025-08-09 14:25:22 Train INFO: [Train]: [069][00035/00051] (69.2%)  Loss=0.9731  cls_loss=0.6747  reg_loss=0.2984  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=98.441s
2025-08-09 14:27:46 Train INFO: [Train]: [069][00040/00051] (78.8%)  Loss=0.9751  cls_loss=0.6751  reg_loss=0.3000  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=144.089s
2025-08-09 14:29:29 Train INFO: [Train]: [069][00045/00051] (88.5%)  Loss=0.9767  cls_loss=0.6756  reg_loss=0.3011  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=103.735s
2025-08-09 14:31:12 Train INFO: [Train]: [069][00050/00051] (98.1%)  Loss=0.9702  cls_loss=0.6711  reg_loss=0.2991  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=102.514s
2025-08-09 14:31:22 Train INFO: [Train]: [069][00051/00051] (100.0%)  Loss=0.9674  cls_loss=0.6691  reg_loss=0.2984  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.362s
2025-08-09 14:31:23 Train INFO: [Train]: Epoch 69 completed in 1265.9s (avg 24.344s/iter)
2025-08-09 14:31:23 Train INFO: [Train]: Final Loss=0.9674
2025-08-09 14:31:23 Train INFO: [Val]: Epoch 69 Loss
2025-08-09 15:18:54 Train INFO: [Val]: [069]  Loss=1.0060  cls_loss=0.6933  reg_loss=0.3127  Average-mAP=0.68%
2025-08-09 15:18:56 Train INFO: Checkpoint saved at epoch 69
2025-08-09 15:18:56 Train INFO: [Train]: Epoch 70 started (Total iterations: 52)
2025-08-09 15:22:35 Train INFO: [Train]: [070][00005/00051] (11.5%)  Loss=0.9472  cls_loss=0.6527  reg_loss=0.2945  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1680s  iter_time=219.071s  fwd=2.080s/bwd=4.304s/opt=3.079s
2025-08-09 15:24:18 Train INFO: [Train]: [070][00010/00051] (21.2%)  Loss=1.0061  cls_loss=0.6908  reg_loss=0.3153  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1201s  iter_time=103.270s
2025-08-09 15:26:01 Train INFO: [Train]: [070][00015/00051] (30.8%)  Loss=1.0052  cls_loss=0.6914  reg_loss=0.3138  lr_backbone=4.0e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=956s  iter_time=102.595s
2025-08-09 15:28:33 Train INFO: [Train]: [070][00020/00051] (40.4%)  Loss=0.9737  cls_loss=0.6728  reg_loss=0.3009  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=852s  iter_time=152.264s
2025-08-09 15:30:13 Train INFO: [Train]: [070][00025/00051] (50.0%)  Loss=0.9921  cls_loss=0.6835  reg_loss=0.3085  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=677s  iter_time=100.136s
2025-08-09 15:31:54 Train INFO: [Train]: [070][00030/00051] (59.6%)  Loss=0.9928  cls_loss=0.6842  reg_loss=0.3086  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=527s  iter_time=100.709s
2025-08-09 15:33:32 Train INFO: [Train]: [070][00035/00051] (69.2%)  Loss=0.9938  cls_loss=0.6842  reg_loss=0.3097  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=390s  iter_time=98.682s
2025-08-09 15:36:02 Train INFO: [Train]: [070][00040/00051] (78.8%)  Loss=0.9837  cls_loss=0.6767  reg_loss=0.3070  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=275s  iter_time=149.283s
2025-08-09 15:37:53 Train INFO: [Train]: [070][00045/00051] (88.5%)  Loss=0.9801  cls_loss=0.6751  reg_loss=0.3050  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=148s  iter_time=110.934s
2025-08-09 15:39:22 Train INFO: [Train]: [070][00050/00051] (98.1%)  Loss=0.9802  cls_loss=0.6748  reg_loss=0.3054  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=89.608s
2025-08-09 15:39:33 Train INFO: [Train]: [070][00051/00051] (100.0%)  Loss=0.9757  cls_loss=0.6718  reg_loss=0.3039  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.381s
2025-08-09 15:39:33 Train INFO: [Train]: Epoch 70 completed in 1237.7s (avg 23.801s/iter)
2025-08-09 15:39:33 Train INFO: [Train]: Final Loss=0.9757
2025-08-09 15:39:33 Train INFO: [Train]: Epoch 71 started (Total iterations: 52)
2025-08-09 15:43:23 Train INFO: [Train]: [071][00005/00051] (11.5%)  Loss=0.9856  cls_loss=0.6848  reg_loss=0.3009  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1764s  iter_time=230.026s  fwd=2.092s/bwd=4.326s/opt=3.084s
2025-08-09 15:45:10 Train INFO: [Train]: [071][00010/00051] (21.2%)  Loss=0.9684  cls_loss=0.6738  reg_loss=0.2946  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1255s  iter_time=106.597s
2025-08-09 15:46:48 Train INFO: [Train]: [071][00015/00051] (30.8%)  Loss=0.9508  cls_loss=0.6591  reg_loss=0.2917  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=979s  iter_time=98.440s
2025-08-09 15:49:13 Train INFO: [Train]: [071][00020/00051] (40.4%)  Loss=0.9651  cls_loss=0.6675  reg_loss=0.2977  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=856s  iter_time=144.652s
2025-08-09 15:50:54 Train INFO: [Train]: [071][00025/00051] (50.0%)  Loss=0.9957  cls_loss=0.6878  reg_loss=0.3079  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=100.690s
2025-08-09 15:52:38 Train INFO: [Train]: [071][00030/00051] (59.6%)  Loss=0.9850  cls_loss=0.6804  reg_loss=0.3045  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=532s  iter_time=104.489s
2025-08-09 15:54:26 Train INFO: [Train]: [071][00035/00051] (69.2%)  Loss=0.9776  cls_loss=0.6747  reg_loss=0.3029  lr_backbone=3.8e-06  lr_det=3.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=107.568s
2025-08-09 15:57:04 Train INFO: [Train]: [071][00040/00051] (78.8%)  Loss=0.9774  cls_loss=0.6758  reg_loss=0.3016  lr_backbone=3.8e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=158.103s
2025-08-09 15:58:52 Train INFO: [Train]: [071][00045/00051] (88.5%)  Loss=0.9816  cls_loss=0.6794  reg_loss=0.3023  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=108.272s
2025-08-09 16:00:29 Train INFO: [Train]: [071][00050/00051] (98.1%)  Loss=0.9854  cls_loss=0.6817  reg_loss=0.3036  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=96.363s
2025-08-09 16:00:39 Train INFO: [Train]: [071][00051/00051] (100.0%)  Loss=0.9866  cls_loss=0.6823  reg_loss=0.3043  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.349s
2025-08-09 16:00:40 Train INFO: [Train]: Epoch 71 completed in 1266.3s (avg 24.352s/iter)
2025-08-09 16:00:40 Train INFO: [Train]: Final Loss=0.9866
2025-08-09 16:00:40 Train INFO: [Train]: Epoch 72 started (Total iterations: 52)
2025-08-09 16:04:21 Train INFO: [Train]: [072][00005/00051] (11.5%)  Loss=1.0086  cls_loss=0.6943  reg_loss=0.3143  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1694s  iter_time=221.003s  fwd=2.067s/bwd=4.283s/opt=3.082s
2025-08-09 16:06:00 Train INFO: [Train]: [072][00010/00051] (21.2%)  Loss=0.9636  cls_loss=0.6668  reg_loss=0.2968  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1194s  iter_time=99.335s
2025-08-09 16:07:39 Train INFO: [Train]: [072][00015/00051] (30.8%)  Loss=0.9551  cls_loss=0.6631  reg_loss=0.2920  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=944s  iter_time=99.178s
2025-08-09 16:10:13 Train INFO: [Train]: [072][00020/00051] (40.4%)  Loss=0.9632  cls_loss=0.6685  reg_loss=0.2947  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=846s  iter_time=153.442s
2025-08-09 16:12:01 Train INFO: [Train]: [072][00025/00051] (50.0%)  Loss=0.9677  cls_loss=0.6703  reg_loss=0.2974  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=108.526s
2025-08-09 16:13:47 Train INFO: [Train]: [072][00030/00051] (59.6%)  Loss=0.9734  cls_loss=0.6736  reg_loss=0.2998  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=533s  iter_time=105.479s
2025-08-09 16:15:29 Train INFO: [Train]: [072][00035/00051] (69.2%)  Loss=0.9705  cls_loss=0.6726  reg_loss=0.2979  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=395s  iter_time=102.573s
2025-08-09 16:17:59 Train INFO: [Train]: [072][00040/00051] (78.8%)  Loss=0.9778  cls_loss=0.6774  reg_loss=0.3005  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=150.248s
2025-08-09 16:19:50 Train INFO: [Train]: [072][00045/00051] (88.5%)  Loss=0.9683  cls_loss=0.6714  reg_loss=0.2969  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=110.179s
2025-08-09 16:21:29 Train INFO: [Train]: [072][00050/00051] (98.1%)  Loss=0.9679  cls_loss=0.6707  reg_loss=0.2972  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=99.190s
2025-08-09 16:21:39 Train INFO: [Train]: [072][00051/00051] (100.0%)  Loss=0.9676  cls_loss=0.6704  reg_loss=0.2972  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.372s
2025-08-09 16:21:40 Train INFO: [Train]: Epoch 72 completed in 1260.2s (avg 24.235s/iter)
2025-08-09 16:21:40 Train INFO: [Train]: Final Loss=0.9676
2025-08-09 16:21:40 Train INFO: [Train]: Epoch 73 started (Total iterations: 52)
2025-08-09 16:25:31 Train INFO: [Train]: [073][00005/00051] (11.5%)  Loss=0.9723  cls_loss=0.6764  reg_loss=0.2959  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1774s  iter_time=231.420s  fwd=2.066s/bwd=4.322s/opt=3.079s
2025-08-09 16:27:09 Train INFO: [Train]: [073][00010/00051] (21.2%)  Loss=0.9720  cls_loss=0.6746  reg_loss=0.2973  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1226s  iter_time=97.430s
2025-08-09 16:28:50 Train INFO: [Train]: [073][00015/00051] (30.8%)  Loss=0.9762  cls_loss=0.6764  reg_loss=0.2998  lr_backbone=3.6e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=967s  iter_time=100.997s
2025-08-09 16:31:22 Train INFO: [Train]: [073][00020/00051] (40.4%)  Loss=0.9746  cls_loss=0.6747  reg_loss=0.3000  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=860s  iter_time=152.608s
2025-08-09 16:33:11 Train INFO: [Train]: [073][00025/00051] (50.0%)  Loss=0.9814  cls_loss=0.6799  reg_loss=0.3014  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=108.267s
2025-08-09 16:34:52 Train INFO: [Train]: [073][00030/00051] (59.6%)  Loss=0.9652  cls_loss=0.6680  reg_loss=0.2972  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=536s  iter_time=101.165s
2025-08-09 16:36:33 Train INFO: [Train]: [073][00035/00051] (69.2%)  Loss=0.9660  cls_loss=0.6679  reg_loss=0.2981  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=100.862s
2025-08-09 16:39:01 Train INFO: [Train]: [073][00040/00051] (78.8%)  Loss=0.9699  cls_loss=0.6703  reg_loss=0.2996  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=148.533s
2025-08-09 16:40:42 Train INFO: [Train]: [073][00045/00051] (88.5%)  Loss=0.9736  cls_loss=0.6727  reg_loss=0.3009  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=100.308s
2025-08-09 16:42:23 Train INFO: [Train]: [073][00050/00051] (98.1%)  Loss=0.9765  cls_loss=0.6740  reg_loss=0.3024  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=101.582s
2025-08-09 16:42:33 Train INFO: [Train]: [073][00051/00051] (100.0%)  Loss=0.9748  cls_loss=0.6729  reg_loss=0.3019  lr_backbone=3.5e-06  lr_det=3.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.354s
2025-08-09 16:42:34 Train INFO: [Train]: Epoch 73 completed in 1254.3s (avg 24.120s/iter)
2025-08-09 16:42:34 Train INFO: [Train]: Final Loss=0.9748
2025-08-09 16:42:34 Train INFO: [Train]: Epoch 74 started (Total iterations: 52)
2025-08-09 16:46:34 Train INFO: [Train]: [074][00005/00051] (11.5%)  Loss=0.9319  cls_loss=0.6468  reg_loss=0.2851  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1838s  iter_time=239.731s  fwd=2.029s/bwd=4.259s/opt=3.080s
2025-08-09 16:48:14 Train INFO: [Train]: [074][00010/00051] (21.2%)  Loss=0.9505  cls_loss=0.6619  reg_loss=0.2886  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1268s  iter_time=100.586s
2025-08-09 16:50:04 Train INFO: [Train]: [074][00015/00051] (30.8%)  Loss=0.9581  cls_loss=0.6661  reg_loss=0.2919  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1012s  iter_time=109.574s
2025-08-09 16:52:35 Train INFO: [Train]: [074][00020/00051] (40.4%)  Loss=0.9468  cls_loss=0.6578  reg_loss=0.2890  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=886s  iter_time=150.502s
2025-08-09 16:54:11 Train INFO: [Train]: [074][00025/00051] (50.0%)  Loss=0.9517  cls_loss=0.6612  reg_loss=0.2905  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=697s  iter_time=96.196s
2025-08-09 16:55:56 Train INFO: [Train]: [074][00030/00051] (59.6%)  Loss=0.9729  cls_loss=0.6759  reg_loss=0.2970  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=104.805s
2025-08-09 16:57:39 Train INFO: [Train]: [074][00035/00051] (69.2%)  Loss=0.9740  cls_loss=0.6757  reg_loss=0.2982  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=103.336s
2025-08-09 17:00:09 Train INFO: [Train]: [074][00040/00051] (78.8%)  Loss=0.9646  cls_loss=0.6688  reg_loss=0.2958  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=149.687s
2025-08-09 17:01:49 Train INFO: [Train]: [074][00045/00051] (88.5%)  Loss=0.9655  cls_loss=0.6698  reg_loss=0.2957  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=100.192s
2025-08-09 17:03:26 Train INFO: [Train]: [074][00050/00051] (98.1%)  Loss=0.9703  cls_loss=0.6725  reg_loss=0.2978  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=97.056s
2025-08-09 17:03:36 Train INFO: [Train]: [074][00051/00051] (100.0%)  Loss=0.9725  cls_loss=0.6740  reg_loss=0.2985  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.345s
2025-08-09 17:03:37 Train INFO: [Train]: Epoch 74 completed in 1262.7s (avg 24.284s/iter)
2025-08-09 17:03:37 Train INFO: [Train]: Final Loss=0.9725
2025-08-09 17:03:37 Train INFO: [Val]: Epoch 74 Loss
2025-08-09 17:51:10 Train INFO: [Val]: [074]  Loss=1.0059  cls_loss=0.6933  reg_loss=0.3126  Average-mAP=0.67%
2025-08-09 17:51:12 Train INFO: Checkpoint saved at epoch 74
2025-08-09 17:51:12 Train INFO: [Train]: Epoch 75 started (Total iterations: 52)
2025-08-09 17:54:59 Train INFO: [Train]: [075][00005/00051] (11.5%)  Loss=0.9761  cls_loss=0.6754  reg_loss=0.3007  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1737s  iter_time=226.625s  fwd=2.058s/bwd=4.307s/opt=3.078s
2025-08-09 17:56:51 Train INFO: [Train]: [075][00010/00051] (21.2%)  Loss=1.0000  cls_loss=0.6925  reg_loss=0.3075  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1261s  iter_time=111.697s
2025-08-09 17:58:36 Train INFO: [Train]: [075][00015/00051] (30.8%)  Loss=0.9961  cls_loss=0.6873  reg_loss=0.3088  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=997s  iter_time=104.873s
2025-08-09 18:01:06 Train INFO: [Train]: [075][00020/00051] (40.4%)  Loss=0.9785  cls_loss=0.6749  reg_loss=0.3035  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=877s  iter_time=150.637s
2025-08-09 18:02:53 Train INFO: [Train]: [075][00025/00051] (50.0%)  Loss=0.9943  cls_loss=0.6853  reg_loss=0.3090  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=701s  iter_time=106.807s
2025-08-09 18:04:35 Train INFO: [Train]: [075][00030/00051] (59.6%)  Loss=0.9902  cls_loss=0.6826  reg_loss=0.3077  lr_backbone=3.3e-06  lr_det=3.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=544s  iter_time=102.188s
2025-08-09 18:06:17 Train INFO: [Train]: [075][00035/00051] (69.2%)  Loss=0.9921  cls_loss=0.6841  reg_loss=0.3081  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=101.295s
2025-08-09 18:08:50 Train INFO: [Train]: [075][00040/00051] (78.8%)  Loss=0.9847  cls_loss=0.6796  reg_loss=0.3051  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=153.199s
2025-08-09 18:10:31 Train INFO: [Train]: [075][00045/00051] (88.5%)  Loss=0.9790  cls_loss=0.6769  reg_loss=0.3020  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=101.331s
2025-08-09 18:12:16 Train INFO: [Train]: [075][00050/00051] (98.1%)  Loss=0.9775  cls_loss=0.6763  reg_loss=0.3012  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.609s
2025-08-09 18:12:26 Train INFO: [Train]: [075][00051/00051] (100.0%)  Loss=0.9749  cls_loss=0.6743  reg_loss=0.3006  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-09 18:12:27 Train INFO: [Train]: Epoch 75 completed in 1274.3s (avg 24.507s/iter)
2025-08-09 18:12:27 Train INFO: [Train]: Final Loss=0.9749
2025-08-09 18:12:27 Train INFO: [Train]: Epoch 76 started (Total iterations: 52)
2025-08-09 18:16:12 Train INFO: [Train]: [076][00005/00051] (11.5%)  Loss=0.9814  cls_loss=0.6791  reg_loss=0.3024  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1725s  iter_time=224.958s  fwd=2.083s/bwd=4.322s/opt=3.083s
2025-08-09 18:17:55 Train INFO: [Train]: [076][00010/00051] (21.2%)  Loss=0.9660  cls_loss=0.6697  reg_loss=0.2963  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1224s  iter_time=103.548s
2025-08-09 18:19:39 Train INFO: [Train]: [076][00015/00051] (30.8%)  Loss=0.9921  cls_loss=0.6885  reg_loss=0.3036  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=972s  iter_time=103.451s
2025-08-09 18:22:00 Train INFO: [Train]: [076][00020/00051] (40.4%)  Loss=0.9860  cls_loss=0.6841  reg_loss=0.3019  lr_backbone=3.2e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=846s  iter_time=141.079s
2025-08-09 18:23:48 Train INFO: [Train]: [076][00025/00051] (50.0%)  Loss=0.9770  cls_loss=0.6779  reg_loss=0.2991  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=108.163s
2025-08-09 18:25:29 Train INFO: [Train]: [076][00030/00051] (59.6%)  Loss=0.9801  cls_loss=0.6804  reg_loss=0.2997  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=530s  iter_time=100.655s
2025-08-09 18:27:07 Train INFO: [Train]: [076][00035/00051] (69.2%)  Loss=0.9634  cls_loss=0.6686  reg_loss=0.2948  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=391s  iter_time=98.097s
2025-08-09 18:29:37 Train INFO: [Train]: [076][00040/00051] (78.8%)  Loss=0.9640  cls_loss=0.6694  reg_loss=0.2946  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=150.759s
2025-08-09 18:31:17 Train INFO: [Train]: [076][00045/00051] (88.5%)  Loss=0.9655  cls_loss=0.6706  reg_loss=0.2949  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=99.150s
2025-08-09 18:32:57 Train INFO: [Train]: [076][00050/00051] (98.1%)  Loss=0.9729  cls_loss=0.6751  reg_loss=0.2978  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=100.167s
2025-08-09 18:33:07 Train INFO: [Train]: [076][00051/00051] (100.0%)  Loss=0.9736  cls_loss=0.6756  reg_loss=0.2980  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.358s
2025-08-09 18:33:08 Train INFO: [Train]: Epoch 76 completed in 1241.1s (avg 23.868s/iter)
2025-08-09 18:33:08 Train INFO: [Train]: Final Loss=0.9736
2025-08-09 18:33:08 Train INFO: [Train]: Epoch 77 started (Total iterations: 52)
2025-08-09 18:36:56 Train INFO: [Train]: [077][00005/00051] (11.5%)  Loss=0.9819  cls_loss=0.6782  reg_loss=0.3036  lr_backbone=3.1e-06  lr_det=3.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1750s  iter_time=228.218s  fwd=2.034s/bwd=4.264s/opt=3.095s
2025-08-09 18:38:41 Train INFO: [Train]: [077][00010/00051] (21.2%)  Loss=0.9862  cls_loss=0.6840  reg_loss=0.3021  lr_backbone=3.1e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1240s  iter_time=104.459s
2025-08-09 18:40:23 Train INFO: [Train]: [077][00015/00051] (30.8%)  Loss=0.9818  cls_loss=0.6795  reg_loss=0.3023  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=980s  iter_time=102.738s
2025-08-09 18:42:46 Train INFO: [Train]: [077][00020/00051] (40.4%)  Loss=0.9558  cls_loss=0.6631  reg_loss=0.2927  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=853s  iter_time=142.531s
2025-08-09 18:44:27 Train INFO: [Train]: [077][00025/00051] (50.0%)  Loss=0.9785  cls_loss=0.6770  reg_loss=0.3016  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=679s  iter_time=100.879s
2025-08-09 18:46:10 Train INFO: [Train]: [077][00030/00051] (59.6%)  Loss=0.9820  cls_loss=0.6789  reg_loss=0.3031  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=529s  iter_time=102.802s
2025-08-09 18:47:48 Train INFO: [Train]: [077][00035/00051] (69.2%)  Loss=0.9757  cls_loss=0.6744  reg_loss=0.3013  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=391s  iter_time=98.894s
2025-08-09 18:50:13 Train INFO: [Train]: [077][00040/00051] (78.8%)  Loss=0.9724  cls_loss=0.6723  reg_loss=0.3001  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=275s  iter_time=144.790s
2025-08-09 18:51:58 Train INFO: [Train]: [077][00045/00051] (88.5%)  Loss=0.9746  cls_loss=0.6737  reg_loss=0.3009  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=105.197s
2025-08-09 18:53:41 Train INFO: [Train]: [077][00050/00051] (98.1%)  Loss=0.9778  cls_loss=0.6754  reg_loss=0.3024  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=102.817s
2025-08-09 18:53:52 Train INFO: [Train]: [077][00051/00051] (100.0%)  Loss=0.9744  cls_loss=0.6732  reg_loss=0.3012  lr_backbone=3.0e-06  lr_det=2.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.355s
2025-08-09 18:53:52 Train INFO: [Train]: Epoch 77 completed in 1244.5s (avg 23.933s/iter)
2025-08-09 18:53:52 Train INFO: [Train]: Final Loss=0.9744
2025-08-09 18:53:52 Train INFO: [Train]: Epoch 78 started (Total iterations: 52)
2025-08-09 18:57:33 Train INFO: [Train]: [078][00005/00051] (11.5%)  Loss=0.9701  cls_loss=0.6684  reg_loss=0.3017  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1694s  iter_time=220.957s  fwd=2.092s/bwd=4.343s/opt=3.078s
2025-08-09 18:59:22 Train INFO: [Train]: [078][00010/00051] (21.2%)  Loss=0.9420  cls_loss=0.6512  reg_loss=0.2908  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1228s  iter_time=108.481s
2025-08-09 19:01:11 Train INFO: [Train]: [078][00015/00051] (30.8%)  Loss=1.0016  cls_loss=0.6928  reg_loss=0.3088  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=986s  iter_time=109.001s
2025-08-09 19:03:47 Train INFO: [Train]: [078][00020/00051] (40.4%)  Loss=0.9782  cls_loss=0.6774  reg_loss=0.3008  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=877s  iter_time=155.730s
2025-08-09 19:05:33 Train INFO: [Train]: [078][00025/00051] (50.0%)  Loss=0.9697  cls_loss=0.6728  reg_loss=0.2969  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=700s  iter_time=105.980s
2025-08-09 19:07:12 Train INFO: [Train]: [078][00030/00051] (59.6%)  Loss=0.9723  cls_loss=0.6739  reg_loss=0.2985  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=542s  iter_time=99.466s
2025-08-09 19:08:52 Train INFO: [Train]: [078][00035/00051] (69.2%)  Loss=0.9713  cls_loss=0.6714  reg_loss=0.2999  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=100.065s
2025-08-09 19:11:38 Train INFO: [Train]: [078][00040/00051] (78.8%)  Loss=0.9857  cls_loss=0.6825  reg_loss=0.3032  lr_backbone=2.9e-06  lr_det=2.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=286s  iter_time=165.649s
2025-08-09 19:13:26 Train INFO: [Train]: [078][00045/00051] (88.5%)  Loss=0.9783  cls_loss=0.6773  reg_loss=0.3010  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=108.748s
2025-08-09 19:15:03 Train INFO: [Train]: [078][00050/00051] (98.1%)  Loss=0.9739  cls_loss=0.6746  reg_loss=0.2992  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=96.325s
2025-08-09 19:15:13 Train INFO: [Train]: [078][00051/00051] (100.0%)  Loss=0.9712  cls_loss=0.6729  reg_loss=0.2983  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-09 19:15:14 Train INFO: [Train]: Epoch 78 completed in 1281.5s (avg 24.644s/iter)
2025-08-09 19:15:14 Train INFO: [Train]: Final Loss=0.9712
2025-08-09 19:15:14 Train INFO: [Train]: Epoch 79 started (Total iterations: 52)
2025-08-09 19:19:04 Train INFO: [Train]: [079][00005/00051] (11.5%)  Loss=0.9404  cls_loss=0.6552  reg_loss=0.2851  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1767s  iter_time=230.458s  fwd=2.073s/bwd=4.314s/opt=3.065s
2025-08-09 19:20:57 Train INFO: [Train]: [079][00010/00051] (21.2%)  Loss=0.9688  cls_loss=0.6713  reg_loss=0.2975  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1280s  iter_time=112.993s
2025-08-09 19:22:48 Train INFO: [Train]: [079][00015/00051] (30.8%)  Loss=0.9801  cls_loss=0.6804  reg_loss=0.2998  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1022s  iter_time=110.921s
2025-08-09 19:25:15 Train INFO: [Train]: [079][00020/00051] (40.4%)  Loss=0.9684  cls_loss=0.6704  reg_loss=0.2981  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=887s  iter_time=146.434s
2025-08-09 19:27:14 Train INFO: [Train]: [079][00025/00051] (50.0%)  Loss=0.9766  cls_loss=0.6736  reg_loss=0.3030  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=720s  iter_time=119.193s
2025-08-09 19:28:57 Train INFO: [Train]: [079][00030/00051] (59.6%)  Loss=0.9713  cls_loss=0.6708  reg_loss=0.3005  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=558s  iter_time=103.160s
2025-08-09 19:30:47 Train INFO: [Train]: [079][00035/00051] (69.2%)  Loss=0.9806  cls_loss=0.6773  reg_loss=0.3033  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=415s  iter_time=110.115s
2025-08-09 19:33:06 Train INFO: [Train]: [079][00040/00051] (78.8%)  Loss=0.9790  cls_loss=0.6769  reg_loss=0.3021  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=288s  iter_time=139.275s
2025-08-09 19:35:05 Train INFO: [Train]: [079][00045/00051] (88.5%)  Loss=0.9789  cls_loss=0.6760  reg_loss=0.3028  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=118.908s
2025-08-09 19:36:45 Train INFO: [Train]: [079][00050/00051] (98.1%)  Loss=0.9824  cls_loss=0.6778  reg_loss=0.3046  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.541s
2025-08-09 19:36:55 Train INFO: [Train]: [079][00051/00051] (100.0%)  Loss=0.9843  cls_loss=0.6791  reg_loss=0.3052  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.351s
2025-08-09 19:36:56 Train INFO: [Train]: Epoch 79 completed in 1302.1s (avg 25.040s/iter)
2025-08-09 19:36:56 Train INFO: [Train]: Final Loss=0.9843
2025-08-09 19:36:56 Train INFO: [Val]: Epoch 79 Loss
2025-08-09 20:24:39 Train INFO: [Val]: [079]  Loss=1.0060  cls_loss=0.6933  reg_loss=0.3126  Average-mAP=0.69%
2025-08-09 20:24:41 Train INFO: Checkpoint saved at epoch 79
2025-08-09 20:24:41 Train INFO: [Train]: Epoch 80 started (Total iterations: 52)
2025-08-09 20:28:32 Train INFO: [Train]: [080][00005/00051] (11.5%)  Loss=0.9144  cls_loss=0.6321  reg_loss=0.2823  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1773s  iter_time=231.212s  fwd=2.092s/bwd=4.320s/opt=3.080s
2025-08-09 20:30:11 Train INFO: [Train]: [080][00010/00051] (21.2%)  Loss=0.9524  cls_loss=0.6576  reg_loss=0.2948  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1230s  iter_time=98.872s
2025-08-09 20:31:57 Train INFO: [Train]: [080][00015/00051] (30.8%)  Loss=0.9476  cls_loss=0.6524  reg_loss=0.2952  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=983s  iter_time=106.674s
2025-08-09 20:34:17 Train INFO: [Train]: [080][00020/00051] (40.4%)  Loss=0.9506  cls_loss=0.6542  reg_loss=0.2963  lr_backbone=2.7e-06  lr_det=2.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=850s  iter_time=139.153s
2025-08-09 20:36:00 Train INFO: [Train]: [080][00025/00051] (50.0%)  Loss=0.9493  cls_loss=0.6542  reg_loss=0.2951  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=103.935s
2025-08-09 20:37:43 Train INFO: [Train]: [080][00030/00051] (59.6%)  Loss=0.9551  cls_loss=0.6581  reg_loss=0.2970  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=530s  iter_time=102.935s
2025-08-09 20:39:29 Train INFO: [Train]: [080][00035/00051] (69.2%)  Loss=0.9606  cls_loss=0.6621  reg_loss=0.2985  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=395s  iter_time=105.824s
2025-08-09 20:41:55 Train INFO: [Train]: [080][00040/00051] (78.8%)  Loss=0.9526  cls_loss=0.6569  reg_loss=0.2957  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=145.340s
2025-08-09 20:43:34 Train INFO: [Train]: [080][00045/00051] (88.5%)  Loss=0.9493  cls_loss=0.6559  reg_loss=0.2933  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=148s  iter_time=99.494s
2025-08-09 20:45:05 Train INFO: [Train]: [080][00050/00051] (98.1%)  Loss=0.9582  cls_loss=0.6627  reg_loss=0.2955  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=90.637s
2025-08-09 20:45:15 Train INFO: [Train]: [080][00051/00051] (100.0%)  Loss=0.9576  cls_loss=0.6625  reg_loss=0.2951  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-09 20:45:16 Train INFO: [Train]: Epoch 80 completed in 1235.2s (avg 23.753s/iter)
2025-08-09 20:45:16 Train INFO: [Train]: Final Loss=0.9576
2025-08-09 20:45:16 Train INFO: [Train]: Epoch 81 started (Total iterations: 52)
2025-08-09 20:48:56 Train INFO: [Train]: [081][00005/00051] (11.5%)  Loss=0.9523  cls_loss=0.6560  reg_loss=0.2963  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1687s  iter_time=220.017s  fwd=2.058s/bwd=4.308s/opt=3.071s
2025-08-09 20:50:40 Train INFO: [Train]: [081][00010/00051] (21.2%)  Loss=0.9616  cls_loss=0.6627  reg_loss=0.2989  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1210s  iter_time=104.583s
2025-08-09 20:52:33 Train INFO: [Train]: [081][00015/00051] (30.8%)  Loss=0.9641  cls_loss=0.6658  reg_loss=0.2984  lr_backbone=2.6e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=984s  iter_time=112.693s
2025-08-09 20:54:56 Train INFO: [Train]: [081][00020/00051] (40.4%)  Loss=0.9794  cls_loss=0.6775  reg_loss=0.3019  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=857s  iter_time=143.082s
2025-08-09 20:56:41 Train INFO: [Train]: [081][00025/00051] (50.0%)  Loss=0.9705  cls_loss=0.6731  reg_loss=0.2974  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=686s  iter_time=105.152s
2025-08-09 20:58:25 Train INFO: [Train]: [081][00030/00051] (59.6%)  Loss=0.9684  cls_loss=0.6720  reg_loss=0.2964  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=535s  iter_time=104.024s
2025-08-09 21:00:10 Train INFO: [Train]: [081][00035/00051] (69.2%)  Loss=0.9659  cls_loss=0.6698  reg_loss=0.2961  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=104.174s
2025-08-09 21:02:48 Train INFO: [Train]: [081][00040/00051] (78.8%)  Loss=0.9707  cls_loss=0.6736  reg_loss=0.2971  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=158.548s
2025-08-09 21:04:41 Train INFO: [Train]: [081][00045/00051] (88.5%)  Loss=0.9720  cls_loss=0.6748  reg_loss=0.2972  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=112.729s
2025-08-09 21:06:20 Train INFO: [Train]: [081][00050/00051] (98.1%)  Loss=0.9692  cls_loss=0.6730  reg_loss=0.2963  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.187s
2025-08-09 21:06:30 Train INFO: [Train]: [081][00051/00051] (100.0%)  Loss=0.9690  cls_loss=0.6732  reg_loss=0.2959  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-09 21:06:31 Train INFO: [Train]: Epoch 81 completed in 1275.3s (avg 24.525s/iter)
2025-08-09 21:06:31 Train INFO: [Train]: Final Loss=0.9690
2025-08-09 21:06:31 Train INFO: [Train]: Epoch 82 started (Total iterations: 52)
2025-08-09 21:10:10 Train INFO: [Train]: [082][00005/00051] (11.5%)  Loss=1.0223  cls_loss=0.7175  reg_loss=0.3048  lr_backbone=2.5e-06  lr_det=2.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1675s  iter_time=218.462s  fwd=2.044s/bwd=4.302s/opt=3.078s
2025-08-09 21:11:54 Train INFO: [Train]: [082][00010/00051] (21.2%)  Loss=0.9812  cls_loss=0.6866  reg_loss=0.2945  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1202s  iter_time=104.015s
2025-08-09 21:13:40 Train INFO: [Train]: [082][00015/00051] (30.8%)  Loss=0.9709  cls_loss=0.6786  reg_loss=0.2923  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=964s  iter_time=105.925s
2025-08-09 21:16:05 Train INFO: [Train]: [082][00020/00051] (40.4%)  Loss=0.9825  cls_loss=0.6855  reg_loss=0.2970  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=847s  iter_time=145.252s
2025-08-09 21:17:47 Train INFO: [Train]: [082][00025/00051] (50.0%)  Loss=0.9745  cls_loss=0.6804  reg_loss=0.2941  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=676s  iter_time=102.403s
2025-08-09 21:19:32 Train INFO: [Train]: [082][00030/00051] (59.6%)  Loss=0.9727  cls_loss=0.6799  reg_loss=0.2928  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=529s  iter_time=104.646s
2025-08-09 21:21:10 Train INFO: [Train]: [082][00035/00051] (69.2%)  Loss=0.9673  cls_loss=0.6751  reg_loss=0.2922  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=390s  iter_time=97.851s
2025-08-09 21:23:38 Train INFO: [Train]: [082][00040/00051] (78.8%)  Loss=0.9647  cls_loss=0.6725  reg_loss=0.2922  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=276s  iter_time=148.517s
2025-08-09 21:25:17 Train INFO: [Train]: [082][00045/00051] (88.5%)  Loss=0.9692  cls_loss=0.6749  reg_loss=0.2943  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=99.180s
2025-08-09 21:27:12 Train INFO: [Train]: [082][00050/00051] (98.1%)  Loss=0.9745  cls_loss=0.6785  reg_loss=0.2960  lr_backbone=2.4e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=114.143s
2025-08-09 21:27:22 Train INFO: [Train]: [082][00051/00051] (100.0%)  Loss=0.9744  cls_loss=0.6783  reg_loss=0.2962  lr_backbone=2.4e-06  lr_det=2.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.381s
2025-08-09 21:27:23 Train INFO: [Train]: Epoch 82 completed in 1251.6s (avg 24.070s/iter)
2025-08-09 21:27:23 Train INFO: [Train]: Final Loss=0.9744
2025-08-09 21:27:23 Train INFO: [Train]: Epoch 83 started (Total iterations: 52)
2025-08-09 21:31:01 Train INFO: [Train]: [083][00005/00051] (11.5%)  Loss=0.9851  cls_loss=0.6881  reg_loss=0.2969  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1674s  iter_time=218.392s  fwd=2.037s/bwd=4.269s/opt=3.074s
2025-08-09 21:32:39 Train INFO: [Train]: [083][00010/00051] (21.2%)  Loss=0.9362  cls_loss=0.6524  reg_loss=0.2839  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1180s  iter_time=98.064s
2025-08-09 21:34:17 Train INFO: [Train]: [083][00015/00051] (30.8%)  Loss=0.9646  cls_loss=0.6694  reg_loss=0.2952  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=931s  iter_time=97.409s
2025-08-09 21:36:55 Train INFO: [Train]: [083][00020/00051] (40.4%)  Loss=0.9709  cls_loss=0.6717  reg_loss=0.2992  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=845s  iter_time=158.757s
2025-08-09 21:38:48 Train INFO: [Train]: [083][00025/00051] (50.0%)  Loss=0.9622  cls_loss=0.6661  reg_loss=0.2961  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=686s  iter_time=113.013s
2025-08-09 21:40:31 Train INFO: [Train]: [083][00030/00051] (59.6%)  Loss=0.9711  cls_loss=0.6714  reg_loss=0.2997  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=102.129s
2025-08-09 21:42:09 Train INFO: [Train]: [083][00035/00051] (69.2%)  Loss=0.9675  cls_loss=0.6695  reg_loss=0.2980  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=394s  iter_time=98.077s
2025-08-09 21:44:27 Train INFO: [Train]: [083][00040/00051] (78.8%)  Loss=0.9807  cls_loss=0.6775  reg_loss=0.3032  lr_backbone=2.3e-06  lr_det=2.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=275s  iter_time=138.414s
2025-08-09 21:46:13 Train INFO: [Train]: [083][00045/00051] (88.5%)  Loss=0.9746  cls_loss=0.6730  reg_loss=0.3017  lr_backbone=2.3e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=106.104s
2025-08-09 21:47:55 Train INFO: [Train]: [083][00050/00051] (98.1%)  Loss=0.9789  cls_loss=0.6757  reg_loss=0.3032  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=101.961s
2025-08-09 21:48:05 Train INFO: [Train]: [083][00051/00051] (100.0%)  Loss=0.9776  cls_loss=0.6750  reg_loss=0.3026  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-09 21:48:06 Train INFO: [Train]: Epoch 83 completed in 1243.4s (avg 23.911s/iter)
2025-08-09 21:48:06 Train INFO: [Train]: Final Loss=0.9776
2025-08-09 21:48:06 Train INFO: [Train]: Epoch 84 started (Total iterations: 52)
2025-08-09 21:51:57 Train INFO: [Train]: [084][00005/00051] (11.5%)  Loss=0.9195  cls_loss=0.6347  reg_loss=0.2847  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1773s  iter_time=231.243s  fwd=2.099s/bwd=4.332s/opt=3.085s
2025-08-09 21:53:34 Train INFO: [Train]: [084][00010/00051] (21.2%)  Loss=0.9489  cls_loss=0.6548  reg_loss=0.2941  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1224s  iter_time=97.125s
2025-08-09 21:55:25 Train INFO: [Train]: [084][00015/00051] (30.8%)  Loss=0.9505  cls_loss=0.6596  reg_loss=0.2908  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=988s  iter_time=110.646s
2025-08-09 21:58:11 Train INFO: [Train]: [084][00020/00051] (40.4%)  Loss=0.9804  cls_loss=0.6768  reg_loss=0.3036  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=894s  iter_time=166.341s
2025-08-09 22:00:01 Train INFO: [Train]: [084][00025/00051] (50.0%)  Loss=0.9616  cls_loss=0.6666  reg_loss=0.2950  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=715s  iter_time=109.513s
2025-08-09 22:01:41 Train INFO: [Train]: [084][00030/00051] (59.6%)  Loss=0.9606  cls_loss=0.6667  reg_loss=0.2939  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=552s  iter_time=100.380s
2025-08-09 22:03:22 Train INFO: [Train]: [084][00035/00051] (69.2%)  Loss=0.9633  cls_loss=0.6690  reg_loss=0.2943  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=407s  iter_time=100.454s
2025-08-09 22:06:04 Train INFO: [Train]: [084][00040/00051] (78.8%)  Loss=0.9623  cls_loss=0.6683  reg_loss=0.2940  lr_backbone=2.2e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=289s  iter_time=162.480s
2025-08-09 22:07:46 Train INFO: [Train]: [084][00045/00051] (88.5%)  Loss=0.9643  cls_loss=0.6695  reg_loss=0.2948  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=101.804s
2025-08-09 22:09:27 Train INFO: [Train]: [084][00050/00051] (98.1%)  Loss=0.9639  cls_loss=0.6691  reg_loss=0.2948  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.729s
2025-08-09 22:09:37 Train INFO: [Train]: [084][00051/00051] (100.0%)  Loss=0.9615  cls_loss=0.6673  reg_loss=0.2942  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.352s
2025-08-09 22:09:38 Train INFO: [Train]: Epoch 84 completed in 1291.8s (avg 24.843s/iter)
2025-08-09 22:09:38 Train INFO: [Train]: Final Loss=0.9615
2025-08-09 22:09:38 Train INFO: [Val]: Epoch 84 Loss
2025-08-09 22:58:05 Train INFO: [Val]: [084]  Loss=1.0062  cls_loss=0.6936  reg_loss=0.3127  Average-mAP=0.76%
2025-08-09 22:58:07 Train INFO: Checkpoint saved at epoch 84
2025-08-09 22:58:07 Train INFO: [Train]: Epoch 85 started (Total iterations: 52)
2025-08-09 23:01:48 Train INFO: [Train]: [085][00005/00051] (11.5%)  Loss=0.9292  cls_loss=0.6456  reg_loss=0.2836  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1695s  iter_time=221.029s  fwd=2.066s/bwd=4.282s/opt=3.085s
2025-08-09 23:03:34 Train INFO: [Train]: [085][00010/00051] (21.2%)  Loss=0.9347  cls_loss=0.6540  reg_loss=0.2807  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1219s  iter_time=106.128s
2025-08-09 23:05:25 Train INFO: [Train]: [085][00015/00051] (30.8%)  Loss=0.9423  cls_loss=0.6587  reg_loss=0.2837  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=984s  iter_time=110.331s
2025-08-09 23:07:48 Train INFO: [Train]: [085][00020/00051] (40.4%)  Loss=0.9625  cls_loss=0.6697  reg_loss=0.2928  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=857s  iter_time=143.022s
2025-08-09 23:09:38 Train INFO: [Train]: [085][00025/00051] (50.0%)  Loss=0.9680  cls_loss=0.6735  reg_loss=0.2945  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=110.222s
2025-08-09 23:11:20 Train INFO: [Train]: [085][00030/00051] (59.6%)  Loss=0.9716  cls_loss=0.6746  reg_loss=0.2970  lr_backbone=2.1e-06  lr_det=2.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=537s  iter_time=101.697s
2025-08-09 23:12:57 Train INFO: [Train]: [085][00035/00051] (69.2%)  Loss=0.9739  cls_loss=0.6752  reg_loss=0.2988  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=396s  iter_time=97.653s
2025-08-09 23:15:16 Train INFO: [Train]: [085][00040/00051] (78.8%)  Loss=0.9720  cls_loss=0.6745  reg_loss=0.2975  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=276s  iter_time=138.468s
2025-08-09 23:17:14 Train INFO: [Train]: [085][00045/00051] (88.5%)  Loss=0.9704  cls_loss=0.6735  reg_loss=0.2969  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=118.222s
2025-08-09 23:18:49 Train INFO: [Train]: [085][00050/00051] (98.1%)  Loss=0.9734  cls_loss=0.6753  reg_loss=0.2981  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=95.460s
2025-08-09 23:19:00 Train INFO: [Train]: [085][00051/00051] (100.0%)  Loss=0.9762  cls_loss=0.6773  reg_loss=0.2990  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.349s
2025-08-09 23:19:00 Train INFO: [Train]: Epoch 85 completed in 1253.4s (avg 24.103s/iter)
2025-08-09 23:19:00 Train INFO: [Train]: Final Loss=0.9762
2025-08-09 23:19:00 Train INFO: [Train]: Epoch 86 started (Total iterations: 52)
2025-08-09 23:22:58 Train INFO: [Train]: [086][00005/00051] (11.5%)  Loss=0.8990  cls_loss=0.6264  reg_loss=0.2726  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1825s  iter_time=238.018s  fwd=2.054s/bwd=4.299s/opt=3.070s
2025-08-09 23:24:42 Train INFO: [Train]: [086][00010/00051] (21.2%)  Loss=0.9853  cls_loss=0.6814  reg_loss=0.3039  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1273s  iter_time=103.541s
2025-08-09 23:26:26 Train INFO: [Train]: [086][00015/00051] (30.8%)  Loss=0.9878  cls_loss=0.6817  reg_loss=0.3061  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1002s  iter_time=103.894s
2025-08-09 23:29:03 Train INFO: [Train]: [086][00020/00051] (40.4%)  Loss=0.9998  cls_loss=0.6915  reg_loss=0.3083  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=889s  iter_time=156.780s
2025-08-09 23:30:56 Train INFO: [Train]: [086][00025/00051] (50.0%)  Loss=0.9926  cls_loss=0.6853  reg_loss=0.3073  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=715s  iter_time=113.180s
2025-08-09 23:32:43 Train INFO: [Train]: [086][00030/00051] (59.6%)  Loss=0.9924  cls_loss=0.6859  reg_loss=0.3065  lr_backbone=2.0e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=557s  iter_time=107.395s
2025-08-09 23:34:20 Train INFO: [Train]: [086][00035/00051] (69.2%)  Loss=0.9739  cls_loss=0.6740  reg_loss=0.3000  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=409s  iter_time=97.064s
2025-08-09 23:36:54 Train INFO: [Train]: [086][00040/00051] (78.8%)  Loss=0.9735  cls_loss=0.6745  reg_loss=0.2990  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=288s  iter_time=154.097s
2025-08-09 23:38:46 Train INFO: [Train]: [086][00045/00051] (88.5%)  Loss=0.9694  cls_loss=0.6728  reg_loss=0.2967  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=111.917s
2025-08-09 23:40:16 Train INFO: [Train]: [086][00050/00051] (98.1%)  Loss=0.9737  cls_loss=0.6755  reg_loss=0.2982  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=89.565s
2025-08-09 23:40:26 Train INFO: [Train]: [086][00051/00051] (100.0%)  Loss=0.9739  cls_loss=0.6754  reg_loss=0.2985  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.385s
2025-08-09 23:40:27 Train INFO: [Train]: Epoch 86 completed in 1286.6s (avg 24.742s/iter)
2025-08-09 23:40:27 Train INFO: [Train]: Final Loss=0.9739
2025-08-09 23:40:27 Train INFO: [Train]: Epoch 87 started (Total iterations: 52)
2025-08-09 23:44:18 Train INFO: [Train]: [087][00005/00051] (11.5%)  Loss=0.9792  cls_loss=0.6776  reg_loss=0.3016  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1770s  iter_time=230.858s  fwd=2.076s/bwd=4.319s/opt=3.077s
2025-08-09 23:46:03 Train INFO: [Train]: [087][00010/00051] (21.2%)  Loss=0.9844  cls_loss=0.6807  reg_loss=0.3037  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1254s  iter_time=105.554s
2025-08-09 23:47:47 Train INFO: [Train]: [087][00015/00051] (30.8%)  Loss=0.9725  cls_loss=0.6710  reg_loss=0.3015  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=989s  iter_time=103.105s
2025-08-09 23:50:30 Train INFO: [Train]: [087][00020/00051] (40.4%)  Loss=0.9811  cls_loss=0.6761  reg_loss=0.3050  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=890s  iter_time=163.443s
2025-08-09 23:52:17 Train INFO: [Train]: [087][00025/00051] (50.0%)  Loss=0.9678  cls_loss=0.6680  reg_loss=0.2998  lr_backbone=1.9e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=710s  iter_time=106.814s
2025-08-09 23:54:04 Train INFO: [Train]: [087][00030/00051] (59.6%)  Loss=0.9764  cls_loss=0.6733  reg_loss=0.3031  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=554s  iter_time=107.509s
2025-08-09 23:55:44 Train INFO: [Train]: [087][00035/00051] (69.2%)  Loss=0.9735  cls_loss=0.6717  reg_loss=0.3019  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=408s  iter_time=99.593s
2025-08-09 23:58:19 Train INFO: [Train]: [087][00040/00051] (78.8%)  Loss=0.9636  cls_loss=0.6649  reg_loss=0.2987  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=288s  iter_time=155.110s
2025-08-10 00:00:00 Train INFO: [Train]: [087][00045/00051] (88.5%)  Loss=0.9662  cls_loss=0.6663  reg_loss=0.2999  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=101.472s
2025-08-10 00:01:41 Train INFO: [Train]: [087][00050/00051] (98.1%)  Loss=0.9754  cls_loss=0.6731  reg_loss=0.3023  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.606s
2025-08-10 00:01:51 Train INFO: [Train]: [087][00051/00051] (100.0%)  Loss=0.9728  cls_loss=0.6719  reg_loss=0.3009  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.371s
2025-08-10 00:01:52 Train INFO: [Train]: Epoch 87 completed in 1285.2s (avg 24.715s/iter)
2025-08-10 00:01:52 Train INFO: [Train]: Final Loss=0.9728
2025-08-10 00:01:52 Train INFO: [Train]: Epoch 88 started (Total iterations: 52)
2025-08-10 00:05:28 Train INFO: [Train]: [088][00005/00051] (11.5%)  Loss=1.0044  cls_loss=0.6929  reg_loss=0.3115  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1654s  iter_time=215.773s  fwd=2.062s/bwd=4.310s/opt=3.090s
2025-08-10 00:07:13 Train INFO: [Train]: [088][00010/00051] (21.2%)  Loss=0.9759  cls_loss=0.6762  reg_loss=0.2997  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1197s  iter_time=105.473s
2025-08-10 00:08:55 Train INFO: [Train]: [088][00015/00051] (30.8%)  Loss=0.9648  cls_loss=0.6667  reg_loss=0.2981  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=950s  iter_time=101.186s
2025-08-10 00:11:40 Train INFO: [Train]: [088][00020/00051] (40.4%)  Loss=0.9690  cls_loss=0.6692  reg_loss=0.2999  lr_backbone=1.8e-06  lr_det=1.8e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=868s  iter_time=165.846s
2025-08-10 00:13:30 Train INFO: [Train]: [088][00025/00051] (50.0%)  Loss=0.9680  cls_loss=0.6699  reg_loss=0.2981  lr_backbone=1.8e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=109.399s
2025-08-10 00:15:14 Train INFO: [Train]: [088][00030/00051] (59.6%)  Loss=0.9773  cls_loss=0.6772  reg_loss=0.3000  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=104.032s
2025-08-10 00:16:55 Train INFO: [Train]: [088][00035/00051] (69.2%)  Loss=0.9711  cls_loss=0.6733  reg_loss=0.2978  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=100.601s
2025-08-10 00:19:13 Train INFO: [Train]: [088][00040/00051] (78.8%)  Loss=0.9842  cls_loss=0.6826  reg_loss=0.3016  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=138.400s
2025-08-10 00:21:04 Train INFO: [Train]: [088][00045/00051] (88.5%)  Loss=0.9825  cls_loss=0.6803  reg_loss=0.3022  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=111.313s
2025-08-10 00:22:53 Train INFO: [Train]: [088][00050/00051] (98.1%)  Loss=0.9743  cls_loss=0.6751  reg_loss=0.2992  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=108.617s
2025-08-10 00:23:03 Train INFO: [Train]: [088][00051/00051] (100.0%)  Loss=0.9723  cls_loss=0.6734  reg_loss=0.2989  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.363s
2025-08-10 00:23:04 Train INFO: [Train]: Epoch 88 completed in 1271.7s (avg 24.456s/iter)
2025-08-10 00:23:04 Train INFO: [Train]: Final Loss=0.9723
2025-08-10 00:23:04 Train INFO: [Train]: Epoch 89 started (Total iterations: 52)
2025-08-10 00:26:48 Train INFO: [Train]: [089][00005/00051] (11.5%)  Loss=0.9695  cls_loss=0.6712  reg_loss=0.2983  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1721s  iter_time=224.539s  fwd=2.080s/bwd=4.292s/opt=3.064s
2025-08-10 00:28:40 Train INFO: [Train]: [089][00010/00051] (21.2%)  Loss=0.9768  cls_loss=0.6754  reg_loss=0.3014  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1253s  iter_time=111.592s
2025-08-10 00:30:34 Train INFO: [Train]: [089][00015/00051] (30.8%)  Loss=0.9747  cls_loss=0.6770  reg_loss=0.2977  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1012s  iter_time=113.709s
2025-08-10 00:33:06 Train INFO: [Train]: [089][00020/00051] (40.4%)  Loss=0.9764  cls_loss=0.6759  reg_loss=0.3006  lr_backbone=1.7e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=889s  iter_time=152.063s
2025-08-10 00:34:56 Train INFO: [Train]: [089][00025/00051] (50.0%)  Loss=0.9770  cls_loss=0.6774  reg_loss=0.2997  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=713s  iter_time=110.631s
2025-08-10 00:36:35 Train INFO: [Train]: [089][00030/00051] (59.6%)  Loss=0.9975  cls_loss=0.6911  reg_loss=0.3064  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=550s  iter_time=98.955s
2025-08-10 00:38:14 Train INFO: [Train]: [089][00035/00051] (69.2%)  Loss=0.9891  cls_loss=0.6853  reg_loss=0.3038  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=404s  iter_time=98.388s
2025-08-10 00:40:46 Train INFO: [Train]: [089][00040/00051] (78.8%)  Loss=0.9791  cls_loss=0.6779  reg_loss=0.3012  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=285s  iter_time=152.250s
2025-08-10 00:42:29 Train INFO: [Train]: [089][00045/00051] (88.5%)  Loss=0.9812  cls_loss=0.6781  reg_loss=0.3031  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=102.721s
2025-08-10 00:44:12 Train INFO: [Train]: [089][00050/00051] (98.1%)  Loss=0.9786  cls_loss=0.6755  reg_loss=0.3032  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=102.974s
2025-08-10 00:44:22 Train INFO: [Train]: [089][00051/00051] (100.0%)  Loss=0.9753  cls_loss=0.6736  reg_loss=0.3017  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.361s
2025-08-10 00:44:23 Train INFO: [Train]: Epoch 89 completed in 1279.0s (avg 24.595s/iter)
2025-08-10 00:44:23 Train INFO: [Train]: Final Loss=0.9753
2025-08-10 00:44:23 Train INFO: [Val]: Epoch 89 Loss
2025-08-10 01:31:42 Train INFO: [Val]: [089]  Loss=1.0066  cls_loss=0.6939  reg_loss=0.3127  Average-mAP=0.70%
2025-08-10 01:31:44 Train INFO: Checkpoint saved at epoch 89
2025-08-10 01:31:44 Train INFO: [Train]: Epoch 90 started (Total iterations: 52)
2025-08-10 01:35:24 Train INFO: [Train]: [090][00005/00051] (11.5%)  Loss=0.8866  cls_loss=0.6136  reg_loss=0.2729  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1690s  iter_time=220.384s  fwd=2.061s/bwd=4.302s/opt=3.080s
2025-08-10 01:37:06 Train INFO: [Train]: [090][00010/00051] (21.2%)  Loss=0.9133  cls_loss=0.6300  reg_loss=0.2833  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1201s  iter_time=101.773s
2025-08-10 01:38:53 Train INFO: [Train]: [090][00015/00051] (30.8%)  Loss=0.9552  cls_loss=0.6594  reg_loss=0.2958  lr_backbone=1.6e-06  lr_det=1.6e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=965s  iter_time=106.689s
2025-08-10 01:41:27 Train INFO: [Train]: [090][00020/00051] (40.4%)  Loss=0.9505  cls_loss=0.6539  reg_loss=0.2966  lr_backbone=1.6e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=861s  iter_time=154.309s
2025-08-10 01:43:13 Train INFO: [Train]: [090][00025/00051] (50.0%)  Loss=0.9379  cls_loss=0.6454  reg_loss=0.2925  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=689s  iter_time=105.959s
2025-08-10 01:45:07 Train INFO: [Train]: [090][00030/00051] (59.6%)  Loss=0.9532  cls_loss=0.6551  reg_loss=0.2981  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=544s  iter_time=114.263s
2025-08-10 01:46:46 Train INFO: [Train]: [090][00035/00051] (69.2%)  Loss=0.9528  cls_loss=0.6557  reg_loss=0.2971  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=401s  iter_time=99.045s
2025-08-10 01:49:12 Train INFO: [Train]: [090][00040/00051] (78.8%)  Loss=0.9547  cls_loss=0.6578  reg_loss=0.2969  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=145.559s
2025-08-10 01:50:56 Train INFO: [Train]: [090][00045/00051] (88.5%)  Loss=0.9552  cls_loss=0.6583  reg_loss=0.2969  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=104.260s
2025-08-10 01:52:31 Train INFO: [Train]: [090][00050/00051] (98.1%)  Loss=0.9540  cls_loss=0.6575  reg_loss=0.2965  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=94.854s
2025-08-10 01:52:41 Train INFO: [Train]: [090][00051/00051] (100.0%)  Loss=0.9542  cls_loss=0.6574  reg_loss=0.2967  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.366s
2025-08-10 01:52:42 Train INFO: [Train]: Epoch 90 completed in 1258.2s (avg 24.196s/iter)
2025-08-10 01:52:42 Train INFO: [Train]: Final Loss=0.9542
2025-08-10 01:52:42 Train INFO: [Train]: Epoch 91 started (Total iterations: 52)
2025-08-10 01:56:34 Train INFO: [Train]: [091][00005/00051] (11.5%)  Loss=0.9622  cls_loss=0.6778  reg_loss=0.2844  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1781s  iter_time=232.251s  fwd=2.068s/bwd=4.331s/opt=3.091s
2025-08-10 01:58:12 Train INFO: [Train]: [091][00010/00051] (21.2%)  Loss=0.9706  cls_loss=0.6799  reg_loss=0.2906  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1232s  iter_time=98.227s
2025-08-10 01:59:57 Train INFO: [Train]: [091][00015/00051] (30.8%)  Loss=1.0160  cls_loss=0.7076  reg_loss=0.3083  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=979s  iter_time=104.787s
2025-08-10 02:02:35 Train INFO: [Train]: [091][00020/00051] (40.4%)  Loss=1.0129  cls_loss=0.7070  reg_loss=0.3059  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=876s  iter_time=158.116s
2025-08-10 02:04:13 Train INFO: [Train]: [091][00025/00051] (50.0%)  Loss=0.9990  cls_loss=0.6980  reg_loss=0.3009  lr_backbone=1.5e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=97.629s
2025-08-10 02:05:58 Train INFO: [Train]: [091][00030/00051] (59.6%)  Loss=0.9915  cls_loss=0.6903  reg_loss=0.3012  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=539s  iter_time=104.772s
2025-08-10 02:07:50 Train INFO: [Train]: [091][00035/00051] (69.2%)  Loss=0.9844  cls_loss=0.6859  reg_loss=0.2985  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=404s  iter_time=112.154s
2025-08-10 02:10:25 Train INFO: [Train]: [091][00040/00051] (78.8%)  Loss=0.9812  cls_loss=0.6834  reg_loss=0.2978  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=285s  iter_time=155.206s
2025-08-10 02:12:04 Train INFO: [Train]: [091][00045/00051] (88.5%)  Loss=0.9899  cls_loss=0.6886  reg_loss=0.3013  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=98.540s
2025-08-10 02:13:48 Train INFO: [Train]: [091][00050/00051] (98.1%)  Loss=0.9893  cls_loss=0.6875  reg_loss=0.3019  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.246s
2025-08-10 02:13:58 Train INFO: [Train]: [091][00051/00051] (100.0%)  Loss=0.9857  cls_loss=0.6850  reg_loss=0.3007  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.354s
2025-08-10 02:13:59 Train INFO: [Train]: Epoch 91 completed in 1277.0s (avg 24.558s/iter)
2025-08-10 02:13:59 Train INFO: [Train]: Final Loss=0.9857
2025-08-10 02:13:59 Train INFO: [Train]: Epoch 92 started (Total iterations: 52)
2025-08-10 02:17:46 Train INFO: [Train]: [092][00005/00051] (11.5%)  Loss=0.9214  cls_loss=0.6306  reg_loss=0.2908  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1741s  iter_time=227.121s  fwd=2.072s/bwd=4.288s/opt=3.064s
2025-08-10 02:19:32 Train INFO: [Train]: [092][00010/00051] (21.2%)  Loss=0.9331  cls_loss=0.6439  reg_loss=0.2892  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1240s  iter_time=105.510s
2025-08-10 02:21:15 Train INFO: [Train]: [092][00015/00051] (30.8%)  Loss=0.9328  cls_loss=0.6434  reg_loss=0.2894  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=980s  iter_time=102.881s
2025-08-10 02:23:45 Train INFO: [Train]: [092][00020/00051] (40.4%)  Loss=0.9379  cls_loss=0.6472  reg_loss=0.2906  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=864s  iter_time=150.105s
2025-08-10 02:25:26 Train INFO: [Train]: [092][00025/00051] (50.0%)  Loss=0.9464  cls_loss=0.6526  reg_loss=0.2938  lr_backbone=1.4e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=687s  iter_time=101.627s
2025-08-10 02:27:13 Train INFO: [Train]: [092][00030/00051] (59.6%)  Loss=0.9513  cls_loss=0.6567  reg_loss=0.2946  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=538s  iter_time=106.838s
2025-08-10 02:28:53 Train INFO: [Train]: [092][00035/00051] (69.2%)  Loss=0.9575  cls_loss=0.6600  reg_loss=0.2975  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=100.327s
2025-08-10 02:31:23 Train INFO: [Train]: [092][00040/00051] (78.8%)  Loss=0.9574  cls_loss=0.6624  reg_loss=0.2949  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=149.342s
2025-08-10 02:33:13 Train INFO: [Train]: [092][00045/00051] (88.5%)  Loss=0.9601  cls_loss=0.6641  reg_loss=0.2959  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=110.476s
2025-08-10 02:34:54 Train INFO: [Train]: [092][00050/00051] (98.1%)  Loss=0.9651  cls_loss=0.6671  reg_loss=0.2980  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.949s
2025-08-10 02:35:05 Train INFO: [Train]: [092][00051/00051] (100.0%)  Loss=0.9624  cls_loss=0.6651  reg_loss=0.2973  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.356s
2025-08-10 02:35:05 Train INFO: [Train]: Epoch 92 completed in 1266.3s (avg 24.351s/iter)
2025-08-10 02:35:05 Train INFO: [Train]: Final Loss=0.9624
2025-08-10 02:35:05 Train INFO: [Train]: Epoch 93 started (Total iterations: 52)
2025-08-10 02:38:53 Train INFO: [Train]: [093][00005/00051] (11.5%)  Loss=0.9434  cls_loss=0.6486  reg_loss=0.2948  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1743s  iter_time=227.374s  fwd=2.062s/bwd=4.263s/opt=3.084s
2025-08-10 02:40:33 Train INFO: [Train]: [093][00010/00051] (21.2%)  Loss=0.9554  cls_loss=0.6578  reg_loss=0.2975  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1221s  iter_time=100.192s
2025-08-10 02:42:24 Train INFO: [Train]: [093][00015/00051] (30.8%)  Loss=0.9392  cls_loss=0.6440  reg_loss=0.2952  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=988s  iter_time=111.488s
2025-08-10 02:44:56 Train INFO: [Train]: [093][00020/00051] (40.4%)  Loss=0.9631  cls_loss=0.6620  reg_loss=0.3011  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=872s  iter_time=151.343s
2025-08-10 02:46:45 Train INFO: [Train]: [093][00025/00051] (50.0%)  Loss=0.9688  cls_loss=0.6656  reg_loss=0.3032  lr_backbone=1.3e-06  lr_det=1.3e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=699s  iter_time=108.997s
2025-08-10 02:48:30 Train INFO: [Train]: [093][00030/00051] (59.6%)  Loss=0.9748  cls_loss=0.6707  reg_loss=0.3041  lr_backbone=1.3e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=545s  iter_time=105.778s
2025-08-10 02:50:06 Train INFO: [Train]: [093][00035/00051] (69.2%)  Loss=0.9755  cls_loss=0.6712  reg_loss=0.3043  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=95.781s
2025-08-10 02:52:54 Train INFO: [Train]: [093][00040/00051] (78.8%)  Loss=0.9612  cls_loss=0.6626  reg_loss=0.2986  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=167.474s
2025-08-10 02:54:40 Train INFO: [Train]: [093][00045/00051] (88.5%)  Loss=0.9681  cls_loss=0.6681  reg_loss=0.3000  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=106.523s
2025-08-10 02:56:25 Train INFO: [Train]: [093][00050/00051] (98.1%)  Loss=0.9748  cls_loss=0.6726  reg_loss=0.3022  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.587s
2025-08-10 02:56:35 Train INFO: [Train]: [093][00051/00051] (100.0%)  Loss=0.9750  cls_loss=0.6728  reg_loss=0.3022  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.376s
2025-08-10 02:56:36 Train INFO: [Train]: Epoch 93 completed in 1290.6s (avg 24.820s/iter)
2025-08-10 02:56:36 Train INFO: [Train]: Final Loss=0.9750
2025-08-10 02:56:36 Train INFO: [Train]: Epoch 94 started (Total iterations: 52)
2025-08-10 03:00:11 Train INFO: [Train]: [094][00005/00051] (11.5%)  Loss=0.9458  cls_loss=0.6583  reg_loss=0.2875  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1646s  iter_time=214.653s  fwd=2.028s/bwd=4.282s/opt=3.075s
2025-08-10 03:01:54 Train INFO: [Train]: [094][00010/00051] (21.2%)  Loss=0.9335  cls_loss=0.6488  reg_loss=0.2846  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1184s  iter_time=102.996s
2025-08-10 03:03:31 Train INFO: [Train]: [094][00015/00051] (30.8%)  Loss=0.9550  cls_loss=0.6613  reg_loss=0.2936  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=934s  iter_time=97.473s
2025-08-10 03:06:07 Train INFO: [Train]: [094][00020/00051] (40.4%)  Loss=0.9589  cls_loss=0.6605  reg_loss=0.2985  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=843s  iter_time=155.889s
2025-08-10 03:07:47 Train INFO: [Train]: [094][00025/00051] (50.0%)  Loss=0.9677  cls_loss=0.6669  reg_loss=0.3008  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=671s  iter_time=100.168s
2025-08-10 03:09:28 Train INFO: [Train]: [094][00030/00051] (59.6%)  Loss=0.9675  cls_loss=0.6646  reg_loss=0.3028  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=523s  iter_time=101.236s
2025-08-10 03:11:14 Train INFO: [Train]: [094][00035/00051] (69.2%)  Loss=0.9721  cls_loss=0.6675  reg_loss=0.3046  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=390s  iter_time=106.035s
2025-08-10 03:13:49 Train INFO: [Train]: [094][00040/00051] (78.8%)  Loss=0.9762  cls_loss=0.6715  reg_loss=0.3047  lr_backbone=1.2e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=154.801s
2025-08-10 03:15:40 Train INFO: [Train]: [094][00045/00051] (88.5%)  Loss=0.9728  cls_loss=0.6694  reg_loss=0.3035  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=149s  iter_time=110.552s
2025-08-10 03:17:17 Train INFO: [Train]: [094][00050/00051] (98.1%)  Loss=0.9735  cls_loss=0.6706  reg_loss=0.3029  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.941s
2025-08-10 03:17:27 Train INFO: [Train]: [094][00051/00051] (100.0%)  Loss=0.9721  cls_loss=0.6695  reg_loss=0.3026  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.369s
2025-08-10 03:17:28 Train INFO: [Train]: Epoch 94 completed in 1251.9s (avg 24.074s/iter)
2025-08-10 03:17:28 Train INFO: [Train]: Final Loss=0.9721
2025-08-10 03:17:28 Train INFO: [Val]: Epoch 94 Loss
2025-08-10 04:04:52 Train INFO: [Val]: [094]  Loss=1.0070  cls_loss=0.6943  reg_loss=0.3127  Average-mAP=0.68%
2025-08-10 04:04:54 Train INFO: Checkpoint saved at epoch 94
2025-08-10 04:04:54 Train INFO: [Train]: Epoch 95 started (Total iterations: 52)
2025-08-10 04:08:37 Train INFO: [Train]: [095][00005/00051] (11.5%)  Loss=0.9789  cls_loss=0.6790  reg_loss=0.3000  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1713s  iter_time=223.469s  fwd=2.038s/bwd=4.321s/opt=3.079s
2025-08-10 04:10:14 Train INFO: [Train]: [095][00010/00051] (21.2%)  Loss=0.9755  cls_loss=0.6763  reg_loss=0.2992  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1192s  iter_time=96.363s
2025-08-10 04:11:57 Train INFO: [Train]: [095][00015/00051] (30.8%)  Loss=0.9923  cls_loss=0.6896  reg_loss=0.3027  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=952s  iter_time=103.447s
2025-08-10 04:14:32 Train INFO: [Train]: [095][00020/00051] (40.4%)  Loss=0.9505  cls_loss=0.6600  reg_loss=0.2905  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=854s  iter_time=155.335s
2025-08-10 04:16:12 Train INFO: [Train]: [095][00025/00051] (50.0%)  Loss=0.9622  cls_loss=0.6681  reg_loss=0.2941  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=678s  iter_time=99.252s
2025-08-10 04:18:02 Train INFO: [Train]: [095][00030/00051] (59.6%)  Loss=0.9641  cls_loss=0.6673  reg_loss=0.2968  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=110.892s
2025-08-10 04:19:46 Train INFO: [Train]: [095][00035/00051] (69.2%)  Loss=0.9720  cls_loss=0.6704  reg_loss=0.3016  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=397s  iter_time=103.793s
2025-08-10 04:22:15 Train INFO: [Train]: [095][00040/00051] (78.8%)  Loss=0.9791  cls_loss=0.6754  reg_loss=0.3037  lr_backbone=1.1e-06  lr_det=1.1e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=148.893s
2025-08-10 04:24:10 Train INFO: [Train]: [095][00045/00051] (88.5%)  Loss=0.9807  cls_loss=0.6766  reg_loss=0.3041  lr_backbone=1.1e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=114.751s
2025-08-10 04:25:50 Train INFO: [Train]: [095][00050/00051] (98.1%)  Loss=0.9788  cls_loss=0.6751  reg_loss=0.3038  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=100.300s
2025-08-10 04:26:01 Train INFO: [Train]: [095][00051/00051] (100.0%)  Loss=0.9748  cls_loss=0.6723  reg_loss=0.3026  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.370s
2025-08-10 04:26:01 Train INFO: [Train]: Epoch 95 completed in 1267.6s (avg 24.377s/iter)
2025-08-10 04:26:01 Train INFO: [Train]: Final Loss=0.9748
2025-08-10 04:26:01 Train INFO: [Train]: Epoch 96 started (Total iterations: 52)
2025-08-10 04:29:40 Train INFO: [Train]: [096][00005/00051] (11.5%)  Loss=0.9227  cls_loss=0.6409  reg_loss=0.2818  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1675s  iter_time=218.433s  fwd=2.049s/bwd=4.299s/opt=3.090s
2025-08-10 04:31:16 Train INFO: [Train]: [096][00010/00051] (21.2%)  Loss=0.9235  cls_loss=0.6462  reg_loss=0.2773  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1173s  iter_time=96.240s
2025-08-10 04:33:08 Train INFO: [Train]: [096][00015/00051] (30.8%)  Loss=0.9766  cls_loss=0.6817  reg_loss=0.2949  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=961s  iter_time=112.300s
2025-08-10 04:35:50 Train INFO: [Train]: [096][00020/00051] (40.4%)  Loss=0.9835  cls_loss=0.6850  reg_loss=0.2984  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=868s  iter_time=161.211s
2025-08-10 04:37:35 Train INFO: [Train]: [096][00025/00051] (50.0%)  Loss=0.9803  cls_loss=0.6833  reg_loss=0.2970  lr_backbone=1.0e-06  lr_det=1.0e-05  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=694s  iter_time=105.457s
2025-08-10 04:39:19 Train INFO: [Train]: [096][00030/00051] (59.6%)  Loss=0.9769  cls_loss=0.6801  reg_loss=0.2968  lr_backbone=1.0e-06  lr_det=9.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=540s  iter_time=104.141s
2025-08-10 04:41:00 Train INFO: [Train]: [096][00035/00051] (69.2%)  Loss=0.9756  cls_loss=0.6782  reg_loss=0.2974  lr_backbone=9.9e-07  lr_det=9.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=100.883s
2025-08-10 04:43:36 Train INFO: [Train]: [096][00040/00051] (78.8%)  Loss=0.9737  cls_loss=0.6772  reg_loss=0.2966  lr_backbone=9.8e-07  lr_det=9.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=155.693s
2025-08-10 04:45:20 Train INFO: [Train]: [096][00045/00051] (88.5%)  Loss=0.9734  cls_loss=0.6755  reg_loss=0.2979  lr_backbone=9.7e-07  lr_det=9.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=104.022s
2025-08-10 04:47:04 Train INFO: [Train]: [096][00050/00051] (98.1%)  Loss=0.9751  cls_loss=0.6765  reg_loss=0.2985  lr_backbone=9.7e-07  lr_det=9.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=104.169s
2025-08-10 04:47:14 Train INFO: [Train]: [096][00051/00051] (100.0%)  Loss=0.9758  cls_loss=0.6768  reg_loss=0.2990  lr_backbone=9.7e-07  lr_det=9.6e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.357s
2025-08-10 04:47:15 Train INFO: [Train]: Epoch 96 completed in 1273.6s (avg 24.493s/iter)
2025-08-10 04:47:15 Train INFO: [Train]: Final Loss=0.9758
2025-08-10 04:47:15 Train INFO: [Train]: Epoch 97 started (Total iterations: 52)
2025-08-10 04:51:02 Train INFO: [Train]: [097][00005/00051] (11.5%)  Loss=0.9677  cls_loss=0.6720  reg_loss=0.2957  lr_backbone=9.6e-07  lr_det=9.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1739s  iter_time=226.776s  fwd=2.062s/bwd=4.309s/opt=3.077s
2025-08-10 04:52:45 Train INFO: [Train]: [097][00010/00051] (21.2%)  Loss=0.9381  cls_loss=0.6526  reg_loss=0.2855  lr_backbone=9.5e-07  lr_det=9.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1230s  iter_time=103.105s
2025-08-10 04:54:29 Train INFO: [Train]: [097][00015/00051] (30.8%)  Loss=0.9323  cls_loss=0.6448  reg_loss=0.2875  lr_backbone=9.4e-07  lr_det=9.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=976s  iter_time=103.839s
2025-08-10 04:57:10 Train INFO: [Train]: [097][00020/00051] (40.4%)  Loss=0.9279  cls_loss=0.6425  reg_loss=0.2853  lr_backbone=9.3e-07  lr_det=9.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=878s  iter_time=161.094s
2025-08-10 04:58:49 Train INFO: [Train]: [097][00025/00051] (50.0%)  Loss=0.9442  cls_loss=0.6536  reg_loss=0.2906  lr_backbone=9.3e-07  lr_det=9.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=694s  iter_time=99.517s
2025-08-10 05:00:27 Train INFO: [Train]: [097][00030/00051] (59.6%)  Loss=0.9574  cls_loss=0.6620  reg_loss=0.2953  lr_backbone=9.2e-07  lr_det=9.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=537s  iter_time=97.957s
2025-08-10 05:02:10 Train INFO: [Train]: [097][00035/00051] (69.2%)  Loss=0.9616  cls_loss=0.6652  reg_loss=0.2964  lr_backbone=9.1e-07  lr_det=9.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=102.979s
2025-08-10 05:04:48 Train INFO: [Train]: [097][00040/00051] (78.8%)  Loss=0.9606  cls_loss=0.6630  reg_loss=0.2976  lr_backbone=9.0e-07  lr_det=8.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=157.468s
2025-08-10 05:06:33 Train INFO: [Train]: [097][00045/00051] (88.5%)  Loss=0.9555  cls_loss=0.6604  reg_loss=0.2951  lr_backbone=9.0e-07  lr_det=8.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=105.694s
2025-08-10 05:08:23 Train INFO: [Train]: [097][00050/00051] (98.1%)  Loss=0.9598  cls_loss=0.6642  reg_loss=0.2956  lr_backbone=8.9e-07  lr_det=8.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=109.576s
2025-08-10 05:08:33 Train INFO: [Train]: [097][00051/00051] (100.0%)  Loss=0.9585  cls_loss=0.6636  reg_loss=0.2948  lr_backbone=8.9e-07  lr_det=8.8e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.376s
2025-08-10 05:08:34 Train INFO: [Train]: Epoch 97 completed in 1279.1s (avg 24.599s/iter)
2025-08-10 05:08:34 Train INFO: [Train]: Final Loss=0.9585
2025-08-10 05:08:34 Train INFO: [Train]: Epoch 98 started (Total iterations: 52)
2025-08-10 05:12:24 Train INFO: [Train]: [098][00005/00051] (11.5%)  Loss=0.9438  cls_loss=0.6497  reg_loss=0.2941  lr_backbone=8.8e-07  lr_det=8.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1760s  iter_time=229.574s  fwd=2.031s/bwd=4.277s/opt=3.088s
2025-08-10 05:14:11 Train INFO: [Train]: [098][00010/00051] (21.2%)  Loss=0.9795  cls_loss=0.6787  reg_loss=0.3007  lr_backbone=8.7e-07  lr_det=8.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1256s  iter_time=107.525s
2025-08-10 05:15:50 Train INFO: [Train]: [098][00015/00051] (30.8%)  Loss=0.9920  cls_loss=0.6870  reg_loss=0.3051  lr_backbone=8.6e-07  lr_det=8.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=981s  iter_time=98.703s
2025-08-10 05:18:30 Train INFO: [Train]: [098][00020/00051] (40.4%)  Loss=0.9689  cls_loss=0.6713  reg_loss=0.2976  lr_backbone=8.6e-07  lr_det=8.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=880s  iter_time=160.093s
2025-08-10 05:20:12 Train INFO: [Train]: [098][00025/00051] (50.0%)  Loss=0.9664  cls_loss=0.6692  reg_loss=0.2972  lr_backbone=8.5e-07  lr_det=8.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=101.886s
2025-08-10 05:21:58 Train INFO: [Train]: [098][00030/00051] (59.6%)  Loss=0.9763  cls_loss=0.6750  reg_loss=0.3013  lr_backbone=8.4e-07  lr_det=8.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=544s  iter_time=105.737s
2025-08-10 05:23:46 Train INFO: [Train]: [098][00035/00051] (69.2%)  Loss=0.9834  cls_loss=0.6812  reg_loss=0.3021  lr_backbone=8.3e-07  lr_det=8.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=405s  iter_time=108.440s
2025-08-10 05:26:13 Train INFO: [Train]: [098][00040/00051] (78.8%)  Loss=0.9864  cls_loss=0.6819  reg_loss=0.3044  lr_backbone=8.3e-07  lr_det=8.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=147.435s
2025-08-10 05:28:02 Train INFO: [Train]: [098][00045/00051] (88.5%)  Loss=0.9823  cls_loss=0.6797  reg_loss=0.3027  lr_backbone=8.2e-07  lr_det=8.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=108.379s
2025-08-10 05:29:41 Train INFO: [Train]: [098][00050/00051] (98.1%)  Loss=0.9842  cls_loss=0.6816  reg_loss=0.3026  lr_backbone=8.1e-07  lr_det=8.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.240s
2025-08-10 05:29:51 Train INFO: [Train]: [098][00051/00051] (100.0%)  Loss=0.9820  cls_loss=0.6801  reg_loss=0.3018  lr_backbone=8.1e-07  lr_det=8.0e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.362s
2025-08-10 05:29:52 Train INFO: [Train]: Epoch 98 completed in 1278.1s (avg 24.579s/iter)
2025-08-10 05:29:52 Train INFO: [Train]: Final Loss=0.9820
2025-08-10 05:29:52 Train INFO: [Train]: Epoch 99 started (Total iterations: 52)
2025-08-10 05:33:33 Train INFO: [Train]: [099][00005/00051] (11.5%)  Loss=0.9944  cls_loss=0.6769  reg_loss=0.3176  lr_backbone=8.0e-07  lr_det=7.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1693s  iter_time=220.781s  fwd=2.031s/bwd=4.271s/opt=3.101s
2025-08-10 05:35:22 Train INFO: [Train]: [099][00010/00051] (21.2%)  Loss=0.9551  cls_loss=0.6567  reg_loss=0.2984  lr_backbone=8.0e-07  lr_det=7.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1231s  iter_time=109.520s
2025-08-10 05:37:05 Train INFO: [Train]: [099][00015/00051] (30.8%)  Loss=1.0086  cls_loss=0.6901  reg_loss=0.3185  lr_backbone=7.9e-07  lr_det=7.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=974s  iter_time=102.646s
2025-08-10 05:39:41 Train INFO: [Train]: [099][00020/00051] (40.4%)  Loss=1.0021  cls_loss=0.6865  reg_loss=0.3156  lr_backbone=7.8e-07  lr_det=7.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=869s  iter_time=155.746s
2025-08-10 05:41:30 Train INFO: [Train]: [099][00025/00051] (50.0%)  Loss=0.9877  cls_loss=0.6780  reg_loss=0.3096  lr_backbone=7.7e-07  lr_det=7.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=109.360s
2025-08-10 05:43:11 Train INFO: [Train]: [099][00030/00051] (59.6%)  Loss=0.9798  cls_loss=0.6726  reg_loss=0.3072  lr_backbone=7.7e-07  lr_det=7.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=100.431s
2025-08-10 05:44:47 Train INFO: [Train]: [099][00035/00051] (69.2%)  Loss=0.9839  cls_loss=0.6752  reg_loss=0.3087  lr_backbone=7.6e-07  lr_det=7.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=96.281s
2025-08-10 05:47:25 Train INFO: [Train]: [099][00040/00051] (78.8%)  Loss=0.9674  cls_loss=0.6649  reg_loss=0.3026  lr_backbone=7.5e-07  lr_det=7.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=158.460s
2025-08-10 05:49:07 Train INFO: [Train]: [099][00045/00051] (88.5%)  Loss=0.9714  cls_loss=0.6688  reg_loss=0.3027  lr_backbone=7.5e-07  lr_det=7.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=101.141s
2025-08-10 05:50:45 Train INFO: [Train]: [099][00050/00051] (98.1%)  Loss=0.9715  cls_loss=0.6704  reg_loss=0.3011  lr_backbone=7.4e-07  lr_det=7.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.912s
2025-08-10 05:50:56 Train INFO: [Train]: [099][00051/00051] (100.0%)  Loss=0.9675  cls_loss=0.6674  reg_loss=0.3001  lr_backbone=7.4e-07  lr_det=7.3e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.379s
2025-08-10 05:50:57 Train INFO: [Train]: Epoch 99 completed in 1264.4s (avg 24.315s/iter)
2025-08-10 05:50:57 Train INFO: [Train]: Final Loss=0.9675
2025-08-10 05:50:57 Train INFO: [Val]: Epoch 99 Loss
2025-08-10 06:39:26 Train INFO: [Val]: [099]  Loss=1.0072  cls_loss=0.6945  reg_loss=0.3127  Average-mAP=0.86%
2025-08-10 06:39:28 Train INFO: Checkpoint saved at epoch 99
2025-08-10 06:39:28 Train INFO: [Train]: Epoch 100 started (Total iterations: 52)
2025-08-10 06:43:21 Train INFO: [Train]: [100][00005/00051] (11.5%)  Loss=1.0141  cls_loss=0.7013  reg_loss=0.3128  lr_backbone=7.3e-07  lr_det=7.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1782s  iter_time=232.498s  fwd=2.039s/bwd=4.308s/opt=3.078s
2025-08-10 06:45:00 Train INFO: [Train]: [100][00010/00051] (21.2%)  Loss=0.9994  cls_loss=0.6952  reg_loss=0.3042  lr_backbone=7.2e-07  lr_det=7.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1237s  iter_time=99.444s
2025-08-10 06:46:44 Train INFO: [Train]: [100][00015/00051] (30.8%)  Loss=0.9930  cls_loss=0.6920  reg_loss=0.3010  lr_backbone=7.2e-07  lr_det=7.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=981s  iter_time=104.029s
2025-08-10 06:49:23 Train INFO: [Train]: [100][00020/00051] (40.4%)  Loss=0.9801  cls_loss=0.6812  reg_loss=0.2989  lr_backbone=7.1e-07  lr_det=7.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=879s  iter_time=159.147s
2025-08-10 06:51:12 Train INFO: [Train]: [100][00025/00051] (50.0%)  Loss=0.9719  cls_loss=0.6742  reg_loss=0.2976  lr_backbone=7.0e-07  lr_det=7.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=703s  iter_time=108.304s
2025-08-10 06:52:54 Train INFO: [Train]: [100][00030/00051] (59.6%)  Loss=0.9757  cls_loss=0.6759  reg_loss=0.2998  lr_backbone=7.0e-07  lr_det=6.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=546s  iter_time=102.047s
2025-08-10 06:54:35 Train INFO: [Train]: [100][00035/00051] (69.2%)  Loss=0.9832  cls_loss=0.6811  reg_loss=0.3021  lr_backbone=6.9e-07  lr_det=6.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=403s  iter_time=100.955s
2025-08-10 06:56:54 Train INFO: [Train]: [100][00040/00051] (78.8%)  Loss=0.9814  cls_loss=0.6799  reg_loss=0.3015  lr_backbone=6.8e-07  lr_det=6.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=280s  iter_time=138.900s
2025-08-10 06:58:48 Train INFO: [Train]: [100][00045/00051] (88.5%)  Loss=0.9778  cls_loss=0.6774  reg_loss=0.3005  lr_backbone=6.8e-07  lr_det=6.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=114.577s
2025-08-10 07:00:24 Train INFO: [Train]: [100][00050/00051] (98.1%)  Loss=0.9789  cls_loss=0.6778  reg_loss=0.3012  lr_backbone=6.7e-07  lr_det=6.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=95.739s
2025-08-10 07:00:34 Train INFO: [Train]: [100][00051/00051] (100.0%)  Loss=0.9747  cls_loss=0.6749  reg_loss=0.2998  lr_backbone=6.7e-07  lr_det=6.6e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.383s
2025-08-10 07:00:35 Train INFO: [Train]: Epoch 100 completed in 1266.8s (avg 24.361s/iter)
2025-08-10 07:00:35 Train INFO: [Train]: Final Loss=0.9747
2025-08-10 07:00:35 Train INFO: [Train]: Epoch 101 started (Total iterations: 52)
2025-08-10 07:04:17 Train INFO: [Train]: [101][00005/00051] (11.5%)  Loss=0.9152  cls_loss=0.6395  reg_loss=0.2757  lr_backbone=6.6e-07  lr_det=6.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1705s  iter_time=222.417s  fwd=2.072s/bwd=4.311s/opt=3.092s
2025-08-10 07:05:54 Train INFO: [Train]: [101][00010/00051] (21.2%)  Loss=0.9475  cls_loss=0.6597  reg_loss=0.2878  lr_backbone=6.5e-07  lr_det=6.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1190s  iter_time=96.830s
2025-08-10 07:07:37 Train INFO: [Train]: [101][00015/00051] (30.8%)  Loss=0.9398  cls_loss=0.6526  reg_loss=0.2872  lr_backbone=6.5e-07  lr_det=6.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=948s  iter_time=102.233s
2025-08-10 07:09:59 Train INFO: [Train]: [101][00020/00051] (40.4%)  Loss=0.9732  cls_loss=0.6738  reg_loss=0.2995  lr_backbone=6.4e-07  lr_det=6.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=833s  iter_time=142.880s
2025-08-10 07:11:38 Train INFO: [Train]: [101][00025/00051] (50.0%)  Loss=0.9880  cls_loss=0.6838  reg_loss=0.3042  lr_backbone=6.4e-07  lr_det=6.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=663s  iter_time=98.504s
2025-08-10 07:13:17 Train INFO: [Train]: [101][00030/00051] (59.6%)  Loss=0.9927  cls_loss=0.6867  reg_loss=0.3060  lr_backbone=6.3e-07  lr_det=6.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=516s  iter_time=99.170s
2025-08-10 07:15:04 Train INFO: [Train]: [101][00035/00051] (69.2%)  Loss=0.9873  cls_loss=0.6817  reg_loss=0.3056  lr_backbone=6.2e-07  lr_det=6.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=386s  iter_time=107.013s
2025-08-10 07:17:56 Train INFO: [Train]: [101][00040/00051] (78.8%)  Loss=0.9758  cls_loss=0.6735  reg_loss=0.3023  lr_backbone=6.2e-07  lr_det=6.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=279s  iter_time=171.966s
2025-08-10 07:19:43 Train INFO: [Train]: [101][00045/00051] (88.5%)  Loss=0.9695  cls_loss=0.6692  reg_loss=0.3003  lr_backbone=6.1e-07  lr_det=6.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=106.834s
2025-08-10 07:21:21 Train INFO: [Train]: [101][00050/00051] (98.1%)  Loss=0.9732  cls_loss=0.6720  reg_loss=0.3012  lr_backbone=6.0e-07  lr_det=6.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=98.403s
2025-08-10 07:21:32 Train INFO: [Train]: [101][00051/00051] (100.0%)  Loss=0.9715  cls_loss=0.6709  reg_loss=0.3006  lr_backbone=6.0e-07  lr_det=5.9e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.369s
2025-08-10 07:21:32 Train INFO: [Train]: Epoch 101 completed in 1257.4s (avg 24.180s/iter)
2025-08-10 07:21:32 Train INFO: [Train]: Final Loss=0.9715
2025-08-10 07:21:32 Train INFO: [Train]: Epoch 102 started (Total iterations: 52)
2025-08-10 07:25:11 Train INFO: [Train]: [102][00005/00051] (11.5%)  Loss=0.9922  cls_loss=0.6830  reg_loss=0.3092  lr_backbone=6.0e-07  lr_det=5.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1675s  iter_time=218.447s  fwd=2.035s/bwd=4.265s/opt=3.080s
2025-08-10 07:26:54 Train INFO: [Train]: [102][00010/00051] (21.2%)  Loss=0.9534  cls_loss=0.6575  reg_loss=0.2959  lr_backbone=5.9e-07  lr_det=5.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1200s  iter_time=103.460s
2025-08-10 07:28:51 Train INFO: [Train]: [102][00015/00051] (30.8%)  Loss=0.9638  cls_loss=0.6641  reg_loss=0.2997  lr_backbone=5.8e-07  lr_det=5.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=988s  iter_time=117.010s
2025-08-10 07:31:33 Train INFO: [Train]: [102][00020/00051] (40.4%)  Loss=0.9712  cls_loss=0.6695  reg_loss=0.3018  lr_backbone=5.8e-07  lr_det=5.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=886s  iter_time=161.333s
2025-08-10 07:33:20 Train INFO: [Train]: [102][00025/00051] (50.0%)  Loss=0.9839  cls_loss=0.6800  reg_loss=0.3039  lr_backbone=5.7e-07  lr_det=5.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=708s  iter_time=107.745s
2025-08-10 07:35:03 Train INFO: [Train]: [102][00030/00051] (59.6%)  Loss=0.9893  cls_loss=0.6839  reg_loss=0.3054  lr_backbone=5.7e-07  lr_det=5.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=549s  iter_time=102.407s
2025-08-10 07:36:56 Train INFO: [Train]: [102][00035/00051] (69.2%)  Loss=0.9811  cls_loss=0.6781  reg_loss=0.3030  lr_backbone=5.6e-07  lr_det=5.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=410s  iter_time=113.189s
2025-08-10 07:39:25 Train INFO: [Train]: [102][00040/00051] (78.8%)  Loss=0.9791  cls_loss=0.6768  reg_loss=0.3023  lr_backbone=5.5e-07  lr_det=5.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=288s  iter_time=149.338s
2025-08-10 07:41:07 Train INFO: [Train]: [102][00045/00051] (88.5%)  Loss=0.9775  cls_loss=0.6758  reg_loss=0.3017  lr_backbone=5.5e-07  lr_det=5.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=101.913s
2025-08-10 07:42:44 Train INFO: [Train]: [102][00050/00051] (98.1%)  Loss=0.9783  cls_loss=0.6761  reg_loss=0.3023  lr_backbone=5.4e-07  lr_det=5.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=96.394s
2025-08-10 07:42:54 Train INFO: [Train]: [102][00051/00051] (100.0%)  Loss=0.9764  cls_loss=0.6743  reg_loss=0.3021  lr_backbone=5.4e-07  lr_det=5.3e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.370s
2025-08-10 07:42:55 Train INFO: [Train]: Epoch 102 completed in 1282.4s (avg 24.661s/iter)
2025-08-10 07:42:55 Train INFO: [Train]: Final Loss=0.9764
2025-08-10 07:42:55 Train INFO: [Train]: Epoch 103 started (Total iterations: 52)
2025-08-10 07:46:43 Train INFO: [Train]: [103][00005/00051] (11.5%)  Loss=1.0047  cls_loss=0.6962  reg_loss=0.3084  lr_backbone=5.3e-07  lr_det=5.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1751s  iter_time=228.438s  fwd=2.051s/bwd=4.329s/opt=3.077s
2025-08-10 07:48:19 Train INFO: [Train]: [103][00010/00051] (21.2%)  Loss=0.9920  cls_loss=0.6907  reg_loss=0.3013  lr_backbone=5.3e-07  lr_det=5.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1207s  iter_time=95.329s
2025-08-10 07:49:59 Train INFO: [Train]: [103][00015/00051] (30.8%)  Loss=0.9922  cls_loss=0.6909  reg_loss=0.3014  lr_backbone=5.2e-07  lr_det=5.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=954s  iter_time=100.256s
2025-08-10 07:52:43 Train INFO: [Train]: [103][00020/00051] (40.4%)  Loss=0.9870  cls_loss=0.6837  reg_loss=0.3033  lr_backbone=5.2e-07  lr_det=5.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=869s  iter_time=164.483s
2025-08-10 07:54:24 Train INFO: [Train]: [103][00025/00051] (50.0%)  Loss=0.9880  cls_loss=0.6841  reg_loss=0.3039  lr_backbone=5.1e-07  lr_det=5.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=690s  iter_time=101.005s
2025-08-10 07:56:03 Train INFO: [Train]: [103][00030/00051] (59.6%)  Loss=0.9807  cls_loss=0.6780  reg_loss=0.3026  lr_backbone=5.0e-07  lr_det=5.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=534s  iter_time=98.875s
2025-08-10 07:57:54 Train INFO: [Train]: [103][00035/00051] (69.2%)  Loss=0.9769  cls_loss=0.6759  reg_loss=0.3010  lr_backbone=5.0e-07  lr_det=4.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=399s  iter_time=110.456s
2025-08-10 08:00:26 Train INFO: [Train]: [103][00040/00051] (78.8%)  Loss=0.9768  cls_loss=0.6753  reg_loss=0.3014  lr_backbone=4.9e-07  lr_det=4.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=152.663s
2025-08-10 08:02:20 Train INFO: [Train]: [103][00045/00051] (88.5%)  Loss=0.9770  cls_loss=0.6763  reg_loss=0.3007  lr_backbone=4.9e-07  lr_det=4.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=113.383s
2025-08-10 08:03:56 Train INFO: [Train]: [103][00050/00051] (98.1%)  Loss=0.9735  cls_loss=0.6740  reg_loss=0.2995  lr_backbone=4.8e-07  lr_det=4.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=96.148s
2025-08-10 08:04:06 Train INFO: [Train]: [103][00051/00051] (100.0%)  Loss=0.9724  cls_loss=0.6730  reg_loss=0.2995  lr_backbone=4.8e-07  lr_det=4.7e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.356s
2025-08-10 08:04:07 Train INFO: [Train]: Epoch 103 completed in 1272.1s (avg 24.464s/iter)
2025-08-10 08:04:07 Train INFO: [Train]: Final Loss=0.9724
2025-08-10 08:04:07 Train INFO: [Train]: Epoch 104 started (Total iterations: 52)
2025-08-10 08:07:48 Train INFO: [Train]: [104][00005/00051] (11.5%)  Loss=0.9330  cls_loss=0.6396  reg_loss=0.2934  lr_backbone=4.7e-07  lr_det=4.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1694s  iter_time=220.935s  fwd=2.056s/bwd=4.297s/opt=3.073s
2025-08-10 08:09:35 Train INFO: [Train]: [104][00010/00051] (21.2%)  Loss=0.9460  cls_loss=0.6571  reg_loss=0.2888  lr_backbone=4.7e-07  lr_det=4.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1221s  iter_time=106.676s
2025-08-10 08:11:23 Train INFO: [Train]: [104][00015/00051] (30.8%)  Loss=0.9750  cls_loss=0.6732  reg_loss=0.3018  lr_backbone=4.6e-07  lr_det=4.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=982s  iter_time=108.891s
2025-08-10 08:14:16 Train INFO: [Train]: [104][00020/00051] (40.4%)  Loss=0.9770  cls_loss=0.6722  reg_loss=0.3047  lr_backbone=4.6e-07  lr_det=4.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=900s  iter_time=173.018s
2025-08-10 08:16:00 Train INFO: [Train]: [104][00025/00051] (50.0%)  Loss=0.9860  cls_loss=0.6780  reg_loss=0.3079  lr_backbone=4.5e-07  lr_det=4.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=713s  iter_time=103.663s
2025-08-10 08:17:37 Train INFO: [Train]: [104][00030/00051] (59.6%)  Loss=0.9810  cls_loss=0.6757  reg_loss=0.3052  lr_backbone=4.5e-07  lr_det=4.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=549s  iter_time=96.579s
2025-08-10 08:19:29 Train INFO: [Train]: [104][00035/00051] (69.2%)  Loss=0.9679  cls_loss=0.6675  reg_loss=0.3004  lr_backbone=4.4e-07  lr_det=4.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=410s  iter_time=112.004s
2025-08-10 08:22:05 Train INFO: [Train]: [104][00040/00051] (78.8%)  Loss=0.9790  cls_loss=0.6752  reg_loss=0.3038  lr_backbone=4.4e-07  lr_det=4.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=289s  iter_time=156.123s
2025-08-10 08:23:42 Train INFO: [Train]: [104][00045/00051] (88.5%)  Loss=0.9821  cls_loss=0.6774  reg_loss=0.3046  lr_backbone=4.3e-07  lr_det=4.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=96.986s
2025-08-10 08:25:20 Train INFO: [Train]: [104][00050/00051] (98.1%)  Loss=0.9845  cls_loss=0.6789  reg_loss=0.3056  lr_backbone=4.3e-07  lr_det=4.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.002s
2025-08-10 08:25:30 Train INFO: [Train]: [104][00051/00051] (100.0%)  Loss=0.9805  cls_loss=0.6758  reg_loss=0.3047  lr_backbone=4.2e-07  lr_det=4.2e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.358s
2025-08-10 08:25:31 Train INFO: [Train]: Epoch 104 completed in 1284.0s (avg 24.692s/iter)
2025-08-10 08:25:31 Train INFO: [Train]: Final Loss=0.9805
2025-08-10 08:25:31 Train INFO: [Val]: Epoch 104 Loss
2025-08-10 09:14:02 Train INFO: [Val]: [104]  Loss=1.0074  cls_loss=0.6947  reg_loss=0.3127  Average-mAP=0.79%
2025-08-10 09:14:04 Train INFO: Checkpoint saved at epoch 104
2025-08-10 09:14:04 Train INFO: [Train]: Epoch 105 started (Total iterations: 52)
2025-08-10 09:17:52 Train INFO: [Train]: [105][00005/00051] (11.5%)  Loss=0.9103  cls_loss=0.6259  reg_loss=0.2844  lr_backbone=4.2e-07  lr_det=4.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1746s  iter_time=227.682s  fwd=2.073s/bwd=4.320s/opt=3.073s
2025-08-10 09:19:31 Train INFO: [Train]: [105][00010/00051] (21.2%)  Loss=0.9482  cls_loss=0.6535  reg_loss=0.2946  lr_backbone=4.1e-07  lr_det=4.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1217s  iter_time=98.952s
2025-08-10 09:21:18 Train INFO: [Train]: [105][00015/00051] (30.8%)  Loss=0.9626  cls_loss=0.6637  reg_loss=0.2988  lr_backbone=4.1e-07  lr_det=4.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=976s  iter_time=107.053s
2025-08-10 09:23:59 Train INFO: [Train]: [105][00020/00051] (40.4%)  Loss=0.9598  cls_loss=0.6622  reg_loss=0.2976  lr_backbone=4.0e-07  lr_det=3.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=878s  iter_time=160.843s
2025-08-10 09:25:42 Train INFO: [Train]: [105][00025/00051] (50.0%)  Loss=0.9749  cls_loss=0.6738  reg_loss=0.3011  lr_backbone=4.0e-07  lr_det=3.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=698s  iter_time=103.269s
2025-08-10 09:27:25 Train INFO: [Train]: [105][00030/00051] (59.6%)  Loss=0.9762  cls_loss=0.6745  reg_loss=0.3018  lr_backbone=3.9e-07  lr_det=3.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=542s  iter_time=102.685s
2025-08-10 09:29:05 Train INFO: [Train]: [105][00035/00051] (69.2%)  Loss=0.9791  cls_loss=0.6761  reg_loss=0.3029  lr_backbone=3.9e-07  lr_det=3.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=100.191s
2025-08-10 09:31:30 Train INFO: [Train]: [105][00040/00051] (78.8%)  Loss=0.9761  cls_loss=0.6734  reg_loss=0.3027  lr_backbone=3.8e-07  lr_det=3.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=145.466s
2025-08-10 09:33:28 Train INFO: [Train]: [105][00045/00051] (88.5%)  Loss=0.9724  cls_loss=0.6715  reg_loss=0.3009  lr_backbone=3.8e-07  lr_det=3.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=117.810s
2025-08-10 09:34:57 Train INFO: [Train]: [105][00050/00051] (98.1%)  Loss=0.9690  cls_loss=0.6689  reg_loss=0.3001  lr_backbone=3.7e-07  lr_det=3.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=88.617s
2025-08-10 09:35:07 Train INFO: [Train]: [105][00051/00051] (100.0%)  Loss=0.9671  cls_loss=0.6675  reg_loss=0.2996  lr_backbone=3.7e-07  lr_det=3.6e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-10 09:35:08 Train INFO: [Train]: Epoch 105 completed in 1263.7s (avg 24.301s/iter)
2025-08-10 09:35:08 Train INFO: [Train]: Final Loss=0.9671
2025-08-10 09:35:08 Train INFO: [Train]: Epoch 106 started (Total iterations: 52)
2025-08-10 09:38:52 Train INFO: [Train]: [106][00005/00051] (11.5%)  Loss=0.9680  cls_loss=0.6711  reg_loss=0.2969  lr_backbone=3.7e-07  lr_det=3.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1718s  iter_time=224.046s  fwd=2.076s/bwd=4.277s/opt=3.079s
2025-08-10 09:40:31 Train INFO: [Train]: [106][00010/00051] (21.2%)  Loss=0.9860  cls_loss=0.6825  reg_loss=0.3036  lr_backbone=3.6e-07  lr_det=3.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1205s  iter_time=99.369s
2025-08-10 09:42:22 Train INFO: [Train]: [106][00015/00051] (30.8%)  Loss=0.9683  cls_loss=0.6705  reg_loss=0.2978  lr_backbone=3.6e-07  lr_det=3.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=976s  iter_time=110.537s
2025-08-10 09:44:48 Train INFO: [Train]: [106][00020/00051] (40.4%)  Loss=0.9693  cls_loss=0.6694  reg_loss=0.3000  lr_backbone=3.5e-07  lr_det=3.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=856s  iter_time=146.033s
2025-08-10 09:46:28 Train INFO: [Train]: [106][00025/00051] (50.0%)  Loss=0.9707  cls_loss=0.6719  reg_loss=0.2988  lr_backbone=3.5e-07  lr_det=3.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=680s  iter_time=99.997s
2025-08-10 09:48:07 Train INFO: [Train]: [106][00030/00051] (59.6%)  Loss=0.9667  cls_loss=0.6679  reg_loss=0.2988  lr_backbone=3.4e-07  lr_det=3.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=528s  iter_time=99.025s
2025-08-10 09:49:49 Train INFO: [Train]: [106][00035/00051] (69.2%)  Loss=0.9672  cls_loss=0.6684  reg_loss=0.2988  lr_backbone=3.4e-07  lr_det=3.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=392s  iter_time=102.234s
2025-08-10 09:52:19 Train INFO: [Train]: [106][00040/00051] (78.8%)  Loss=0.9724  cls_loss=0.6722  reg_loss=0.3002  lr_backbone=3.3e-07  lr_det=3.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=277s  iter_time=150.285s
2025-08-10 09:53:59 Train INFO: [Train]: [106][00045/00051] (88.5%)  Loss=0.9764  cls_loss=0.6757  reg_loss=0.3007  lr_backbone=3.3e-07  lr_det=3.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=99.253s
2025-08-10 09:55:35 Train INFO: [Train]: [106][00050/00051] (98.1%)  Loss=0.9750  cls_loss=0.6750  reg_loss=0.3001  lr_backbone=3.2e-07  lr_det=3.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.426s
2025-08-10 09:55:45 Train INFO: [Train]: [106][00051/00051] (100.0%)  Loss=0.9738  cls_loss=0.6739  reg_loss=0.2999  lr_backbone=3.2e-07  lr_det=3.1e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.367s
2025-08-10 09:55:46 Train INFO: [Train]: Epoch 106 completed in 1238.3s (avg 23.814s/iter)
2025-08-10 09:55:46 Train INFO: [Train]: Final Loss=0.9738
2025-08-10 09:55:46 Train INFO: [Train]: Epoch 107 started (Total iterations: 52)
2025-08-10 09:59:24 Train INFO: [Train]: [107][00005/00051] (11.5%)  Loss=1.0152  cls_loss=0.6955  reg_loss=0.3197  lr_backbone=3.2e-07  lr_det=3.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1670s  iter_time=217.884s  fwd=2.037s/bwd=4.290s/opt=3.072s
2025-08-10 10:01:09 Train INFO: [Train]: [107][00010/00051] (21.2%)  Loss=1.0182  cls_loss=0.6994  reg_loss=0.3187  lr_backbone=3.1e-07  lr_det=3.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1203s  iter_time=104.851s
2025-08-10 10:02:55 Train INFO: [Train]: [107][00015/00051] (30.8%)  Loss=1.0137  cls_loss=0.6965  reg_loss=0.3172  lr_backbone=3.1e-07  lr_det=3.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=965s  iter_time=106.249s
2025-08-10 10:05:23 Train INFO: [Train]: [107][00020/00051] (40.4%)  Loss=0.9921  cls_loss=0.6826  reg_loss=0.3095  lr_backbone=3.0e-07  lr_det=2.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=851s  iter_time=147.514s
2025-08-10 10:07:07 Train INFO: [Train]: [107][00025/00051] (50.0%)  Loss=0.9653  cls_loss=0.6646  reg_loss=0.3007  lr_backbone=3.0e-07  lr_det=2.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=681s  iter_time=104.250s
2025-08-10 10:08:45 Train INFO: [Train]: [107][00030/00051] (59.6%)  Loss=0.9671  cls_loss=0.6672  reg_loss=0.2999  lr_backbone=2.9e-07  lr_det=2.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=527s  iter_time=97.747s
2025-08-10 10:10:37 Train INFO: [Train]: [107][00035/00051] (69.2%)  Loss=0.9589  cls_loss=0.6621  reg_loss=0.2968  lr_backbone=2.9e-07  lr_det=2.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=396s  iter_time=112.378s
2025-08-10 10:13:04 Train INFO: [Train]: [107][00040/00051] (78.8%)  Loss=0.9700  cls_loss=0.6702  reg_loss=0.2998  lr_backbone=2.9e-07  lr_det=2.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=278s  iter_time=146.876s
2025-08-10 10:14:45 Train INFO: [Train]: [107][00045/00051] (88.5%)  Loss=0.9781  cls_loss=0.6749  reg_loss=0.3032  lr_backbone=2.8e-07  lr_det=2.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=148s  iter_time=100.608s
2025-08-10 10:16:23 Train INFO: [Train]: [107][00050/00051] (98.1%)  Loss=0.9793  cls_loss=0.6763  reg_loss=0.3030  lr_backbone=2.8e-07  lr_det=2.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=98.665s
2025-08-10 10:16:34 Train INFO: [Train]: [107][00051/00051] (100.0%)  Loss=0.9789  cls_loss=0.6756  reg_loss=0.3033  lr_backbone=2.8e-07  lr_det=2.7e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.379s
2025-08-10 10:16:34 Train INFO: [Train]: Epoch 107 completed in 1248.2s (avg 24.003s/iter)
2025-08-10 10:16:34 Train INFO: [Train]: Final Loss=0.9789
2025-08-10 10:16:34 Train INFO: [Train]: Epoch 108 started (Total iterations: 52)
2025-08-10 10:20:28 Train INFO: [Train]: [108][00005/00051] (11.5%)  Loss=0.9186  cls_loss=0.6376  reg_loss=0.2810  lr_backbone=2.7e-07  lr_det=2.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1788s  iter_time=233.252s  fwd=2.099s/bwd=4.340s/opt=3.081s
2025-08-10 10:22:14 Train INFO: [Train]: [108][00010/00051] (21.2%)  Loss=0.9363  cls_loss=0.6491  reg_loss=0.2872  lr_backbone=2.7e-07  lr_det=2.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1266s  iter_time=106.332s
2025-08-10 10:23:56 Train INFO: [Train]: [108][00015/00051] (30.8%)  Loss=0.9538  cls_loss=0.6593  reg_loss=0.2945  lr_backbone=2.6e-07  lr_det=2.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=993s  iter_time=101.958s
2025-08-10 10:26:22 Train INFO: [Train]: [108][00020/00051] (40.4%)  Loss=0.9677  cls_loss=0.6711  reg_loss=0.2966  lr_backbone=2.6e-07  lr_det=2.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=868s  iter_time=146.556s
2025-08-10 10:28:02 Train INFO: [Train]: [108][00025/00051] (50.0%)  Loss=0.9632  cls_loss=0.6675  reg_loss=0.2956  lr_backbone=2.6e-07  lr_det=2.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=688s  iter_time=99.827s
2025-08-10 10:29:57 Train INFO: [Train]: [108][00030/00051] (59.6%)  Loss=0.9695  cls_loss=0.6719  reg_loss=0.2977  lr_backbone=2.5e-07  lr_det=2.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=114.346s
2025-08-10 10:31:40 Train INFO: [Train]: [108][00035/00051] (69.2%)  Loss=0.9687  cls_loss=0.6717  reg_loss=0.2970  lr_backbone=2.5e-07  lr_det=2.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=103.228s
2025-08-10 10:34:11 Train INFO: [Train]: [108][00040/00051] (78.8%)  Loss=0.9630  cls_loss=0.6670  reg_loss=0.2959  lr_backbone=2.4e-07  lr_det=2.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=284s  iter_time=151.414s
2025-08-10 10:35:58 Train INFO: [Train]: [108][00045/00051] (88.5%)  Loss=0.9626  cls_loss=0.6679  reg_loss=0.2947  lr_backbone=2.4e-07  lr_det=2.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=106.798s
2025-08-10 10:37:49 Train INFO: [Train]: [108][00050/00051] (98.1%)  Loss=0.9657  cls_loss=0.6700  reg_loss=0.2957  lr_backbone=2.4e-07  lr_det=2.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=110.856s
2025-08-10 10:37:59 Train INFO: [Train]: [108][00051/00051] (100.0%)  Loss=0.9679  cls_loss=0.6715  reg_loss=0.2965  lr_backbone=2.3e-07  lr_det=2.3e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.356s
2025-08-10 10:38:00 Train INFO: [Train]: Epoch 108 completed in 1285.7s (avg 24.724s/iter)
2025-08-10 10:38:00 Train INFO: [Train]: Final Loss=0.9679
2025-08-10 10:38:00 Train INFO: [Train]: Epoch 109 started (Total iterations: 52)
2025-08-10 10:41:55 Train INFO: [Train]: [109][00005/00051] (11.5%)  Loss=0.9195  cls_loss=0.6391  reg_loss=0.2803  lr_backbone=2.3e-07  lr_det=2.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1802s  iter_time=234.992s  fwd=2.034s/bwd=4.277s/opt=3.079s
2025-08-10 10:43:31 Train INFO: [Train]: [109][00010/00051] (21.2%)  Loss=0.9554  cls_loss=0.6626  reg_loss=0.2928  lr_backbone=2.3e-07  lr_det=2.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1233s  iter_time=95.718s
2025-08-10 10:45:10 Train INFO: [Train]: [109][00015/00051] (30.8%)  Loss=0.9748  cls_loss=0.6708  reg_loss=0.3039  lr_backbone=2.2e-07  lr_det=2.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=968s  iter_time=99.714s
2025-08-10 10:47:38 Train INFO: [Train]: [109][00020/00051] (40.4%)  Loss=0.9500  cls_loss=0.6553  reg_loss=0.2947  lr_backbone=2.2e-07  lr_det=2.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=854s  iter_time=147.971s
2025-08-10 10:49:16 Train INFO: [Train]: [109][00025/00051] (50.0%)  Loss=0.9635  cls_loss=0.6657  reg_loss=0.2978  lr_backbone=2.1e-07  lr_det=2.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=676s  iter_time=97.591s
2025-08-10 10:50:56 Train INFO: [Train]: [109][00030/00051] (59.6%)  Loss=0.9750  cls_loss=0.6719  reg_loss=0.3032  lr_backbone=2.1e-07  lr_det=2.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=526s  iter_time=100.091s
2025-08-10 10:52:35 Train INFO: [Train]: [109][00035/00051] (69.2%)  Loss=0.9666  cls_loss=0.6666  reg_loss=0.3001  lr_backbone=2.1e-07  lr_det=2.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=389s  iter_time=98.872s
2025-08-10 10:55:03 Train INFO: [Train]: [109][00040/00051] (78.8%)  Loss=0.9628  cls_loss=0.6633  reg_loss=0.2995  lr_backbone=2.0e-07  lr_det=1.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=275s  iter_time=148.255s
2025-08-10 10:56:47 Train INFO: [Train]: [109][00045/00051] (88.5%)  Loss=0.9596  cls_loss=0.6617  reg_loss=0.2979  lr_backbone=2.0e-07  lr_det=1.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=147s  iter_time=103.319s
2025-08-10 10:58:23 Train INFO: [Train]: [109][00050/00051] (98.1%)  Loss=0.9645  cls_loss=0.6646  reg_loss=0.2998  lr_backbone=2.0e-07  lr_det=1.9e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.820s
2025-08-10 10:58:34 Train INFO: [Train]: [109][00051/00051] (100.0%)  Loss=0.9625  cls_loss=0.6633  reg_loss=0.2992  lr_backbone=2.0e-07  lr_det=1.9e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.358s
2025-08-10 10:58:34 Train INFO: [Train]: Epoch 109 completed in 1234.4s (avg 23.739s/iter)
2025-08-10 10:58:34 Train INFO: [Train]: Final Loss=0.9625
2025-08-10 10:58:34 Train INFO: [Val]: Epoch 109 Loss
2025-08-10 11:46:05 Train INFO: [Val]: [109]  Loss=1.0073  cls_loss=0.6947  reg_loss=0.3127  Average-mAP=0.84%
2025-08-10 11:46:07 Train INFO: Checkpoint saved at epoch 109
2025-08-10 11:46:07 Train INFO: [Train]: Epoch 110 started (Total iterations: 52)
2025-08-10 11:50:05 Train INFO: [Train]: [110][00005/00051] (11.5%)  Loss=0.9690  cls_loss=0.6713  reg_loss=0.2977  lr_backbone=1.9e-07  lr_det=1.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1828s  iter_time=238.481s  fwd=2.098s/bwd=4.318s/opt=3.087s
2025-08-10 11:51:58 Train INFO: [Train]: [110][00010/00051] (21.2%)  Loss=0.9591  cls_loss=0.6663  reg_loss=0.2928  lr_backbone=1.9e-07  lr_det=1.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1311s  iter_time=113.136s
2025-08-10 11:53:40 Train INFO: [Train]: [110][00015/00051] (30.8%)  Loss=0.9700  cls_loss=0.6742  reg_loss=0.2958  lr_backbone=1.8e-07  lr_det=1.8e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1021s  iter_time=101.980s
2025-08-10 11:56:16 Train INFO: [Train]: [110][00020/00051] (40.4%)  Loss=0.9965  cls_loss=0.6906  reg_loss=0.3059  lr_backbone=1.8e-07  lr_det=1.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=899s  iter_time=155.145s
2025-08-10 11:58:06 Train INFO: [Train]: [110][00025/00051] (50.0%)  Loss=0.9694  cls_loss=0.6712  reg_loss=0.2982  lr_backbone=1.8e-07  lr_det=1.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=719s  iter_time=110.072s
2025-08-10 11:59:47 Train INFO: [Train]: [110][00030/00051] (59.6%)  Loss=0.9873  cls_loss=0.6832  reg_loss=0.3041  lr_backbone=1.7e-07  lr_det=1.7e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=556s  iter_time=101.706s
2025-08-10 12:01:31 Train INFO: [Train]: [110][00035/00051] (69.2%)  Loss=0.9774  cls_loss=0.6759  reg_loss=0.3015  lr_backbone=1.7e-07  lr_det=1.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=411s  iter_time=103.373s
2025-08-10 12:04:19 Train INFO: [Train]: [110][00040/00051] (78.8%)  Loss=0.9718  cls_loss=0.6722  reg_loss=0.2996  lr_backbone=1.7e-07  lr_det=1.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=293s  iter_time=168.612s
2025-08-10 12:06:08 Train INFO: [Train]: [110][00045/00051] (88.5%)  Loss=0.9678  cls_loss=0.6692  reg_loss=0.2986  lr_backbone=1.6e-07  lr_det=1.6e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=157s  iter_time=108.765s
2025-08-10 12:07:47 Train INFO: [Train]: [110][00050/00051] (98.1%)  Loss=0.9717  cls_loss=0.6720  reg_loss=0.2997  lr_backbone=1.6e-07  lr_det=1.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.127s
2025-08-10 12:07:58 Train INFO: [Train]: [110][00051/00051] (100.0%)  Loss=0.9668  cls_loss=0.6686  reg_loss=0.2982  lr_backbone=1.6e-07  lr_det=1.5e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.359s
2025-08-10 12:07:58 Train INFO: [Train]: Epoch 110 completed in 1311.5s (avg 25.222s/iter)
2025-08-10 12:07:58 Train INFO: [Train]: Final Loss=0.9668
2025-08-10 12:07:58 Train INFO: [Train]: Epoch 111 started (Total iterations: 52)
2025-08-10 12:11:56 Train INFO: [Train]: [111][00005/00051] (11.5%)  Loss=1.0097  cls_loss=0.7037  reg_loss=0.3060  lr_backbone=1.6e-07  lr_det=1.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1819s  iter_time=237.275s  fwd=2.061s/bwd=4.304s/opt=3.079s
2025-08-10 12:13:41 Train INFO: [Train]: [111][00010/00051] (21.2%)  Loss=0.9570  cls_loss=0.6698  reg_loss=0.2872  lr_backbone=1.5e-07  lr_det=1.5e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1277s  iter_time=105.436s
2025-08-10 12:15:26 Train INFO: [Train]: [111][00015/00051] (30.8%)  Loss=0.9626  cls_loss=0.6697  reg_loss=0.2929  lr_backbone=1.5e-07  lr_det=1.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1006s  iter_time=104.585s
2025-08-10 12:18:10 Train INFO: [Train]: [111][00020/00051] (40.4%)  Loss=0.9650  cls_loss=0.6694  reg_loss=0.2956  lr_backbone=1.5e-07  lr_det=1.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=903s  iter_time=164.610s
2025-08-10 12:19:56 Train INFO: [Train]: [111][00025/00051] (50.0%)  Loss=0.9812  cls_loss=0.6791  reg_loss=0.3021  lr_backbone=1.4e-07  lr_det=1.4e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=717s  iter_time=105.429s
2025-08-10 12:21:45 Train INFO: [Train]: [111][00030/00051] (59.6%)  Loss=0.9824  cls_loss=0.6800  reg_loss=0.3023  lr_backbone=1.4e-07  lr_det=1.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=560s  iter_time=109.639s
2025-08-10 12:23:23 Train INFO: [Train]: [111][00035/00051] (69.2%)  Loss=0.9706  cls_loss=0.6715  reg_loss=0.2991  lr_backbone=1.4e-07  lr_det=1.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=411s  iter_time=97.904s
2025-08-10 12:25:50 Train INFO: [Train]: [111][00040/00051] (78.8%)  Loss=0.9819  cls_loss=0.6782  reg_loss=0.3037  lr_backbone=1.4e-07  lr_det=1.3e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=287s  iter_time=146.298s
2025-08-10 12:27:43 Train INFO: [Train]: [111][00045/00051] (88.5%)  Loss=0.9782  cls_loss=0.6761  reg_loss=0.3021  lr_backbone=1.3e-07  lr_det=1.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=154s  iter_time=113.145s
2025-08-10 12:29:16 Train INFO: [Train]: [111][00050/00051] (98.1%)  Loss=0.9845  cls_loss=0.6805  reg_loss=0.3039  lr_backbone=1.3e-07  lr_det=1.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=93.526s
2025-08-10 12:29:27 Train INFO: [Train]: [111][00051/00051] (100.0%)  Loss=0.9816  cls_loss=0.6788  reg_loss=0.3028  lr_backbone=1.3e-07  lr_det=1.2e-06  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.364s
2025-08-10 12:29:27 Train INFO: [Train]: Epoch 111 completed in 1288.9s (avg 24.787s/iter)
2025-08-10 12:29:27 Train INFO: [Train]: Final Loss=0.9816
2025-08-10 12:29:27 Train INFO: [Train]: Epoch 112 started (Total iterations: 52)
2025-08-10 12:33:19 Train INFO: [Train]: [112][00005/00051] (11.5%)  Loss=0.9892  cls_loss=0.6809  reg_loss=0.3083  lr_backbone=1.3e-07  lr_det=1.2e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1774s  iter_time=231.430s  fwd=2.033s/bwd=4.307s/opt=3.080s
2025-08-10 12:35:04 Train INFO: [Train]: [112][00010/00051] (21.2%)  Loss=0.9308  cls_loss=0.6448  reg_loss=0.2860  lr_backbone=1.2e-07  lr_det=1.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1255s  iter_time=105.161s
2025-08-10 12:36:47 Train INFO: [Train]: [112][00015/00051] (30.8%)  Loss=0.9410  cls_loss=0.6533  reg_loss=0.2877  lr_backbone=1.2e-07  lr_det=1.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=989s  iter_time=102.906s
2025-08-10 12:39:33 Train INFO: [Train]: [112][00020/00051] (40.4%)  Loss=0.9554  cls_loss=0.6613  reg_loss=0.2942  lr_backbone=1.2e-07  lr_det=1.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=895s  iter_time=166.457s
2025-08-10 12:41:24 Train INFO: [Train]: [112][00025/00051] (50.0%)  Loss=0.9525  cls_loss=0.6614  reg_loss=0.2911  lr_backbone=1.2e-07  lr_det=1.1e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=717s  iter_time=110.719s
2025-08-10 12:43:07 Train INFO: [Train]: [112][00030/00051] (59.6%)  Loss=0.9607  cls_loss=0.6666  reg_loss=0.2941  lr_backbone=1.1e-07  lr_det=1.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=555s  iter_time=102.684s
2025-08-10 12:44:56 Train INFO: [Train]: [112][00035/00051] (69.2%)  Loss=0.9592  cls_loss=0.6657  reg_loss=0.2934  lr_backbone=1.1e-07  lr_det=1.0e-06  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=413s  iter_time=109.148s
2025-08-10 12:47:36 Train INFO: [Train]: [112][00040/00051] (78.8%)  Loss=0.9646  cls_loss=0.6703  reg_loss=0.2943  lr_backbone=1.1e-07  lr_det=9.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=292s  iter_time=160.277s
2025-08-10 12:49:18 Train INFO: [Train]: [112][00045/00051] (88.5%)  Loss=0.9688  cls_loss=0.6725  reg_loss=0.2963  lr_backbone=1.0e-07  lr_det=9.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=155s  iter_time=101.965s
2025-08-10 12:50:56 Train INFO: [Train]: [112][00050/00051] (98.1%)  Loss=0.9614  cls_loss=0.6667  reg_loss=0.2947  lr_backbone=1.0e-07  lr_det=9.3e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.014s
2025-08-10 12:51:06 Train INFO: [Train]: [112][00051/00051] (100.0%)  Loss=0.9578  cls_loss=0.6641  reg_loss=0.2938  lr_backbone=1.0e-07  lr_det=9.3e-07  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.359s
2025-08-10 12:51:07 Train INFO: [Train]: Epoch 112 completed in 1299.9s (avg 24.997s/iter)
2025-08-10 12:51:07 Train INFO: [Train]: Final Loss=0.9578
2025-08-10 12:51:07 Train INFO: [Train]: Epoch 113 started (Total iterations: 52)
2025-08-10 12:54:57 Train INFO: [Train]: [113][00005/00051] (11.5%)  Loss=0.9545  cls_loss=0.6695  reg_loss=0.2851  lr_backbone=9.9e-08  lr_det=9.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1764s  iter_time=230.080s  fwd=2.045s/bwd=4.298s/opt=3.075s
2025-08-10 12:56:39 Train INFO: [Train]: [113][00010/00051] (21.2%)  Loss=0.9450  cls_loss=0.6562  reg_loss=0.2888  lr_backbone=9.6e-08  lr_det=8.7e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1236s  iter_time=101.445s
2025-08-10 12:58:26 Train INFO: [Train]: [113][00015/00051] (30.8%)  Loss=0.9880  cls_loss=0.6863  reg_loss=0.3017  lr_backbone=9.4e-08  lr_det=8.5e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=987s  iter_time=107.075s
2025-08-10 13:00:58 Train INFO: [Train]: [113][00020/00051] (40.4%)  Loss=0.9687  cls_loss=0.6706  reg_loss=0.2981  lr_backbone=9.1e-08  lr_det=8.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=872s  iter_time=151.879s
2025-08-10 13:02:38 Train INFO: [Train]: [113][00025/00051] (50.0%)  Loss=0.9771  cls_loss=0.6753  reg_loss=0.3017  lr_backbone=8.9e-08  lr_det=8.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=691s  iter_time=100.504s
2025-08-10 13:04:26 Train INFO: [Train]: [113][00030/00051] (59.6%)  Loss=0.9861  cls_loss=0.6815  reg_loss=0.3046  lr_backbone=8.7e-08  lr_det=7.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=541s  iter_time=108.265s
2025-08-10 13:06:12 Train INFO: [Train]: [113][00035/00051] (69.2%)  Loss=0.9726  cls_loss=0.6728  reg_loss=0.2998  lr_backbone=8.4e-08  lr_det=7.5e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=105.734s
2025-08-10 13:08:44 Train INFO: [Train]: [113][00040/00051] (78.8%)  Loss=0.9722  cls_loss=0.6730  reg_loss=0.2993  lr_backbone=8.2e-08  lr_det=7.3e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=151.490s
2025-08-10 13:10:31 Train INFO: [Train]: [113][00045/00051] (88.5%)  Loss=0.9687  cls_loss=0.6702  reg_loss=0.2985  lr_backbone=8.0e-08  lr_det=7.1e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=107.213s
2025-08-10 13:12:17 Train INFO: [Train]: [113][00050/00051] (98.1%)  Loss=0.9735  cls_loss=0.6732  reg_loss=0.3003  lr_backbone=7.8e-08  lr_det=6.9e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=106.484s
2025-08-10 13:12:28 Train INFO: [Train]: [113][00051/00051] (100.0%)  Loss=0.9750  cls_loss=0.6739  reg_loss=0.3011  lr_backbone=7.7e-08  lr_det=6.8e-07  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.343s
2025-08-10 13:12:28 Train INFO: [Train]: Epoch 113 completed in 1281.3s (avg 24.640s/iter)
2025-08-10 13:12:28 Train INFO: [Train]: Final Loss=0.9750
2025-08-10 13:12:28 Train INFO: [Train]: Epoch 114 started (Total iterations: 52)
2025-08-10 13:16:25 Train INFO: [Train]: [114][00005/00051] (11.5%)  Loss=0.9903  cls_loss=0.6933  reg_loss=0.2970  lr_backbone=7.5e-08  lr_det=6.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1812s  iter_time=236.350s  fwd=2.059s/bwd=4.317s/opt=3.070s
2025-08-10 13:18:09 Train INFO: [Train]: [114][00010/00051] (21.2%)  Loss=0.9820  cls_loss=0.6837  reg_loss=0.2982  lr_backbone=7.3e-08  lr_det=6.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1270s  iter_time=104.388s
2025-08-10 13:20:01 Train INFO: [Train]: [114][00015/00051] (30.8%)  Loss=0.9957  cls_loss=0.6900  reg_loss=0.3057  lr_backbone=7.1e-08  lr_det=6.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1019s  iter_time=112.023s
2025-08-10 13:22:39 Train INFO: [Train]: [114][00020/00051] (40.4%)  Loss=0.9721  cls_loss=0.6736  reg_loss=0.2985  lr_backbone=6.9e-08  lr_det=6.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=901s  iter_time=157.505s
2025-08-10 13:24:20 Train INFO: [Train]: [114][00025/00051] (50.0%)  Loss=0.9863  cls_loss=0.6832  reg_loss=0.3031  lr_backbone=6.7e-08  lr_det=5.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=712s  iter_time=101.355s
2025-08-10 13:26:13 Train INFO: [Train]: [114][00030/00051] (59.6%)  Loss=0.9852  cls_loss=0.6818  reg_loss=0.3034  lr_backbone=6.5e-08  lr_det=5.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=558s  iter_time=112.669s
2025-08-10 13:27:59 Train INFO: [Train]: [114][00035/00051] (69.2%)  Loss=0.9811  cls_loss=0.6784  reg_loss=0.3027  lr_backbone=6.3e-08  lr_det=5.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=413s  iter_time=105.876s
2025-08-10 13:30:38 Train INFO: [Train]: [114][00040/00051] (78.8%)  Loss=0.9810  cls_loss=0.6792  reg_loss=0.3018  lr_backbone=6.1e-08  lr_det=5.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=292s  iter_time=159.780s
2025-08-10 13:32:28 Train INFO: [Train]: [114][00045/00051] (88.5%)  Loss=0.9803  cls_loss=0.6783  reg_loss=0.3020  lr_backbone=5.9e-08  lr_det=5.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=156s  iter_time=109.456s
2025-08-10 13:34:08 Train INFO: [Train]: [114][00050/00051] (98.1%)  Loss=0.9841  cls_loss=0.6808  reg_loss=0.3033  lr_backbone=5.7e-08  lr_det=4.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=99.784s
2025-08-10 13:34:18 Train INFO: [Train]: [114][00051/00051] (100.0%)  Loss=0.9774  cls_loss=0.6765  reg_loss=0.3009  lr_backbone=5.7e-08  lr_det=4.8e-07  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.349s
2025-08-10 13:34:19 Train INFO: [Train]: Epoch 114 completed in 1310.3s (avg 25.197s/iter)
2025-08-10 13:34:19 Train INFO: [Train]: Final Loss=0.9774
2025-08-10 13:34:19 Train INFO: [Val]: Epoch 114 Loss
2025-08-10 14:22:37 Train INFO: [Val]: [114]  Loss=1.0073  cls_loss=0.6947  reg_loss=0.3127  Average-mAP=0.79%
2025-08-10 14:22:39 Train INFO: Checkpoint saved at epoch 114
2025-08-10 14:22:39 Train INFO: [Train]: Epoch 115 started (Total iterations: 52)
2025-08-10 14:26:30 Train INFO: [Train]: [115][00005/00051] (11.5%)  Loss=0.9790  cls_loss=0.6746  reg_loss=0.3043  lr_backbone=5.5e-08  lr_det=4.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1769s  iter_time=230.718s  fwd=2.064s/bwd=4.280s/opt=3.086s
2025-08-10 14:28:20 Train INFO: [Train]: [115][00010/00051] (21.2%)  Loss=0.9440  cls_loss=0.6516  reg_loss=0.2924  lr_backbone=5.3e-08  lr_det=4.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1272s  iter_time=110.470s
2025-08-10 14:30:04 Train INFO: [Train]: [115][00015/00051] (30.8%)  Loss=0.9712  cls_loss=0.6715  reg_loss=0.2997  lr_backbone=5.1e-08  lr_det=4.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1000s  iter_time=103.305s
2025-08-10 14:32:27 Train INFO: [Train]: [115][00020/00051] (40.4%)  Loss=0.9629  cls_loss=0.6629  reg_loss=0.3000  lr_backbone=5.0e-08  lr_det=4.1e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=868s  iter_time=143.532s
2025-08-10 14:34:04 Train INFO: [Train]: [115][00025/00051] (50.0%)  Loss=0.9676  cls_loss=0.6661  reg_loss=0.3015  lr_backbone=4.8e-08  lr_det=3.9e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=685s  iter_time=97.062s
2025-08-10 14:35:49 Train INFO: [Train]: [115][00030/00051] (59.6%)  Loss=0.9726  cls_loss=0.6697  reg_loss=0.3029  lr_backbone=4.6e-08  lr_det=3.7e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=535s  iter_time=104.798s
2025-08-10 14:37:43 Train INFO: [Train]: [115][00035/00051] (69.2%)  Loss=0.9686  cls_loss=0.6673  reg_loss=0.3014  lr_backbone=4.5e-08  lr_det=3.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=402s  iter_time=114.096s
2025-08-10 14:40:23 Train INFO: [Train]: [115][00040/00051] (78.8%)  Loss=0.9731  cls_loss=0.6706  reg_loss=0.3024  lr_backbone=4.3e-08  lr_det=3.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=285s  iter_time=160.098s
2025-08-10 14:42:09 Train INFO: [Train]: [115][00045/00051] (88.5%)  Loss=0.9749  cls_loss=0.6712  reg_loss=0.3036  lr_backbone=4.2e-08  lr_det=3.3e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=153s  iter_time=106.129s
2025-08-10 14:43:43 Train INFO: [Train]: [115][00050/00051] (98.1%)  Loss=0.9777  cls_loss=0.6726  reg_loss=0.3051  lr_backbone=4.0e-08  lr_det=3.1e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=93.288s
2025-08-10 14:43:53 Train INFO: [Train]: [115][00051/00051] (100.0%)  Loss=0.9774  cls_loss=0.6725  reg_loss=0.3049  lr_backbone=4.0e-08  lr_det=3.1e-07  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.367s
2025-08-10 14:43:54 Train INFO: [Train]: Epoch 115 completed in 1274.6s (avg 24.512s/iter)
2025-08-10 14:43:54 Train INFO: [Train]: Final Loss=0.9774
2025-08-10 14:43:54 Train INFO: [Train]: Epoch 116 started (Total iterations: 52)
2025-08-10 14:47:39 Train INFO: [Train]: [116][00005/00051] (11.5%)  Loss=0.9548  cls_loss=0.6592  reg_loss=0.2956  lr_backbone=3.8e-08  lr_det=2.9e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1726s  iter_time=225.114s  fwd=2.057s/bwd=4.300s/opt=3.090s
2025-08-10 14:49:23 Train INFO: [Train]: [116][00010/00051] (21.2%)  Loss=0.9457  cls_loss=0.6491  reg_loss=0.2966  lr_backbone=3.7e-08  lr_det=2.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1228s  iter_time=104.458s
2025-08-10 14:51:03 Train INFO: [Train]: [116][00015/00051] (30.8%)  Loss=0.9541  cls_loss=0.6535  reg_loss=0.3007  lr_backbone=3.6e-08  lr_det=2.7e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=966s  iter_time=99.961s
2025-08-10 14:53:46 Train INFO: [Train]: [116][00020/00051] (40.4%)  Loss=0.9639  cls_loss=0.6609  reg_loss=0.3030  lr_backbone=3.4e-08  lr_det=2.5e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=875s  iter_time=163.235s
2025-08-10 14:55:35 Train INFO: [Train]: [116][00025/00051] (50.0%)  Loss=0.9666  cls_loss=0.6639  reg_loss=0.3027  lr_backbone=3.3e-08  lr_det=2.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=702s  iter_time=109.052s
2025-08-10 14:57:16 Train INFO: [Train]: [116][00030/00051] (59.6%)  Loss=0.9568  cls_loss=0.6589  reg_loss=0.2979  lr_backbone=3.2e-08  lr_det=2.3e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=100.144s
2025-08-10 14:58:54 Train INFO: [Train]: [116][00035/00051] (69.2%)  Loss=0.9622  cls_loss=0.6634  reg_loss=0.2988  lr_backbone=3.1e-08  lr_det=2.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=98.643s
2025-08-10 15:01:27 Train INFO: [Train]: [116][00040/00051] (78.8%)  Loss=0.9672  cls_loss=0.6666  reg_loss=0.3006  lr_backbone=2.9e-08  lr_det=2.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=152.982s
2025-08-10 15:03:08 Train INFO: [Train]: [116][00045/00051] (88.5%)  Loss=0.9672  cls_loss=0.6665  reg_loss=0.3007  lr_backbone=2.8e-08  lr_det=1.9e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=101.273s
2025-08-10 15:04:47 Train INFO: [Train]: [116][00050/00051] (98.1%)  Loss=0.9676  cls_loss=0.6669  reg_loss=0.3007  lr_backbone=2.7e-08  lr_det=1.8e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=98.245s
2025-08-10 15:04:57 Train INFO: [Train]: [116][00051/00051] (100.0%)  Loss=0.9689  cls_loss=0.6672  reg_loss=0.3017  lr_backbone=2.7e-08  lr_det=1.8e-07  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.353s
2025-08-10 15:04:58 Train INFO: [Train]: Epoch 116 completed in 1264.2s (avg 24.312s/iter)
2025-08-10 15:04:58 Train INFO: [Train]: Final Loss=0.9689
2025-08-10 15:04:58 Train INFO: [Train]: Epoch 117 started (Total iterations: 52)
2025-08-10 15:08:51 Train INFO: [Train]: [117][00005/00051] (11.5%)  Loss=0.9676  cls_loss=0.6741  reg_loss=0.2935  lr_backbone=2.6e-08  lr_det=1.7e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1790s  iter_time=233.463s  fwd=2.050s/bwd=4.297s/opt=3.083s
2025-08-10 15:10:27 Train INFO: [Train]: [117][00010/00051] (21.2%)  Loss=0.9630  cls_loss=0.6701  reg_loss=0.2929  lr_backbone=2.5e-08  lr_det=1.6e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1226s  iter_time=95.428s
2025-08-10 15:12:14 Train INFO: [Train]: [117][00015/00051] (30.8%)  Loss=0.9709  cls_loss=0.6707  reg_loss=0.3002  lr_backbone=2.4e-08  lr_det=1.5e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=982s  iter_time=107.345s
2025-08-10 15:14:39 Train INFO: [Train]: [117][00020/00051] (40.4%)  Loss=0.9783  cls_loss=0.6780  reg_loss=0.3003  lr_backbone=2.3e-08  lr_det=1.4e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=858s  iter_time=145.315s
2025-08-10 15:16:34 Train INFO: [Train]: [117][00025/00051] (50.0%)  Loss=0.9666  cls_loss=0.6697  reg_loss=0.2969  lr_backbone=2.2e-08  lr_det=1.3e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=696s  iter_time=114.270s
2025-08-10 15:18:14 Train INFO: [Train]: [117][00030/00051] (59.6%)  Loss=0.9801  cls_loss=0.6800  reg_loss=0.3001  lr_backbone=2.1e-08  lr_det=1.2e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=539s  iter_time=100.258s
2025-08-10 15:19:57 Train INFO: [Train]: [117][00035/00051] (69.2%)  Loss=0.9859  cls_loss=0.6813  reg_loss=0.3046  lr_backbone=2.0e-08  lr_det=1.1e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=400s  iter_time=103.317s
2025-08-10 15:22:30 Train INFO: [Train]: [117][00040/00051] (78.8%)  Loss=0.9867  cls_loss=0.6819  reg_loss=0.3048  lr_backbone=1.9e-08  lr_det=1.0e-07  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=282s  iter_time=152.614s
2025-08-10 15:24:25 Train INFO: [Train]: [117][00045/00051] (88.5%)  Loss=0.9722  cls_loss=0.6720  reg_loss=0.3002  lr_backbone=1.8e-08  lr_det=9.5e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=152s  iter_time=114.822s
2025-08-10 15:26:02 Train INFO: [Train]: [117][00050/00051] (98.1%)  Loss=0.9665  cls_loss=0.6686  reg_loss=0.2978  lr_backbone=1.8e-08  lr_det=8.7e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=97.346s
2025-08-10 15:26:12 Train INFO: [Train]: [117][00051/00051] (100.0%)  Loss=0.9625  cls_loss=0.6656  reg_loss=0.2969  lr_backbone=1.8e-08  lr_det=8.6e-08  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.350s
2025-08-10 15:26:13 Train INFO: [Train]: Epoch 117 completed in 1275.3s (avg 24.526s/iter)
2025-08-10 15:26:13 Train INFO: [Train]: Final Loss=0.9625
2025-08-10 15:26:13 Train INFO: [Train]: Epoch 118 started (Total iterations: 52)
2025-08-10 15:29:59 Train INFO: [Train]: [118][00005/00051] (11.5%)  Loss=0.9321  cls_loss=0.6538  reg_loss=0.2784  lr_backbone=1.7e-08  lr_det=7.8e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1729s  iter_time=225.459s  fwd=2.073s/bwd=4.315s/opt=3.091s
2025-08-10 15:31:43 Train INFO: [Train]: [118][00010/00051] (21.2%)  Loss=0.9579  cls_loss=0.6707  reg_loss=0.2872  lr_backbone=1.6e-08  lr_det=7.1e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1231s  iter_time=104.806s
2025-08-10 15:33:36 Train INFO: [Train]: [118][00015/00051] (30.8%)  Loss=0.9811  cls_loss=0.6827  reg_loss=0.2984  lr_backbone=1.5e-08  lr_det=6.5e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=997s  iter_time=113.050s
2025-08-10 15:36:07 Train INFO: [Train]: [118][00020/00051] (40.4%)  Loss=0.9878  cls_loss=0.6869  reg_loss=0.3009  lr_backbone=1.5e-08  lr_det=5.9e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=877s  iter_time=150.953s
2025-08-10 15:37:50 Train INFO: [Train]: [118][00025/00051] (50.0%)  Loss=0.9855  cls_loss=0.6843  reg_loss=0.3012  lr_backbone=1.4e-08  lr_det=5.3e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=697s  iter_time=102.951s
2025-08-10 15:39:35 Train INFO: [Train]: [118][00030/00051] (59.6%)  Loss=0.9836  cls_loss=0.6814  reg_loss=0.3022  lr_backbone=1.4e-08  lr_det=4.8e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=543s  iter_time=104.665s
2025-08-10 15:41:19 Train INFO: [Train]: [118][00035/00051] (69.2%)  Loss=0.9820  cls_loss=0.6798  reg_loss=0.3022  lr_backbone=1.3e-08  lr_det=4.3e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=403s  iter_time=104.361s
2025-08-10 15:43:48 Train INFO: [Train]: [118][00040/00051] (78.8%)  Loss=0.9870  cls_loss=0.6821  reg_loss=0.3049  lr_backbone=1.3e-08  lr_det=3.8e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=283s  iter_time=148.224s
2025-08-10 15:45:32 Train INFO: [Train]: [118][00045/00051] (88.5%)  Loss=0.9841  cls_loss=0.6795  reg_loss=0.3046  lr_backbone=1.2e-08  lr_det=3.4e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=151s  iter_time=104.528s
2025-08-10 15:47:16 Train INFO: [Train]: [118][00050/00051] (98.1%)  Loss=0.9793  cls_loss=0.6766  reg_loss=0.3028  lr_backbone=1.2e-08  lr_det=3.0e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=25s  iter_time=103.833s
2025-08-10 15:47:26 Train INFO: [Train]: [118][00051/00051] (100.0%)  Loss=0.9785  cls_loss=0.6761  reg_loss=0.3024  lr_backbone=1.2e-08  lr_det=2.9e-08  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.349s
2025-08-10 15:47:27 Train INFO: [Train]: Epoch 118 completed in 1273.9s (avg 24.499s/iter)
2025-08-10 15:47:27 Train INFO: [Train]: Final Loss=0.9785
2025-08-10 15:47:27 Train INFO: [Train]: Epoch 119 started (Total iterations: 52)
2025-08-10 15:51:15 Train INFO: [Train]: [119][00005/00051] (11.5%)  Loss=0.9556  cls_loss=0.6601  reg_loss=0.2956  lr_backbone=1.2e-08  lr_det=2.5e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1744s  iter_time=227.415s  fwd=2.057s/bwd=4.303s/opt=3.080s
2025-08-10 15:52:51 Train INFO: [Train]: [119][00010/00051] (21.2%)  Loss=0.9611  cls_loss=0.6661  reg_loss=0.2950  lr_backbone=1.1e-08  lr_det=2.2e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=1209s  iter_time=96.838s
2025-08-10 15:54:46 Train INFO: [Train]: [119][00015/00051] (30.8%)  Loss=0.9807  cls_loss=0.6801  reg_loss=0.3006  lr_backbone=1.1e-08  lr_det=1.9e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=987s  iter_time=114.387s
2025-08-10 15:57:12 Train INFO: [Train]: [119][00020/00051] (40.4%)  Loss=0.9778  cls_loss=0.6772  reg_loss=0.3006  lr_backbone=1.1e-08  lr_det=1.7e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=864s  iter_time=146.362s
2025-08-10 15:59:04 Train INFO: [Train]: [119][00025/00051] (50.0%)  Loss=0.9730  cls_loss=0.6746  reg_loss=0.2983  lr_backbone=1.1e-08  lr_det=1.5e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=697s  iter_time=111.928s
2025-08-10 16:00:44 Train INFO: [Train]: [119][00030/00051] (59.6%)  Loss=0.9564  cls_loss=0.6634  reg_loss=0.2930  lr_backbone=1.0e-08  lr_det=1.3e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=540s  iter_time=99.889s
2025-08-10 16:02:22 Train INFO: [Train]: [119][00035/00051] (69.2%)  Loss=0.9622  cls_loss=0.6672  reg_loss=0.2950  lr_backbone=1.0e-08  lr_det=1.2e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=398s  iter_time=98.554s
2025-08-10 16:04:53 Train INFO: [Train]: [119][00040/00051] (78.8%)  Loss=0.9575  cls_loss=0.6636  reg_loss=0.2938  lr_backbone=1.0e-08  lr_det=1.1e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=281s  iter_time=150.451s
2025-08-10 16:06:34 Train INFO: [Train]: [119][00045/00051] (88.5%)  Loss=0.9620  cls_loss=0.6673  reg_loss=0.2947  lr_backbone=1.0e-08  lr_det=1.0e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=150s  iter_time=101.076s
2025-08-10 16:08:11 Train INFO: [Train]: [119][00050/00051] (98.1%)  Loss=0.9658  cls_loss=0.6703  reg_loss=0.2955  lr_backbone=1.0e-08  lr_det=1.0e-08  GPU=1440MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=24s  iter_time=96.663s
2025-08-10 16:08:21 Train INFO: [Train]: [119][00051/00051] (100.0%)  Loss=0.9663  cls_loss=0.6710  reg_loss=0.2954  lr_backbone=1.0e-08  lr_det=1.0e-08  GPU=1404MB(alloc)/19180MB(reserved)/16159MB(max)  ETA=0s  iter_time=10.354s
2025-08-10 16:08:22 Train INFO: [Train]: Epoch 119 completed in 1254.7s (avg 24.128s/iter)
2025-08-10 16:08:22 Train INFO: [Train]: Final Loss=0.9663
2025-08-10 16:08:22 Train INFO: [Val]: Epoch 119 Loss
2025-08-10 16:56:49 Train INFO: [Val]: [119]  Loss=1.0073  cls_loss=0.6946  reg_loss=0.3127  Average-mAP=0.92%
2025-08-10 16:56:52 Train INFO: Checkpoint saved at epoch 119
2025-08-10 16:56:52 Train INFO: Training Over...

2025-08-11 09:32:08 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-11 09:32:08 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.1,
        0.3,
        0.5,
        0.7,
        0.9,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.03)
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=1000,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.6),
    save_dict=True)
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=3,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=0,
    val_eval_interval=3,
    val_loss_interval=3,
    val_start_epoch=3)

2025-08-11 09:32:09 Train INFO: training subset: 831 videos
2025-08-11 09:32:09 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-11 09:32:09 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-11 09:32:10 Train INFO: Using single GPU training...
2025-08-11 09:32:10 Train INFO: Using Model EMA...
2025-08-11 09:32:10 Train INFO: Using Automatic Mixed Precision...
2025-08-11 09:32:10 Train INFO: GPU Memory: 24.0 GB
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.pos_embed
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-11 09:32:10 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-11 09:32:10 Train INFO: Training Starts...

2025-08-11 09:32:10 Train INFO: [Train]: Epoch 0 started (Total iterations: 52)
2025-08-11 09:41:29 Train INFO: [Train]: [000][00005/00051] (11.5%)  Loss=1.6272  cls_loss=0.8681  reg_loss=0.7590  lr_backbone=1.9e-07  lr_det=1.9e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=4288s  iter_time=559.242s  fwd=3.855s/bwd=50.673s/opt=0.007s
2025-08-11 09:46:22 Train INFO: [Train]: [000][00010/00051] (21.2%)  Loss=1.6351  cls_loss=0.8832  reg_loss=0.7518  lr_backbone=3.9e-07  lr_det=3.9e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=3176s  iter_time=292.970s
2025-08-11 09:51:26 Train INFO: [Train]: [000][00015/00051] (30.8%)  Loss=1.6662  cls_loss=0.9263  reg_loss=0.7399  lr_backbone=5.8e-07  lr_det=5.8e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=2601s  iter_time=303.691s
2025-08-11 09:56:39 Train INFO: [Train]: [000][00020/00051] (40.4%)  Loss=1.6710  cls_loss=0.9595  reg_loss=0.7115  lr_backbone=7.7e-07  lr_det=7.7e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=2169s  iter_time=313.403s
2025-08-11 10:02:37 Train INFO: [Train]: [000][00025/00051] (50.0%)  Loss=1.6092  cls_loss=0.9571  reg_loss=0.6522  lr_backbone=9.7e-07  lr_det=9.7e-06  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1827s  iter_time=357.835s
2025-08-11 10:07:10 Train INFO: [Train]: [000][00030/00051] (59.6%)  Loss=1.6146  cls_loss=0.9997  reg_loss=0.6149  lr_backbone=1.2e-06  lr_det=1.2e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1423s  iter_time=273.216s
2025-08-11 10:11:47 Train INFO: [Train]: [000][00035/00051] (69.2%)  Loss=1.5723  cls_loss=0.9999  reg_loss=0.5725  lr_backbone=1.4e-06  lr_det=1.4e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=1057s  iter_time=277.003s
2025-08-11 10:16:54 Train INFO: [Train]: [000][00040/00051] (78.8%)  Loss=1.5410  cls_loss=0.9990  reg_loss=0.5420  lr_backbone=1.5e-06  lr_det=1.5e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=720s  iter_time=307.221s
2025-08-11 10:21:20 Train INFO: [Train]: [000][00045/00051] (88.5%)  Loss=1.5226  cls_loss=1.0028  reg_loss=0.5198  lr_backbone=1.7e-06  lr_det=1.7e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=385s  iter_time=265.810s
2025-08-11 10:25:22 Train INFO: [Train]: [000][00050/00051] (98.1%)  Loss=1.5152  cls_loss=1.0115  reg_loss=0.5038  lr_backbone=1.9e-06  lr_det=1.9e-05  GPU=1443MB(alloc)/25254MB(reserved)/16159MB(max)  ETA=63s  iter_time=241.709s
2025-08-11 10:25:39 Train INFO: [Train]: [000][00051/00051] (100.0%)  Loss=1.5078  cls_loss=1.0081  reg_loss=0.4996  lr_backbone=2.0e-06  lr_det=2.0e-05  GPU=1404MB(alloc)/16714MB(reserved)/16159MB(max)  ETA=0s  iter_time=17.234s
2025-08-11 10:25:40 Train INFO: [Train]: Epoch 0 completed in 3210.4s (avg 61.738s/iter)
2025-08-11 10:25:40 Train INFO: [Train]: Final Loss=1.5078
2025-08-11 10:25:40 Train INFO: [Train]: Epoch 1 started (Total iterations: 52)
2025-08-11 10:35:33 Train INFO: [Train]: [001][00005/00051] (11.5%)  Loss=1.3505  cls_loss=1.0122  reg_loss=0.3383  lr_backbone=2.2e-06  lr_det=2.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4546s  iter_time=592.949s  fwd=36.840s/bwd=10.172s/opt=17.542s
2025-08-11 10:41:21 Train INFO: [Train]: [001][00010/00051] (21.2%)  Loss=1.3498  cls_loss=1.0126  reg_loss=0.3372  lr_backbone=2.4e-06  lr_det=2.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3509s  iter_time=348.456s
2025-08-11 10:46:49 Train INFO: [Train]: [001][00015/00051] (30.8%)  Loss=1.3285  cls_loss=0.9980  reg_loss=0.3305  lr_backbone=2.6e-06  lr_det=2.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2855s  iter_time=327.312s
2025-08-11 10:52:15 Train INFO: [Train]: [001][00020/00051] (40.4%)  Loss=1.3148  cls_loss=0.9886  reg_loss=0.3262  lr_backbone=2.8e-06  lr_det=2.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2354s  iter_time=326.056s
2025-08-11 10:57:45 Train INFO: [Train]: [001][00025/00051] (50.0%)  Loss=1.3169  cls_loss=0.9906  reg_loss=0.3264  lr_backbone=3.0e-06  lr_det=3.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1925s  iter_time=329.805s
2025-08-11 11:03:19 Train INFO: [Train]: [001][00030/00051] (59.6%)  Loss=1.3222  cls_loss=0.9952  reg_loss=0.3270  lr_backbone=3.2e-06  lr_det=3.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1530s  iter_time=334.211s
2025-08-11 11:08:55 Train INFO: [Train]: [001][00035/00051] (69.2%)  Loss=1.3187  cls_loss=0.9939  reg_loss=0.3248  lr_backbone=3.4e-06  lr_det=3.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1153s  iter_time=336.354s
2025-08-11 11:14:15 Train INFO: [Train]: [001][00040/00051] (78.8%)  Loss=1.2965  cls_loss=0.9783  reg_loss=0.3182  lr_backbone=3.6e-06  lr_det=3.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=782s  iter_time=319.764s
2025-08-11 11:19:19 Train INFO: [Train]: [001][00045/00051] (88.5%)  Loss=1.2976  cls_loss=0.9798  reg_loss=0.3178  lr_backbone=3.7e-06  lr_det=3.7e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=420s  iter_time=303.983s
2025-08-11 11:24:08 Train INFO: [Train]: [001][00050/00051] (98.1%)  Loss=1.2952  cls_loss=0.9780  reg_loss=0.3173  lr_backbone=3.9e-06  lr_det=3.9e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=69s  iter_time=288.851s
2025-08-11 11:26:59 Train INFO: [Train]: [001][00051/00051] (100.0%)  Loss=1.2964  cls_loss=0.9790  reg_loss=0.3174  lr_backbone=4.0e-06  lr_det=4.0e-05  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=171.674s
2025-08-11 11:27:00 Train INFO: [Train]: Epoch 1 completed in 3680.2s (avg 70.774s/iter)
2025-08-11 11:27:00 Train INFO: [Train]: Final Loss=1.2964
2025-08-11 11:27:00 Train INFO: [Train]: Epoch 2 started (Total iterations: 52)
2025-08-11 11:36:28 Train INFO: [Train]: [002][00005/00051] (11.5%)  Loss=1.1765  cls_loss=0.8977  reg_loss=0.2788  lr_backbone=4.2e-06  lr_det=4.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=4352s  iter_time=567.701s  fwd=34.302s/bwd=9.220s/opt=15.436s
2025-08-11 11:41:42 Train INFO: [Train]: [002][00010/00051] (21.2%)  Loss=1.3091  cls_loss=0.9893  reg_loss=0.3198  lr_backbone=4.4e-06  lr_det=4.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=3287s  iter_time=314.215s
2025-08-11 11:46:55 Train INFO: [Train]: [002][00015/00051] (30.8%)  Loss=1.3182  cls_loss=0.9935  reg_loss=0.3247  lr_backbone=4.6e-06  lr_det=4.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2689s  iter_time=313.099s
2025-08-11 11:52:06 Train INFO: [Train]: [002][00020/00051] (40.4%)  Loss=1.3029  cls_loss=0.9837  reg_loss=0.3192  lr_backbone=4.8e-06  lr_det=4.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=2223s  iter_time=311.219s
2025-08-11 11:57:17 Train INFO: [Train]: [002][00025/00051] (50.0%)  Loss=1.3109  cls_loss=0.9905  reg_loss=0.3204  lr_backbone=5.0e-06  lr_det=5.0e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1817s  iter_time=310.816s
2025-08-11 12:02:30 Train INFO: [Train]: [002][00030/00051] (59.6%)  Loss=1.2961  cls_loss=0.9802  reg_loss=0.3159  lr_backbone=5.2e-06  lr_det=5.2e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1442s  iter_time=312.250s
2025-08-11 12:07:42 Train INFO: [Train]: [002][00035/00051] (69.2%)  Loss=1.2985  cls_loss=0.9814  reg_loss=0.3171  lr_backbone=5.4e-06  lr_det=5.4e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=1085s  iter_time=312.107s
2025-08-11 12:12:54 Train INFO: [Train]: [002][00040/00051] (78.8%)  Loss=1.2968  cls_loss=0.9793  reg_loss=0.3175  lr_backbone=5.6e-06  lr_det=5.6e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=739s  iter_time=312.270s
2025-08-11 12:17:57 Train INFO: [Train]: [002][00045/00051] (88.5%)  Loss=1.2812  cls_loss=0.9683  reg_loss=0.3129  lr_backbone=5.8e-06  lr_det=5.8e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=399s  iter_time=303.239s
2025-08-11 12:22:45 Train INFO: [Train]: [002][00050/00051] (98.1%)  Loss=1.2803  cls_loss=0.9676  reg_loss=0.3127  lr_backbone=5.9e-06  lr_det=5.9e-05  GPU=1441MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=66s  iter_time=287.648s
2025-08-11 12:25:36 Train INFO: [Train]: [002][00051/00051] (100.0%)  Loss=1.2809  cls_loss=0.9680  reg_loss=0.3128  lr_backbone=6.0e-06  lr_det=6.0e-05  GPU=1403MB(alloc)/23952MB(reserved)/16159MB(max)  ETA=0s  iter_time=171.609s
2025-08-11 12:25:37 Train INFO: [Train]: Epoch 2 completed in 3517.0s (avg 67.634s/iter)
2025-08-11 12:25:37 Train INFO: [Train]: Final Loss=1.2809
2025-08-11 12:25:38 Train INFO: Checkpoint saved at epoch 2
2025-08-11 12:25:38 Train INFO: [Train]: Epoch 3 started (Total iterations: 52)
2025-08-11 13:21:54 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-11 13:21:54 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.1,
        0.3,
        0.5,
        0.7,
        0.9,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.03)
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=1000,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.6),
    save_dict=True)
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=3,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=0,
    val_eval_interval=3,
    val_loss_interval=3,
    val_start_epoch=3)

2025-08-11 13:21:55 Train INFO: training subset: 831 videos
2025-08-11 13:21:55 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-11 13:21:55 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-11 13:21:55 Train INFO: Using single GPU training...
2025-08-11 13:21:55 Train INFO: Using Model EMA...
2025-08-11 13:21:56 Train INFO: Using Automatic Mixed Precision...
2025-08-11 13:21:56 Train INFO: GPU Memory: 24.0 GB
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.pos_embed
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-11 13:21:56 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-11 13:21:56 Train INFO: Resume training from: work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze/gpu1_id0/checkpoint/epoch_2.pth
2025-08-11 13:21:56 Train INFO: Resume epoch is 2
2025-08-11 13:21:56 Train INFO: Training Starts...

2025-08-11 13:21:56 Train INFO: [Train]: Epoch 3 started (Total iterations: 52)
2025-08-11 13:33:14 Train INFO: [Train]: [003][00005/00051] (11.5%)  Loss=1.4254  cls_loss=1.0676  reg_loss=0.3579  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=5196s  iter_time=677.770s  fwd=3.830s/bwd=53.988s/opt=0.016s
2025-08-11 13:38:26 Train INFO: [Train]: [003][00010/00051] (21.2%)  Loss=1.3361  cls_loss=1.0058  reg_loss=0.3303  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=3692s  iter_time=312.673s
2025-08-11 13:43:33 Train INFO: [Train]: [003][00015/00051] (30.8%)  Loss=1.3105  cls_loss=0.9876  reg_loss=0.3230  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=2919s  iter_time=306.867s
2025-08-11 13:47:32 Train INFO: Using torch version: 2.5.1+cu121, CUDA version: 12.1
2025-08-11 13:47:33 Train INFO: Config: 
annotation_test = 'data/PKU-MMD/pku_test.json'
annotation_train = 'data/PKU-MMD/pku_train.json'
annotation_val = 'data/PKU-MMD/pku_val.json'
block_list = None
chunk_num = 32
class_map = 'data/PKU-MMD/class_map.txt'
dataset = dict(
    test=dict(
        ann_file='data/PKU-MMD/pku_test.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(keys=[
                'imgs',
            ], type='ConvertToTensor'),
            dict(inputs='imgs', keys=[
                'masks',
            ], type='Collect'),
        ],
        sample_stride=1,
        subset_name='testing',
        test_mode=True,
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512),
    train=dict(
        ann_file='data/PKU-MMD/pku_train.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=6, type='mmaction.DecordInit'),
            dict(
                crop_ratio=[
                    0.9,
                    1.0,
                ],
                method='random_trunc',
                num_clips=1,
                scale_factor=1,
                trunc_len=512,
                trunc_thresh=0.5,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                182,
            ), type='mmaction.Resize'),
            dict(type='mmaction.RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                160,
                160,
            ), type='mmaction.Resize'),
            dict(flip_ratio=0.5, type='mmaction.Flip'),
            dict(transforms='default', type='mmaction.ImgAug'),
            dict(type='mmaction.ColorJitter'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='training',
        type='PkuPaddingDataset'),
    val=dict(
        ann_file='data/PKU-MMD/pku_val.json',
        class_map='data/PKU-MMD/class_map.txt',
        data_path='F:/dataset/pku-mmd/rgb',
        feature_stride=1,
        filter_gt=False,
        pipeline=[
            dict(format='avi', type='PrepareVideoInfo'),
            dict(num_threads=4, type='mmaction.DecordInit'),
            dict(
                method='sliding_window',
                num_clips=1,
                scale_factor=1,
                type='LoadFrames'),
            dict(type='mmaction.DecordDecode'),
            dict(scale=(
                -1,
                160,
            ), type='mmaction.Resize'),
            dict(crop_size=160, type='mmaction.CenterCrop'),
            dict(input_format='NCTHW', type='mmaction.FormatShape'),
            dict(
                keys=[
                    'imgs',
                    'gt_segments',
                    'gt_labels',
                ],
                type='ConvertToTensor'),
            dict(
                inputs='imgs',
                keys=[
                    'masks',
                    'gt_segments',
                    'gt_labels',
                ],
                type='Collect'),
        ],
        sample_stride=1,
        subset_name='validation',
        type='PkuSlidingDataset',
        window_overlap_ratio=0.5,
        window_size=512))
evaluation = dict(
    ground_truth_filename='data/PKU-MMD/pku_val.json',
    prediction_filename=
    'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter/gpu1_id0/predictions_val.json',
    subset='validation',
    tiou_thresholds=[
        0.2,
        0.3,
        0.4,
        0.5,
        0.6,
    ],
    type='mAP_PKU_MMD')
inference = dict(
    load_from_raw_predictions=False,
    save_raw_prediction=False,
    score_thresh=0.03)
model = dict(
    backbone=dict(
        adapter_index=[
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
        ],
        adapter_mlp_ratio=0.25,
        custom=dict(
            freeze_backbone=False,
            norm_eval=False,
            post_processing_pipeline=[
                dict(
                    keys=[
                        'feats',
                    ],
                    ops='b n c t -> b c t',
                    reduction='mean',
                    type='Reduce'),
            ]),
        depth=12,
        drop_path_rate=0.1,
        embed_dims=384,
        img_size=160,
        mlp_ratio=4.0,
        num_frames=16,
        num_heads=6,
        patch_size=16,
        pretrained=
        'pretrained/vit-small-p16_videomae-k400-pre_16x4x1_kinetics-400_my.pth',
        qkv_bias=True,
        return_feat_map=True,
        total_frames=512,
        tubelet_size=2,
        type='VisionTransformerAdapter',
        use_mean_pooling=True,
        with_cp=True),
    neck=dict(
        in_channels=512, num_levels=6, out_channels=512, type='FPNIdentity'),
    projection=dict(
        arch=(
            2,
            2,
            5,
        ),
        attn_cfg=dict(n_head=4, n_mha_win_size=-1),
        conv_cfg=dict(kernel_size=3, proj_pdrop=0.0),
        in_channels=384,
        max_seq_len=512,
        norm_cfg=dict(type='LN'),
        out_channels=512,
        path_pdrop=0.1,
        type='Conv1DTransformerProj',
        use_abs_pe=False),
    rpn_head=dict(
        center_sample='radius',
        center_sample_radius=1.5,
        cls_prior_prob=0.01,
        feat_channels=512,
        in_channels=512,
        label_smoothing=0.0,
        loss=dict(
            cls_loss=dict(type='FocalLoss'), reg_loss=dict(type='DIOULoss')),
        loss_normalizer=100,
        loss_normalizer_momentum=0.9,
        num_classes=51,
        num_convs=2,
        prior_generator=dict(
            regression_range=[
                (
                    0,
                    4,
                ),
                (
                    4,
                    8,
                ),
                (
                    8,
                    16,
                ),
                (
                    16,
                    32,
                ),
                (
                    32,
                    64,
                ),
                (
                    64,
                    10000,
                ),
            ],
            strides=[
                1,
                2,
                4,
                8,
                16,
                32,
            ],
            type='PointGenerator'),
        type='ActionFormerHead'),
    type='ActionFormer')
optimizer = dict(
    backbone=dict(
        custom=[
            dict(lr=0.0002, name='adapter', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.10', weight_decay=0.05),
            dict(lr=5e-05, name='blocks.11', weight_decay=0.05),
        ],
        exclude=[
            'backbone',
        ],
        lr=1e-05,
        weight_decay=0.05),
    lr=0.0001,
    paramwise=True,
    type='AdamW',
    weight_decay=0.05)
post_processing = dict(
    nms=dict(
        max_seg_num=1000,
        multiclass=False,
        sigma=0.3,
        use_soft_nms=True,
        voting_thresh=0.6),
    save_dict=True)
scale_factor = 1
scheduler = dict(
    max_epoch=120, type='LinearWarmupCosineAnnealingLR', warmup_epoch=5)
solver = dict(
    amp=True,
    clip_grad_norm=1,
    ema=True,
    fp16_compress=True,
    static_graph=True,
    test=dict(batch_size=4, num_workers=4),
    train=dict(batch_size=16, num_workers=4),
    val=dict(batch_size=16, num_workers=4))
video_dir = 'F:/dataset/pku-mmd/rgb'
window_size = 512
work_dir = 'work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze\\gpu1_id0/'
workflow = dict(
    checkpoint_interval=3,
    end_epoch=120,
    logging_interval=5,
    num_sanity_check=0,
    val_eval_interval=3,
    val_loss_interval=3,
    val_start_epoch=3)

2025-08-11 13:47:33 Train INFO: training subset: 831 videos
2025-08-11 13:47:33 Train INFO: validation subset: 111 videos, truncated as 1958 windows.
2025-08-11 13:47:33 Train INFO: testing subset: 132 videos, truncated as 2370 windows.
2025-08-11 13:47:34 Train INFO: Using single GPU training...
2025-08-11 13:47:34 Train INFO: Using Model EMA...
2025-08-11 13:47:34 Train INFO: Using Automatic Mixed Precision...
2025-08-11 13:47:34 Train INFO: GPU Memory: 24.0 GB
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.pos_embed
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.patch_embed.projection.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.patch_embed.projection.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.0.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.1.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.2.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.3.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.4.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.5.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.6.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.7.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.8.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.9.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.10.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.norm1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.norm1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.attn.q_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.attn.v_bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.attn.qkv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.attn.proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.attn.proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.norm2.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.norm2.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.0.0.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.mlp.layers.1.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.gamma
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.dwconv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.conv.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.down_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.blocks.11.adapter.up_proj.bias
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.fc_norm.weight
2025-08-11 13:47:34 Train INFO: Backbone parameter: model.fc_norm.bias
2025-08-11 13:47:34 Train INFO: Resume training from: work_dirs/e2e_pku_mmd_videomae_s_768x1_160_adapter_unfreeze/gpu1_id0/checkpoint/epoch_2.pth
2025-08-11 13:47:34 Train INFO: Resume epoch is 2
2025-08-11 13:47:34 Train INFO: Training Starts...

2025-08-11 13:47:34 Train INFO: [Train]: Epoch 3 started (Total iterations: 52)
2025-08-11 13:52:55 Train INFO: [Train]: [003][00005/00051] (11.5%)  Loss=1.4254  cls_loss=1.0676  reg_loss=0.3579  lr_backbone=6.2e-06  lr_det=6.2e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=2461s  iter_time=320.975s  fwd=3.138s/bwd=33.490s/opt=0.035s
2025-08-11 13:55:56 Train INFO: [Train]: [003][00010/00051] (21.2%)  Loss=1.3361  cls_loss=1.0058  reg_loss=0.3303  lr_backbone=6.4e-06  lr_det=6.4e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=1872s  iter_time=181.201s
2025-08-11 13:58:53 Train INFO: [Train]: [003][00015/00051] (30.8%)  Loss=1.3105  cls_loss=0.9876  reg_loss=0.3229  lr_backbone=6.6e-06  lr_det=6.6e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=1529s  iter_time=177.264s
2025-08-11 14:01:39 Train INFO: [Train]: [003][00020/00051] (40.4%)  Loss=1.2991  cls_loss=0.9759  reg_loss=0.3232  lr_backbone=6.8e-06  lr_det=6.8e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=1247s  iter_time=165.070s
2025-08-11 14:04:16 Train INFO: [Train]: [003][00025/00051] (50.0%)  Loss=1.2566  cls_loss=0.9439  reg_loss=0.3127  lr_backbone=7.0e-06  lr_det=7.0e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=1002s  iter_time=157.108s
2025-08-11 14:06:55 Train INFO: [Train]: [003][00030/00051] (59.6%)  Loss=1.2653  cls_loss=0.9466  reg_loss=0.3187  lr_backbone=7.2e-06  lr_det=7.2e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=787s  iter_time=159.688s
2025-08-11 14:09:34 Train INFO: [Train]: [003][00035/00051] (69.2%)  Loss=1.2341  cls_loss=0.9215  reg_loss=0.3127  lr_backbone=7.4e-06  lr_det=7.4e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=586s  iter_time=158.212s
2025-08-11 14:12:10 Train INFO: [Train]: [003][00040/00051] (78.8%)  Loss=1.2138  cls_loss=0.9024  reg_loss=0.3114  lr_backbone=7.6e-06  lr_det=7.6e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=396s  iter_time=156.903s
2025-08-11 14:14:39 Train INFO: [Train]: [003][00045/00051] (88.5%)  Loss=1.1997  cls_loss=0.8883  reg_loss=0.3114  lr_backbone=7.8e-06  lr_det=7.8e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=212s  iter_time=148.292s
2025-08-11 14:16:40 Train INFO: [Train]: [003][00050/00051] (98.1%)  Loss=1.1963  cls_loss=0.8826  reg_loss=0.3137  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1441MB(alloc)/25434MB(reserved)/16157MB(max)  ETA=34s  iter_time=121.181s
2025-08-11 14:16:55 Train INFO: [Train]: [003][00051/00051] (100.0%)  Loss=1.1898  cls_loss=0.8772  reg_loss=0.3126  lr_backbone=8.0e-06  lr_det=8.0e-05  GPU=1403MB(alloc)/16898MB(reserved)/16157MB(max)  ETA=0s  iter_time=14.773s
2025-08-11 14:16:55 Train INFO: [Train]: Epoch 3 completed in 1761.5s (avg 33.874s/iter)
2025-08-11 14:16:55 Train INFO: [Train]: Final Loss=1.1898
2025-08-11 14:16:55 Train INFO: [Train]: Epoch 4 started (Total iterations: 52)
